{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuananh/anaconda3/envs/code/lib/python3.8/site-packages/datasets/load.py:1461: FutureWarning: The repository for code_search_net contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/code_search_net\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# This can take a few minutes to load, so grab a coffee or tea while you wait!\n",
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 412178\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412178"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_new_token(self, netloc):\n",
      "        \"\"\"Get a new token from BIG-IP and store it internally.\n",
      "\n",
      "        Throws relevant exception if it fails to get a new token.\n",
      "\n",
      "        This method will be called automatically if a request is attempted\n",
      "        but there is no authentication token, or the authentication token\n",
      "        is expired.  It is usually not necessary for users to call it, but\n",
      "        it can be called if it is known that the authentication token has\n",
      "        been invalidated by other means.\n",
      "        \"\"\"\n",
      "        login_body = {\n",
      "            'username': self.username,\n",
      "            'password': self.password,\n",
      "        }\n",
      "\n",
      "        if self.auth_provider:\n",
      "            if self.auth_provider == 'local':\n",
      "                login_body['loginProviderName'] = 'local'\n",
      "            elif self.auth_provider == 'tmos':\n",
      "                login_body['loginProviderName'] = 'tmos'\n",
      "            elif self.auth_provider not in ['none', 'default']:\n",
      "                providers = self.get_auth_providers(netloc)\n",
      "                for provider in providers:\n",
      "                    if self.auth_provider in provider['link']:\n",
      "                        login_body['loginProviderName'] = provider['name']\n",
      "                        break\n",
      "                    elif self.auth_provider == provider['name']:\n",
      "                        login_body['loginProviderName'] = provider['name']\n",
      "                        break\n",
      "        else:\n",
      "            if self.login_provider_name == 'tmos':\n",
      "                login_body['loginProviderName'] = self.login_provider_name\n",
      "\n",
      "        login_url = \"https://%s/mgmt/shared/authn/login\" % (netloc)\n",
      "\n",
      "        response = requests.post(\n",
      "            login_url,\n",
      "            json=login_body,\n",
      "            verify=self.verify,\n",
      "            auth=HTTPBasicAuth(self.username, self.password)\n",
      "        )\n",
      "        self.attempts += 1\n",
      "        if not response.ok or not hasattr(response, \"json\"):\n",
      "            error_message = '%s Unexpected Error: %s for uri: %s\\nText: %r' %\\\n",
      "                            (response.status_code,\n",
      "                             response.reason,\n",
      "                             response.url,\n",
      "                             response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "        respJson = response.json()\n",
      "\n",
      "        token = self._get_token_from_response(respJson)\n",
      "        created_bigip = self._get_last_update_micros(token)\n",
      "\n",
      "        try:\n",
      "            expiration_bigip = self._get_expiration_micros(\n",
      "                token, created_bigip\n",
      "            )\n",
      "        except (KeyError, ValueError):\n",
      "            error_message = \\\n",
      "                '%s Unparseable Response: %s for uri: %s\\nText: %r' %\\\n",
      "                (response.status_code,\n",
      "                 response.reason,\n",
      "                 response.url,\n",
      "                 response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "\n",
      "        try:\n",
      "            self.expiration = self._get_token_expiration_time(\n",
      "                created_bigip, expiration_bigip\n",
      "            )\n",
      "        except iControlUnexpectedHTTPError:\n",
      "            error_message = \\\n",
      "                '%s Token already expired: %s for uri: %s\\nText: %r' % \\\n",
      "                (response.status_code,\n",
      "                 time.ctime(expiration_bigip),\n",
      "                 response.url,\n",
      "                 response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "def get_new_token(self, netloc):\n",
      "        \"\"\"Get a new token from BIG-IP and store it internally.\n",
      "\n",
      "        Throws relevant exception if it fails to get a new token.\n",
      "\n",
      "        This method will be called automatically if a request is attempted\n",
      "        but there is no authentication token, or the authentication token\n",
      "        is expired.  It is usually not necessary for users to call it, but\n",
      "        it can be called if it is known that the authentication token has\n",
      "        been invalidated by other means.\n",
      "        \"\"\"\n",
      "        login_body = {\n",
      "            'username': self.username,\n",
      "            'password': self.password,\n",
      "        }\n",
      "\n",
      "        if self.auth_provider:\n",
      "            if self.auth_provider == 'local':\n",
      "                login_body['loginProviderName'] = 'local'\n",
      "            elif self.auth_provider == 'tmos':\n",
      "                login_body['loginProviderName'] = 'tmos'\n",
      "            elif self.auth_provider not in ['none', 'default']:\n",
      "                providers = self.get_auth_providers(netloc)\n",
      "                for provider in providers:\n",
      "                    if self.auth_provider in provider['link']:\n",
      "                        login_body['loginProviderName'] = provider['name']\n",
      "                        break\n",
      "                    elif self.auth_provider == provider['name']:\n",
      "                        login_body['loginProviderName'] = provider['name']\n",
      "                        break\n",
      "        else:\n",
      "            if self.login_provider_name == 'tmos':\n",
      "                login_body['loginProviderName'] = self.login_provider_name\n",
      "\n",
      "        login_url = \"https://%s/mgmt/shared/authn/login\" % (netloc)\n",
      "\n",
      "        response = requests.post(\n",
      "            login_url,\n",
      "            json=login_body,\n",
      "            verify=self.verify,\n",
      "            auth=HTTPBasicAuth(self.username, self.password)\n",
      "        )\n",
      "        self.attempts += 1\n",
      "        if not response.ok or not hasattr(response, \"json\"):\n",
      "            error_message = '%s Unexpected Error: %s for uri: %s\\nText: %r' %\\\n",
      "                            (response.status_code,\n",
      "                             response.reason,\n",
      "                             response.url,\n",
      "                             response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "        respJson = response.json()\n",
      "\n",
      "        token = self._get_token_from_response(respJson)\n",
      "        created_bigip = self._get_last_update_micros(token)\n",
      "\n",
      "        try:\n",
      "            expiration_bigip = self._get_expiration_micros(\n",
      "                token, created_bigip\n",
      "            )\n",
      "        except (KeyError, ValueError):\n",
      "            error_message = \\\n",
      "                '%s Unparseable Response: %s for uri: %s\\nText: %r' %\\\n",
      "                (response.status_code,\n",
      "                 response.reason,\n",
      "                 response.url,\n",
      "                 response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "\n",
      "        try:\n",
      "            self.expiration = self._get_token_expiration_time(\n",
      "                created_bigip, expiration_bigip\n",
      "            )\n",
      "        except iControlUnexpectedHTTPError:\n",
      "            error_message = \\\n",
      "                '%s Token already expired: %s for uri: %s\\nText: %r' % \\\n",
      "                (response.status_code,\n",
      "                 time.ctime(expiration_bigip),\n",
      "                 response.url,\n",
      "                 response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])\n",
    "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MESSAGE_CALLBACK = lambda x: None\n",
    "def handle_simple_responses(\n",
    "      self, timeout_ms=None, info_cb=DEFAULT_MESSAGE_CALLBACK):\n",
    "    \"\"\"Accepts normal responses from the device.\n",
    "\n",
    "    Args:\n",
    "      timeout_ms: Timeout in milliseconds to wait for each response.\n",
    "      info_cb: Optional callback for text sent from the bootloader.\n",
    "\n",
    "    Returns:\n",
    "      OKAY packet's message.\n",
    "    \"\"\"\n",
    "    return self._accept_responses('OKAY', info_cb, timeout_ms=timeout_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = (\n",
    "    raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "    for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "gen = (i for i in range(10))\n",
    "print(list(gen))\n",
    "print(list(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "        for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    dataset = raw_datasets[\"train\"]\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = dataset[start_idx : start_idx + 1000]\n",
    "        yield samples[\"whole_func_string\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your tokenizer from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how to build your tokenizer from scratch, we have to dive a little bit more in the ðŸ¤— Tokenizers library and the tokenization pipeline. This pipeline takes several steps:  \n",
    "\n",
    "- **Normalization:** Executes all the initial transformations over the initial input string. For example when you need to lowercase some text, maybe strip it, or even apply one of the common unicode normalization process, you will add a Normalizer.  \n",
    "\n",
    "- **Pre-tokenization:** In charge of splitting the initial input string. That's the component that decides where and how to pre-segment the origin string. The simplest example would be to simply split on spaces.  \n",
    "\n",
    "- **Model:** Handles all the sub-token discovery and generation, this is the part that is trainable and really dependent of your input data.\n",
    "\n",
    "- **Post-Processing:** Provides advanced construction features to be compatible with some of the Transformers-based SoTA models. For instance, for BERT it would wrap the tokenized sentence around [CLS] and [SEP] tokens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other directions: \n",
    "- **Decoding**: in charge of mapping back a tokenized input to the original string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huáº¥n luyá»‡n má»™t tokenizer má»›i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ä add',\n",
       " '_',\n",
       " 'n',\n",
       " 'umbers',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'Ä b',\n",
       " '):',\n",
       " 'ÄŠ',\n",
       " 'Ä ',\n",
       " 'Ä ',\n",
       " 'Ä ',\n",
       " 'Ä \"\"\"',\n",
       " 'Add',\n",
       " 'Ä the',\n",
       " 'Ä two',\n",
       " 'Ä numbers',\n",
       " 'Ä `',\n",
       " 'a',\n",
       " '`',\n",
       " 'Ä and',\n",
       " 'Ä `',\n",
       " 'b',\n",
       " '`',\n",
       " '.\"',\n",
       " '\"\"',\n",
       " 'ÄŠ',\n",
       " 'Ä ',\n",
       " 'Ä ',\n",
       " 'Ä ',\n",
       " 'Ä return',\n",
       " 'Ä a',\n",
       " 'Ä +',\n",
       " 'Ä b']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''\n",
    "\n",
    "tokens = old_tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'Ä add', '_', 'numbers', '(', 'a', ',', 'Ä b', '):', 'ÄŠÄ Ä Ä ', 'Ä \"\"\"', 'Add', 'Ä the', 'Ä two', 'Ä numbers', 'Ä `', 'a', '`', 'Ä and', 'Ä `', 'b', '`.\"\"\"', 'ÄŠÄ Ä Ä ', 'Ä return', 'Ä a', 'Ä +', 'Ä b']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(example)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(old_tokenizer.tokenize(example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'Ä Linear', 'Layer', '():', 'ÄŠÄ Ä Ä ', 'Ä def', 'Ä __', 'init', '__(', 'self', ',', 'Ä input', '_', 'size', ',', 'Ä output', '_', 'size', '):', 'ÄŠÄ Ä Ä Ä Ä Ä Ä ', 'Ä self', '.', 'weight', 'Ä =', 'Ä torch', '.', 'randn', '(', 'input', '_', 'size', ',', 'Ä output', '_', 'size', ')', 'ÄŠÄ Ä Ä Ä Ä Ä Ä ', 'Ä self', '.', 'bias', 'Ä =', 'Ä torch', '.', 'zeros', '(', 'output', '_', 'size', ')', 'ÄŠÄŠÄ Ä Ä ', 'Ä def', 'Ä __', 'call', '__(', 'self', ',', 'Ä x', '):', 'ÄŠÄ Ä Ä Ä Ä Ä Ä ', 'Ä return', 'Ä x', 'Ä @', 'Ä self', '.', 'weights', 'Ä +', 'Ä self', '.', 'bias', 'ÄŠÄ Ä Ä Ä ']\n"
     ]
    }
   ],
   "source": [
    "example = \"\"\"class LinearLayer():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weight = torch.randn(input_size, output_size)\n",
    "        self.bias = torch.zeros(output_size)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.weights + self.bias\n",
    "    \"\"\"\n",
    "print(tokenizer.tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer nhanh vÃ  cháº­m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "encoding = tokenizer(example)\n",
    "print(type(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'My', 'name', 'is', 'S', '##yl', '##va', '##in', 'and', 'I', 'work', 'at', 'Hu', '##gging', 'Face', 'in', 'Brooklyn', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(encoding.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sylvain'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = encoding.word_to_chars(3)\n",
    "example[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃªn trong pipeline token-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline lÃ  má»™t nhÃ³m cÃ¡c model Ä‘Ã£ Ä‘Æ°á»£c code sáºµn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 17:07:12.617401: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 17:07:13.178742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.99938285,\n",
       "  'index': 4,\n",
       "  'word': 'S',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99815494,\n",
       "  'index': 5,\n",
       "  'word': '##yl',\n",
       "  'start': 12,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99590707,\n",
       "  'index': 6,\n",
       "  'word': '##va',\n",
       "  'start': 14,\n",
       "  'end': 16},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99923277,\n",
       "  'index': 7,\n",
       "  'word': '##in',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9738931,\n",
       "  'index': 12,\n",
       "  'word': 'Hu',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.976115,\n",
       "  'index': 13,\n",
       "  'word': '##gging',\n",
       "  'start': 35,\n",
       "  'end': 40},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9887976,\n",
       "  'index': 14,\n",
       "  'word': 'Face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9932106,\n",
       "  'index': 16,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\")\n",
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thá»±c hiá»‡n nhÃ³m chÃºng láº¡i vá»›i nhau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"simple\")\n",
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 17:07:18.188945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.209848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.210021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.210879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.211056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.211207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.284694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.284883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.285040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.285179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22494 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "All the weights of TFBertForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n",
      "2024-05-17 17:07:19.731955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForTokenClassification\n",
    "\n",
    "model_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "inputs = tokenizer(example, return_tensors=\"tf\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19)\n",
      "(1, 19, 9)\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"].shape)\n",
    "print(outputs.logits.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChÃºng ta cÃ³ má»™t lÃ´ vá»›i 1 chuá»—i gá»“m 19 token vÃ  mÃ´ hÃ¬nh cÃ³ 9 nhÃ£n khÃ¡c nhau, vÃ¬ váº­y Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh cÃ³ hÃ¬nh dáº¡ng 1 x 19 x 9. Giá»‘ng nhÆ° Ä‘á»‘i vá»›i pipeline phÃ¢n loáº¡i vÄƒn báº£n, chÃºng ta sá»­ dá»¥ng hÃ m softmax Ä‘á»ƒ chuyá»ƒn Ä‘á»•i cÃ¡c logits Ä‘Ã³ theo xÃ¡c suáº¥t, vÃ  chÃºng ta láº¥y argmax Ä‘á»ƒ nháº­n dá»± Ä‘oÃ¡n (lÆ°u Ã½ ráº±ng ta cÃ³ thá»ƒ láº¥y argmax trÃªn logits vÃ¬ softmax khÃ´ng thay Ä‘á»•i thá»© tá»±):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "probabilities = tf.math.softmax(outputs.logits, axis=-1)[0]\n",
    "probabilities = probabilities.numpy().tolist()\n",
    "predictions = tf.math.argmax(outputs.logits, axis=-1)[0]\n",
    "predictions = predictions.numpy().tolist()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-MISC',\n",
       " 2: 'I-MISC',\n",
       " 3: 'B-PER',\n",
       " 4: 'I-PER',\n",
       " 5: 'B-ORG',\n",
       " 6: 'I-ORG',\n",
       " 7: 'B-LOC',\n",
       " 8: 'I-LOC'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "á»Ÿ Ä‘Ã¢y Ä‘á»‹nh dáº¡ng B-PER chá»‰ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n tÃ¡ch 2 tá»« khÃ¡c nhau, dÃ²ng thá»© 2 mÃ u há»“ng Ä‘Æ°á»£c sá»­ dá»¥ng trong hoÃ n cáº£nh nÃ y (cÃ²n Ä‘á»ƒ dá»… hiá»ƒu vÃ  phÃ¢n biá»‡t rÃµ hÆ¡n ta sáº½ nhÃ¬n vÃ o dÃ²ng thá»© 3)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABscAAAGBCAYAAAA6xm9AAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAGx6ADAAQAAAABAAABgQAAAADNGltYAABAAElEQVR4AezdB7wcRf0A8EkCAUIJvUnvINJBlK4oIEhTpBcRAVEUUBABBRTFgihFEBVFRUVFBKTJHwULKiJdpEpHaoAECBBI8t/ZuOe9d/eSe3l392b3vusnvLu92dmZ7+/n3s3N7e6IqdkSLAQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgR6QGBkD/RRFwkQIECAAAECBAgQIECAAAECBAgQIECAAAECBAjkAibHJAIBAgQIECBAgAABAgQIECBAgAABAgQIECBAgEDPCJgc65lQ6ygBAgQIECBAgAABAgQIECBAgAABAgQIECBAgIDJMTlAgAABAgQIECBAgAABAgQIECBAgAABAgQIECDQMwImx3om1DpKgAABAgQIECBAgAABAgQIECBAgAABAgQIECBgckwOECBAgAABAgQIECBAgAABAgQIECBAgAABAgQI9IyAybGeCbWOEiBAgAABAgQIECBAgAABAgQIECBAgAABAgQImByTAwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAj0jYHKsZ0KtowQIECBAgAABAgQIECBAgAABAgQIECBAgAABAibH5AABAgQIECBAgAABAgQIECBAgAABAgQIECBAgEDPCJgc65lQ6ygBAgQIECBAgAABAgQIECBAgAABAgQIECBAgIDJMTlAgAABAgQIECBAgAABAgQIECBAgAABAgQIECDQMwImx3om1DpKgAABAgQIECBAgAABAgQIECBAgAABAgQIECBgckwOECBAgAABAgQIECBAgAABAgQIECBAgAABAgQI9IyAybGeCbWOEiBAgAABAgQIECBAgAABAgQIECBAgAABAgQImByTAwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAj0jYHKsZ0KtowQIECBAgAABAgQIECBAgAABAgQIECBAgAABAibH5AABAgQIECBAgAABAgQIECBAgAABAgQIECBAgEDPCJgc65lQ6ygBAgQIECBAgAABAgQIECBAgAABAgQIECBAgIDJMTlAgAABAgQIECBAgAABAgQIECBAgAABAgQIECDQMwImx3om1DpKgAABAgQIECBAgAABAgQIECBAgAABAgQIECBgckwOECBAgAABAgQIECBAgAABAgQIECBAgAABAgQI9IyAybGeCbWOEiBAgAABAgQIECBAgAABAgQIECBAgAABAgQImByTAwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAj0jYHKsZ0KtowQIECBAgAABAgQIECBAgAABAgQIECBAgAABAibH5AABAgQIECBAgAABAgQIECBAgAABAgQIECBAgEDPCJgc65lQ6ygBAgQIECBAgAABAgQIECBAgAABAgQIECBAgIDJMTlAgAABAgQIECBAgAABAgQIECBAgAABAgQIECDQMwImx3om1DpKgAABAgQIECBAgAABAgQIECBAgAABAgQIECBgckwOECBAgAABAgQIECBAgAABAgQIECBAgAABAgQI9IyAybGeCbWOEiBAgAABAgQIECBAgAABAgQIECBAgAABAgQImByTAwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAj0jYHKsZ0KtowQIECBAgAABAgQIECBAgAABAgQIECBAgAABAibH5AABAgQIECBAgAABAgQIECBAgAABAgQIECBAgEDPCJgc65lQ6ygBAgQIECBAgAABAgQIECBAgAABAgQIECBAgIDJMTlAgAABAgQIECBAgAABAgQIECBAgAABAgQIECDQMwImx3om1DpKgAABAgQIECBAgAABAgQIECBAgAABAgQIECAwCwICPSUwZXIIE+4L4bXnQ3j9xRCmvN5T3S9dZ0fOGsKs84Qw27whjF0xhBGjytUF+VaueMm3csWr7K0tc745tpUr+8qca+WS1toqCDi+lSuKZT++yTf51k0B+dZN7aHvy/Ft6IZqaF2g7PnWek+VJNAgMGJqtjSstYJAFQVefjyEcbeHMOdCIcwyW/Zv9hDiG4AlXYE4efnGq9m/SSG8/FQIC6yZxe9N6ba3vmXyrV6jHI/lWzniVJVWljXfHNvKl4FlzbXySWtx2QUc38oXwTIf3+SbfOumgHzrpnZ79uX41h5HtbQmUOZ8a62HShEYUMDk2IA0XqiUwIsPZpMr2eTY2CUq1a2e68z4x7LJsSVDmHvptLsu39KOT6utk2+tSinXDoEy5JtjWzsiPfx1lCHXhl9JC3pNwPGtGhEvy/FNvsm3bgrIt25qd25fjm+ds1Vzo0BZ8q2x5dYQGLSAe44NmswGpRN4KZtQMTFWurA1bXCc3Hz5kWnxbFoggZXyLYEgtKkJ8q1NkKppSSD1fHNsaymMpSiUeq6VAlEjKyXg+FadcJbh+Cbf5Fs3BeRbN7U7uy/Ht876qr2vQBnyrW+LPSMw0wImx2aazoalEIjX1X7uDmeMlSJYLTZybHbm2LjbQpg6pcUNulhMvnURu0u7km9dgrabXCDVfHNsq16Cpppr1ZPWo9QFHN9Sj9Dg25fy8U2+DT6eqW8h31KPULXaJ9+qFc/Ue5NyvqVup32lEjA5VqpwaeygBcbfl12Gb5FBb2aDxAViTMffn14j5Vt6MWlHi+RbOxTV0apAivnm2NZq9MpVLsVcK5eg1lZBwPGtClFs7EOqxzf51hirKqyRb1WIYnn6IN/KE6sqtDTVfKuCrT4kI2ByLJlQaEhHBF5/IYRZZu1I1SodRoFRo0OY9PwwNmCAXcu3AWBKvlq+lTyAJWt+ivnm2FayJGqxuSnmWotNV4xA2wQc39pGmVRFqR7f5FtSadK2xsi3tlGqqAUB+dYCkiJtE0g139rWQRURCMHkmCyotsCkCdnk2OzV7mMv9m7WLKaTxqfXc/mWXkza0SL51g5FdbQqkGK+Oba1Gr1ylUsx18olqLVVEHB8q0IUG/uQ6vFNvjXGqgpr5FsVoliePsi38sSqCi1NNd+qYKsPyQiYHEsmFBrSEYEpr2dTwM4c64jtcFYaYxpjm9oi31KLSHvaI9/a46iW1gRSzDfHttZiV7ZSKeZa2Qy1t/wCjm/lj2GzHqR6fJNvzaJV/nXyrfwxLFMP5FuZolX+tqaab+WX1YOEBEyOJRQMTSFAgAABAgQIECBAgAABAgQIECBAgAABAgQIEOisgMmxzvqqnQABAgQIECBAgAABAgQIECBAgAABAgQIECBAICEBk2MJBUNTCBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIEOitgcqyzvmonQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBBISMDkWELB0BQCBAgQIECAAAECBAgQIECAAAECBAgQIECAAIHOCpgc66yv2gkQIECAAAECBAgQIECAAAECBAgQIECAAAECBBISMDmWUDA0hQABAgQIECBAgAABAgQIECBAgAABAgQIECBAoLMCJsc666t2AgQIECBAgAABAgQIECBAgAABAgQIECBAgACBhARMjiUUDE0hQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBDorIDJsc76qp0AAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQCAhAZNjCQVDUwgQIECAAAECBAgQIECAAAECBAgQIECAAAECBDorYHKss75qJ0CAAAECBAgQIECAAAECBAgQIECAAAECBAgQSEjA5FhCwdAUAgQI9ILATTffEW686bZe6Ko+EiBAgAABAgQIECBQJ/D4f54M1/3xb+HFF1+qW+shAQIEqiFw730P5Me4yZMnV6NDekGg4gImxyoeYN3rDYH4pvuPm2/P34DjQOPpp5/tjY7rZSkFDjz0mLDPAZ8sZds1mgCB3hK47IrfhRFjlg3X/P7PvdVxvSVAgAABAh0SuOiS34Yttt493JN9gVwsV1x1bf5+G/9aCBAgUGaBU08/Nz/GvfLKq2XuhrYT6BkBk2M9E2odrarADTfeGpZeeeOw/sY75G/AcaCxyDLrh512PShMmPBiVbutX20U+NXFV4Z3vmfPWo0fPexz4eSvnVV7Xjz4/g9/EXbe7eDiadhr/8PDWd/5ce25BwRmJLD/wUeFb5xxbq1YPHbdfsddtefFg/ft/pEQ861Y5l1sjfDwI48VT/0lMEOBoz/7lXDsCafUyq230fbh2j/8tfa8eHDwoceGr33jO8XTsPKa78h/bFKs+MOfb8gf/ukvNxar/CVAgEApBQ445Oh88uHDHz26lO3X6OEXiDlU/zlumVU2Dnf88+6Ghr1/j0PCD370y9r6+RZfMzz62H9qz5s9KN5n//zXfzR72boeEIjjyj0/eFitp/3HA8ULcZx6yCc+WzwNW267V7jokqtqzz0g0IrAa6+9lr8nxh/B1f9bcMl18vx67rkXWqlGGQIEKiBgcqwCQdSF3hV4+eWJYftdPhxmm210+MX5Z4Zxj90SJo67Kxz6kX3Dxb+5Olx59R96F0fPWxZ46OHHwjJLL1Er/+DDj4Zll1my9rx48FA2OdGn3ENZuaUbyxXl/SXQX6A+1+IZr488+nhYacXl+hcL9bn2/PPjw0svTQxLL/W/HG3YwAoC/QTyXKvLmfqcqi86bf2baqvuve/BsPyyS9eef+1Lx4Rrr/pZOPG4w2vrPCBAgEDZBF5//fX8y+P11lkj/Oriq4JLPZUtgmm0t/5z3BtvvJFNeD0Rll/uf++ZRSvry73wwoT8c9ybFl+0eLnp3xOPOyx/vz3h2E80fd3K6gvU503s7YBj0v5jV2PS6idHB3u41bs2zY898fN+/HfAfruGc879aVh3o/cGZ351EF7VBBISMDmWUDA0hcBgBX7/h7/kl1A85shDwi47bxvmn3/eMMccs4fTv35CeOz+v4Zd37/dYKtUvgcF+n+J/GAcYDSbHGs2EGlSrgcJdblFgfpci48XWGC+MPvsszVsXT84jvm49FL/m7xoKGwFgSYC9Xnz6quvhXHjng9LLbl4Q8mYa0stOS2/4q/aYz7ON9/YPuU233TDPs89IUCAQNkEfvt/fwzxxyZfPOFT+d/43EJgsAL5e+t/3zMfefQ/Yd555wljxszRUE2c1Cjec+M28fHIkf/76mnKlCn5NlOnTq1tO3r06BDfb+NfS28K1I8TosADDz7SfEza7webDz/yeFhuWT/Y7M2sGXqvF11kofzYE48/8d+Xv/Dp8KnDPhxiPsZblszMMmLEiHyz+uPezNRjGwIEuiPwv08o3dmfvRAg0EaByZOnDSxenvhKQ60z+nVewwZW9JzAvx94OP/Ad9sdd4eXJ06s3bPu7nv+HR57/Ilw57/uzU3uuXfaDWX/mT0fP/7FvNzvrr0+PPHk03m5+PqVv70ubL7VbuFvf7+lwfHyK3+fv3b/vx/KXxsRRvQZIDdsYEXlBP7+j1vzvIlfkDySTUDEgcZlWV7MP9+8+eMnn3wm7/Nf/nZTfm+neBmLOCCO5a76vz+EeeaZK3/87LPPheNO/HrYavt9mhp9+rgv97n0Z6wvXjI0Xipj7KJrhHdtt3f4zxNPNd3WymoI3HLrnXmuPJDl2pNPPZM//sWvLg8LLjh/+NP1N+ZnK8ae3njTbflr8QuVx//zZP74N9n9xeIAOeZdkSe/v+4v+fEr5nCx/PrS34atd9g3f3rmt38Y4mU/Y45t/M5dQjx+WggQIJCawM+z4+D6664Z3r3lJvmXzb+46PLUmqg9CQsUn+PihFj957j55h2bv2fWf467+po/hfg5Ln7mi++nV159XZh77jnzx888My7vZfGFcfEFclz5hz/dkL/fxs9ult4SuOvu+/P8uCv7DPX8C+Pzx1dlV8CJ4844QXHf/Q/mIPESnjGn7rv/ofDMs+Pyxxf++or8Kjq33PavPOfq5eL9Yt+z0wfD3AuvHuZZ5C3hq6ee03Am0ElfPiO/pHYss+m7dg3/vPOe+io87lGB9dZ5S97zNya/0UcgTuyf/d3z81uaxJzZZsf98mNXn0J1T+IPAI45/mthlrlXyMcKG2yyY4j5biFAIC2BWdJqjtYQIDAYgY02XDc/Uyx+IbxcdgbPdu9552A2V7bHBX57zR9D/NI4fkkcJ8fixFZx6YAzzv5h2HTjDcLnVzsiXHLZ/4UrfnttiF86zzrLLOF3110fXnzp5fwMi5O+cmZ4z1ZbhAP33z3E+9+d+8Ofhw03WLuP7Hnn/yobrDwWVlh+mT7rPekdgTPO/lG49783Xf/mmd/PO/7Y40+Gl15+OZz4pdPCUYcfFLZZdPNwyje/Gx7OLrUYf4X8xa9+Ky8XB8VvvDE5L/f5zx6eH+u+mOVdHDRv/e7Naogxd79xxvfzS2HElfG+BfH+eTts965wfHaJnvj6Wd85Px/E3HbDlbXtPKiWwLnZvepuue3OECdSv/+jafete+rpZ0MczJ7wxW/mx6o9dn1Tngv/uuu+EM8qO/2s83KEx//zVJiY5Uksd8THDwjbb7tIiNvGL+zGjfvffQdi7sazLvbY7xPh7nv/HT7x0Q+Gm2+5M5vw/V3YabeDwl23XFMtVL0hQKDUAvGSivGzXLzSRFzev9M22SWjfha++63Xw6yzzlrqvml8dwTi57j4Y7g4mdX/c1x8z/z0EQfXPsfFyxXHK5nEMUJcis9xsVy8RPFmCy3QtNFxsiN/v33u+aavW1ldgXj/699lP0aKE1PTbg1xXRif3Tt9zjnH5J//42f5wz62bPjpLy4Nf73h5nwS7OcXXh5GjboyjMsmYmeddZa83J677hAO+OBuOVSc9Prs508NG6y3ZvjkJw7IfwgVvzNZY/VV8vFDvD3FZu/eLTzw0CN5Xi6y8ILhO9//WXjbFu8L/7r56rDkEo1XG6huBPSsv8AvL7oiv8LJ5pv87+oR8VKy733/AfkYdPttt8y/K7nm2j+HLbbePZz5jRPDIQfu3b+asP4mO4TFFl04HHPUIdl3Kf/KxwqxjphjzpJt4LKCwLAJmBwbNno7JjB0gYWywcWlv/xu2Hn3j+Rv1HEy42MH7xN2fO+7DXaHzlv5GuIHuPhvzAKrhl/99Oz8fmLXZzfB3v/go8J1v72g1v+jjjgo+6L4Q2H02JXCVZf8ML/k2BVXXZt9gXxan3Lv3+k94YJfXhbO+uYXavk3adKkcPlVv8/vg1dUODVMzb+oLp77W32BH597av6FxyGHfTa/lnvs8Wc+99UwadLr4etfPrYGcNEF3w6XXn5N+PIpZ9fKxRtux7N5PnfMx/Nya6/55nDwx48Lv8x+KVo/ORYH0/ELwD132yEvt0uWj9tuvUWfe5Utvtgi4bAjP59PbMTry1uqJxAHp/EXmZtnA9XiOPaNM84Nt97+r/DD73691uEfnPO1/AcB+xzwyVq5+MVd/LV7vDRxK0scJN/8l8tqReNZjXHi9vY77gprvGXV2noPCBAgMJwC8azYF198Kfsx0+Z5M7Z59+bha9/4TvbDp+vyH5AMZ9vsuxwC8XPcH/98Q/75q3hvjWdDxB+YnPqV42qdiJ/jfnPFNeHkr51de2+NP1RaOBuzxh8qFUuzyyoWl1icMmVqUczfHhE47uhDswmsD+dj0t9d8ZN8cjVOmMUfL8V7QBXLyZ8/Kj+zf+mVNw5/uPqCfLL2+9mPouIY4NILv1cUC/EKJ3FibJed35Pdl33aj+3ii1864cgQvz+Jy1HHfjncdMsd4fa/Xxnekk2YxeUD79s2P4vsK18/J5/syFf6T+UFbss+t5+Yfa9RLNf96W/hzuwHdBf+5KzsrNe5itX5cS3+OPPs008KBx+wZ74+jgV2+MCB4dAjTgibbrRBWP3NK9fKxwex3McP2a+27kvZjz+PPeGUcN6PfxUO/NDutfUeECAwvAIuqzi8/vZOYMgCW75j43DLXy8LH/nwXuHm7MyeD+z1sbDw0uuFb3/vJ0OuWwXVF4j3n4gD2yXeNO0m2fFyKcssvURDx+OZEvX34omXVFlm6Wn36SkKH7j/btkNt1/OJzeKdVdmHyDjGTu777J9scrfHhV4JDsjrLj/RCSIvySuf16wNJTLfoFcX26uuebMfgDwrnwgPHny5GKzEH/ht8SbFgsbvW29fF0c/C69VN9cXnKJxfLX7rjz7tp2HlRPIF4qcam6X/wOnGv/6ZNbA5UbSOjIww/s89Jaa0ybEHswy20LAQIEUhH42S9+k/9yvZi0jz+mm2eeubMfNP0mlSZqRwkE+o8R4vP6z2dFF/qv779dUc5fAvUC8TNYvAR2POswLtM+k/Uda8b1RT4Vl+SMY9Li3rHx9bh865wf53/PPu2k/G/xn2JiLI5Nzzv/wvDRg/apTYwVZbbd+h3h2j/+tXjqbw8I5JdhzybE4qTYT39xSX4Z9gkTXswnZ+MPS4rlnHN/GpZfbulw0If2KFaFWbKr6nw5m7SNE/7xzMNiKSb7999nl2JV/vfQj+ybb3Np9iMCCwEC6Qg4cyydWGgJgZkWiG/SZ532hfwMjB//9Nfh0E+eED6SnVkxW3ZD4w/2e0Oe6Z3YsHICf7r+7+H+fz8c5p9/3vDnv/wj798f//z3/ANbvJ57vOxEfC0+vvOue8OCC8yfP44F4yUt4hJfW2etN+dfsmyS/VpqlZWXDz+54JLwvh23yV+Pv+SL69Zac7X8efyPe47VKHriwQsvTMjP2ok5NmrUqFoO/evu+8KqK6+Qn1G22SZvzS+DF+9r97e/3xrigCLmVlzuve/B7JIpz4d4VmMx8bXX7jvlk2HX/P76EM8Ai4PceA+zeNmU+iXetyyeNXR9dv+KeFnQYomXYLFUTyBeIufGm27Pv9SYbbbRtRyK96GI9w6IORVvtB0HvPHHJPHyTaNGjayVuyO7nE+cQC3KDVZozjFj8k0mNrkP6GDrUp4AAQLtEIjHxXjJ13ds/vbasS7WGz/jxUstxvfP4svoduxPHdUT6PM5bmTfz3ErZpdMj++l9Z/j/nrDLX0+x92TXVb7uedf6PM5rtk9x4rJjpEjR1QPUY+mKxA/d9186z/DvGPnqR2n4uX642Vf42vxM1z8cVx8HO8fO9dcY2rlbrr5n2GxxabdLzZe2j/+mDNeLSCOPRdYYL6m+433wY6f1eKtAuIl8eqXOPn2THZpbkvvCGz9rs1CvKJEscQfDsf3zb0/dER+tuxPfjDtyhLxHsX77LlzfsZiUTb+jWcexvyMZ6AVS3E8K/4W6+OZaPGHyPGHfBYCBNIRMDmWTiy0hMCQBeLgNp6eHQcoG2+5S/jS184yOTZk1epWsPUO++UDg9jD/gODeNnEKy8+L79sXf1r9Y/jdvFsnb9ed1HtPmPx0gHxsnVxID3vvPPkZ/d8KrtMhqV3BeL9n96xzf9+YXd5NolVLLffcXc+YfbGi/eHP2eTXzvtelDxUn4/vOLJpz7zpXyidtxjt+Sr4nXe55tvbLjw4ivyybH4BV+8pOJeu+1YbJJfD36XvT4aVltlhXDYR/cP6669er6vVdfeMv/SplbQg8oIPPjQo32OZfXHq/hjgDhR+tzjt4Y4MVv/2tXX/KlmcPMt/wwnffnMMPmlf4f45V3xy8/ibyxYPC7+FhsXz4u/xXp/CRAgMFwC8f0xftEXP9fFf/2XeMnFeCkxC4GBBOJEQ/17ZvzSuFjiD49Gnjwyf8+c3ue4Iz59Uv65Lb4Hx8VlFQtBf+OZOfX5Vf846vz055dkV8m5PJvomne65b77/QvCA//6Y1g2uw97vDd2vJTnQEu8v2xc4g+M48Rb/yX+wNjSuwJxgjXeLiL+8PL8n12cXZb9lPz+7FFk7rn+d5nFeqH55h2b5139uoEexwmzOG61ECCQjoDLKqYTCy0h0DaBlVdaLmzy9vWzs4IeCvWXHWvbDlRUCYGXn/1XOOPUE8Ku798uTJ34YP7vve95Z/7Lqfi8uJ9TfPzFEz6VX0KgKBfPEvvVz87Ot4m/0iuWvbMzeuJy0SVXZWej3ZhPku2R3Ry5/+LL4/4i1X2+xWZvy/MknuH1o+99PX885eUH8jMUn374HyFOjMUl3isx5lfMp0uyeynGxxPH3ZX/Ou/1CfeFYmKskIqX6rz4N/+XP41f7q226orhzautVLwc9j3wU2GVlZYPN/zx4vxXfvG1ONixVFcgXuc/5k08szDey644Xi2c3WT9zpuuzp/HSdV4BmJ8LR7vvnfWl/PHRU4+dv9f8+fFr9qrq6VnBAj0gkC8dGI8eyIe44pjYvz72gv3hDFj5nBpxV5IgiH2MZ5xHXMmjgvivTvj4+I986mHbswnxuIuis9xb3vrOk0/xxUTY0Nsjs0rJhDPpIk5deynP5bfmyk+jv/WX3fNcMWvf5A/jmeBLZldLjuuj/dXj/chLsqtuMKy4frfX5g/jxNjcVls0YXDv7OrRwy0LLrIgvlLK6+4XDjh2MMa/n3myEMG2tT6CgoM9L3E6NGz5t+lxR/9xvtfx0soPvBQY17FH6A8Gi/vWXdJ96LO4m/BFm9BES8ZutyySxWr/CVAIAEBk2MJBEETCMyswJXZjbT/73f/+8V7UU+8MWj8ld/SS70pP1OiWO8vgf4CDz38eJ97jD2c3Req2T3H4qn/9evjfaGWXXraAKS+zngZxvjF9A9+fGH41cVXhbeuv1b+C776MvFx/0sM9H/d8+oJxIFAkUOPPf5EdqmUWWo3xa7v7UPZPcaWyY5dcfn3Aw/XBiP1ZeLjPXfbIb8UY7zc4pVXXxf22WPnWpH4K9Snn342bPz2afcfK164M7tsY1zkXyFSzb/1uRYvGRZzofjCpL7HD9Ud12KZuCy+2CL1RTwmQIBAaQXie+FV//fHsPMOWzW8743OzoyIl5KKv4yvv6dKaTur4R0XmPbeOu3zWfE5Lv74pP+Sl6v7HLdINhERv1S2EJieQP1nt1huoDFpPnb97z2F48RDvGpAMb4o6n/PVpvnY4Qzzv5hsarP33hP4njZ//MvuDg851LrfWw8mSbwxBNPZ2dbX5ffzzreCy9e4nPLd2yUX5kkXmWifjn5lLPyp/FHd8VSjDXjOKR++fpp38vPGvvAzs7YrnfxmMBwC5gcG+4I2D+BIQj89BeXhq223ze8ddMdw2c+99UQL1f2u2uvDztmlyaLHxTjDT8tBKYn0H8g0n+yrNi2/wAlTpY1+7I5lj9w/93ys8Yu/PWVodlZY/E68c8/Pz7ED52W3hCIg9fiBtqxxwPlT5zYf+qpZ0P8FWhRrv+AN38h+8/bN1w3/xXpkcecnOfT7h94b/FSiL9CjV/Y/Phnvw7xRwRxMve4E78e9j7giFoZD6orMO2LuSXyDsa8izdgb3ZPnXh2dZFfxTGuGMxWV0fPCBDoFYH4OSxeummn927VtMs7bPeu/PV46UULgRkJPPrYE7WzHeLnuGZnPkyaNCk8+dQztdcee/zJsPyySzdUPXd2f564xPvKFlc5Kd5/R2WXNLb0nkD9mLT4YVPxGa1eI/8RXXbPprjEMUNc4pli9csRh34oxEnZj2f3Yf/Ep07Mz+q5LLvKxJbb7hXOPe/nedHTvnb8tB/SZbeiiPfNi2f/xHtKHXvCKeH2untH1dfrcTUF4jEr3s8u/vtZ9v3a4Ud9Iay6zpb5vRLjVU+K5eQTj8onybbIbhfwgx/9Mh9ffvLoL4bPf+n0/L5je+8x7Qo6Rfn4d9N37xp+m/1I5aqr/xDi5WVP+OI38ytYxHuXWQgQSEfAJ490YqElBAYt8ONzTw3f/dbJ4cHsjIwvn3J22O59H8o/9MWBxmmnHB8+6V5PgzbttQ3qv0SOlwyYMOHF2pfF9Rb1v8qLlw2Ikw/xnmLNlnjJxXhpz/ir0l2y63X3X7bcYqPwxJNPZ5O4B/Z/yfOKCsTB6+uvv5H/+i52sf+ZiEW3//3AI3leFRMZxYRF8Xr/v/vutXP46w0354OMpZac9mvmosxPvv+NMPtss4X37PTBsPTKG4d/3nlPuPkvl027LEs2WWeppkCcYI1fbhRfqOS59t9fGNf3OP5SOH4REs+wjstAOVm/jccECBAok8AFF/4mzDPP3OGdW7y9abN3fO+78itMXHDhZU1ft5JAIfDMM+PCa69Nqp1dHSfKivfPokz8G99L4+WL5/rv5NeDDz/atNymG2+Qn0221/6HZ7cBeLi+ijA1+5+l9wTqx6Txh03xR27FeKBeI15VovYZL17JJLuUYjGxWpSL2/7u8p/kl1s//azzwlIrbRTe+/4Dwn+eeCqstcZqebF3b7lJfouAZ8c9Hzbfarcwx/yrhCVWeFv4/XV/ySZspxRV+dsDAnHyKt7rLv47+OPH5VdgOuhDe+SXZI+3ByiWeHnPq3/zozDXnGPC/gcflY8vTz39eyF+9/G7y88P8Yzs+mW9ddbIb0ux/S4fDtvsuF+Iubjf3u/P63D59nopjwkMv8CI7NfcPn0Mfxy0oFMCj1wewkJv7lTtydQbf6V3w43TbnC8+mor54OSZBrXqYY8c2cISyV2OnqP5FsrIY1nM8YJtGuyD4rNlvgLvcUWXSislF3rvRSLfCtFmJo1Mt4sfvnllsq/IGz2epLrUss3x7Yk06QtjUot19rSKZUQGISA49sgsEpWNMXjm3yrJdE99z4Qnnr6mbDpxm+trSv1A/mWZPjij+jixO6YMbOHDdZbq2kb47g0fi06NvsxwdprleS7I/nWNJbdWBnPyI55NWXK1DBP9n3HOmuvPt3dPvvsc+Ffd98X1nzLqmHs2OY/Lp5uBSm8mGK+peCiDZURcPHnyoRSR3pZIP5KJf5ixUIgBYE//+XG8Pd/3BbO+84pAzZns00qMhAesIdeSEWgNIPcVMC0gwABAgQIECDQYYF4lYn4z0KgkwJve+s6M6zeuHSGRArUCcT7jw1mUj/es2ww5et25SEBAl0SMDnWJWi7IUCAQNUFbrzptvDMM8+FQw77bP6ru333el/Vu6x/BAgQIECAAAECBAgQIECAAAECBAiUUMDkWAmDpskECBBIUWCDTXbMm/XW9dcKF/zojBSbqE0ECBAgQIAAAQIECBAgQIAAAQIECBAIJsckAQECBAi0RWDqxAfDI9mNkZda8k1tqU8lBAgQIECAAAECBAgQIECAAAECBAgQ6ITAyE5Uqk4CBAgQ6E0BE2O9GXe9JkCAAAECBAgQIECAAAECBAgQIFAmAZNjZYqWthIgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECAxJwOTYkPhsTIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgUCYBk2Nlipa2EiBAgAABAgQIECBAgAABAgQIECBAgAABAgQIDEnA5NiQ+GxMgAABAgQIECBAgAABAgQIECBAgAABAgQIECBQJgGTY2WKlrYSIECAAAECBAgQIECAAAECBAgQIECAAAECBAgMScDk2JD4bEyAAAECBAgQIECAAAECBAgQIECAAAECBAgQIFAmAZNjZYqWthIgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECAxJwOTYkPhsTIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgUCYBk2Nlipa2Dl5g5KwhTHl98NvZIm2ByVlMR45Or43yLb2YtKNF8q0diupoVSDFfHNsazV65SqXYq6VS1BrqyDg+FaFKDb2IdXjm3xrjFUV1si3KkSxPH2Qb+WJVRVammq+VcFWH5IRMDmWTCg0pCMCs84TwhuvdqRqlQ6jQIzp6LmHsQED7Fq+DQBT8tXyreQBLFnzU8w3x7aSJVGLzU0x11psumIE2ibg+NY2yqQqSvX4Jt+SSpO2NUa+tY1SRS0IyLcWkBRpm0Cq+da2DqqIQHbuBQQClRaYbd5scmxSpbvYk52b/Fo2OTZfel2Xb+nFpB0tkm/tUFRHqwIp5ptjW6vRK1e5FHOtXIJaWwUBx7cqRLGxD6ke3+RbY6yqsEa+VSGK5emDfCtPrKrQ0lTzrQq2+pCMgMmxZEKhIR0RGLtiCC8/1ZGqVTqMAjGmY1caxgYMsGv5NgBMyVfLt5IHsGTNTzHfHNtKlkQtNjfFXGux6YoRaJuA41vbKJOqKNXjm3xLKk3a1hj51jZKFbUgIN9aQFKkbQKp5lvbOqgiAs4ckwNVFxgxKoT51whh/GNV72nv9G/8oyEssHYII0ak12f5ll5Mhtoi+TZUQdsPRiDVfHNsG0wUy1E21Vwrh55WVknA8a1K0ZzWl5SPb/JNvnVTQL51U7s7+3J8646zvUwTSDnfxIhAGwWcOdZGTFUlKjDXEiHMmf0b/0iiDdSslgViDOdcJvu3eMubdL2gfOs6ecd2mOfbUvKtY8Aq7iOQ+vHNsa1PuEr9pAzHtlIDa3zpBBzfSheyARuc+ntpbLh8GzB8pXuhDO+n8q10aTVgg+XbgDRe6IBAGd5PO9BtVfamwIip2dKbXdfrnhN4+T8hjLs1hDELhzDLbCHMOnt27uSsPcdQqg5Pfj27Z9yrIcTrHMfTueMZYylPjNXjyrd6jXI8lm/liFNVWlnWfHNsK18GljXXyietxWUXcHwrXwTLfHyTb/KtmwLyrZva7dmX41t7HNXSmkCZ8621HipFYEABk2MD0nihkgJTp2RnkN0XwqTns38TQpiSTb5Y0hUYOTqE0XOHMNt8IcyT3WMsxUspTk9Pvk1PJ73X5Ft6Malyi8qcb45t5crMMudauaS1tgoCjm/limLZj2/yTb51U0C+dVN76PtyfBu6oRpaFyh7vrXeUyUJNAiYHGsgsYIAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQKCqAu45VtXI6hcBAgQIECBAgAABAgQIECBAgAABAgQIECBAgECDgMmxBhIrCBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIEqipgcqyqkdUvAgQIECBAgAABAgQIECBAgAABAgQIECBAgACBBgGTYw0kVhAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECFRVwORYVSOrXwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAg0CJscaSKwgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBCoqoDJsapGVr8IECBAgAABAgQIECBAgAABAgQIECBAgAABAgQaBEyONZBYQYAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgUFUBk2NVjax+ESBAgAABAgQIECBAgAABAgQIECBAgAABAgQINAiYHGsgsYIAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQKCqAibHqhpZ/SJAgAABAgQIECBAgAABAgQIECBAgAABAgQIEGgQMDnWQGIFAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIBAVQVMjlU1svpFgAABAgQIECBAgAABAgQIECBAgAABAgQIECDQIGByrIHECgIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAgaoKmByramT1iwABAgQIECBAgAABAgQIECBAgAABAgQIECBAoEHA5FgDiRUECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQJVFTA5VtXI6hcBAgQIECBAgAABAgQIECBAgAABAgQIECBAgECDgMmxBhIrCBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIEqipgcqyqkdUvAgQIECBAgAABAgQIECBAgAABAgQIECBAgACBBgGTYw0kVhAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECFRVwORYVSOrXwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAg0CJscaSKwgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBCoqoDJsapGVr8IECBAgAABAgQIECBAgAABAgQIECBAgAABAgQaBEyONZBYQYAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgUFUBk2NVjax+ESBAgAABAgQIECBAgAABAgQIECBAgAABAgQINAjM0rDGCgIVFpgyJYRxL4TwyqshvDYphMnZc0u6AqOy6fvZRocwx+whLDBfCCNHpNvWZi2Tb81U0l0n39KNTRVbVuZ8c2wrV0aWOdfKJa21VRBwfCtXFMt+fJNv8q2bAvKtm9pD35fj29AN1dC6QNnzrfWeKkmgUWDE1GxpXG0NgeoJjH8xhCefDWHeOUOYdVQIo7Op4VHZX0u6ApMnhzDpjRBez/49/3IIiy0cwti50m1vfcvkW71GOR7Lt3LEqSqtLGu+ObaVLwPLmmvlk9bisgs4vpUvgmU+vsk3+dZNAfnWTe327MvxrT2OamlNoMz51loPlSIwsIDJsYFtvFIhgefGh/DSSyEsNLZCnerBrjydxXGebHJsvsTjKN+qkZzyrRpxLEsvypBvjm1lyabpt7MMuTb9HniVQPsFHN/abzocNZbl+CbfhiM72r9P+dZ+UzUOLCDfBrbxSvsFypJv7e+5GntRwD3HejHqPdbnF7Izxl40MVaJqC+cTYpNyGIZf/mW6iLfUo3M4Nsl3wZvZouZF0g93xzbZj62qW2Zeq6l5qU91RdwfKtOjMtwfJNv8q2bAvKtm9qd3ZfjW2d91d5XoAz51rfFnhGYeQGTYzNvZ8sSCMTraj+VXUoxHtgt1RCIsXzimRBSvCCsfKtGjtX3Qr7Va3jcaYFU882xrdOR7379qeZa9yXssdcFHN+qlwEpH9/km3zrpoB866Z2d/bl+NYdZ3uZJpByvokRgXYKmBxrp6a6khN49vnsHmNjkmuWBg1RYL7s0ooxtqkt8i21iLSnPfKtPY5qaU0gxXxzbGstdmUrlWKulc1Qe8sv4PhW/hg260Gqxzf51ixa5V8n38ofwzL1QL6VKVrlb2uq+VZ+WT1IScDkWErR0Ja2C7w6KYRZZ2l7tSocZoFZR4Xw6mvD3Igmu5dvTVAqsEq+VSCIJepCivnm2FaiBBpEU1PMtUE0X1ECbRFwfGsLY3KVpHp8k2/JpUpbGiTf2sKokhYF5FuLUIq1RSDVfGtL51RC4L8CJsekQqUFXssmUEabHKtcjGNMU5wck2+VS7W8Q/KtmnFNtVcp5ptjW6rZMrR2pZhrQ+uRrQkMXsDxbfBmZdgi1eObfCtD9gy+jfJt8Ga2mHkB+TbzdrYcvECq+Tb4ntiCwMACJscGtvFKBQQmZ/ccG5WdZWSplkCMaYxtaot8Sy0i7WmPfGuPo1paE0gx3xzbWotd2UqlmGtlM9Te8gs4vpU/hs16kOrxTb41i1b518m38sewTD2Qb2WKVvnbmmq+lV9WD1ISMDmWUjS0hQABAgQIECBAgAABAgQIECBAgAABAgQIECBAoKMCJsc6yqtyAgQIECBAgAABAgQIECBAgAABAgQIECBAgACBlARMjqUUDW0hQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBDoqIDJsY7yqpwAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQCAlAZNjKUVDWwgQIECAAAECBAgQIECAAAECBAgQIECAAAECBDoqYHKso7wqJ0CAAAECBAgQIECAAAECBAgQIECAAAECBAgQSEnA5FhK0dAWAgQIECBAgAABAgQIECBAgAABAgQIECBAgACBjgqYHOsor8oJECBAgAABAgQIECBAgAABAgQIECBAgAABAgRSEjA5llI0tIUAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQKCjAibHOsqrcgIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAgZQETI6lFA1tIUCAAAECBAgQIECAAAECBAgQIECAAAECBAgQ6KiAybGO8qqcAAECBAgQIECAAAECBAgQIECAAAECBAgQIEAgJQGTYylFQ1sIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQ6KmByrKO8KidAgAABAgQIECBAgAABAgQIECBAgAABAgQIEEhJwORYStHQlp4SeOGFF8KYuUeEQz9xcEv9/tjHD8rLx23q/22x5dvDJZde1KeO3/3+//qUqS8fH//26itr5bffcaumZTfadL1w2eWX1Mp5UG4B+Vbu+JWt9fKtbBErb3vlWnljp+UECExfIJXj2w47bd10rLDxZusbK0w/hKV6Vb6VKlylb6x8K30Ik+/Ahm9fq+G9a+HF5g677bFzuP/++1pu/1rrrNK0nl123SHcdvutfeo5/oRjGsrWfxc3ceLEWvn5F5qjoewCC48J8T33n3feUSvnAQECnReYpfO7sAcCBNohMGLEiLyaX//qijDHHHOEp556Mtx1153hiit/E3bf833hu+f8MOy5xz55maLsJw//dHjXu7Zu2P3qb16jti6WnWeeecIvLpg2EfbihAnhpptvDL+57OLwgd12DL/M1m+77fa18h70hkCRQ/KtN+I93L2Ub8Mdgd7Zv1zrnVjrKYFeE+h/fHvyySfyscKVV12WjxW+950fhT123ztnKcq2MlaIG8w555zhV7+8LN+2/1jhFxdcHLbbdof8Nf/pHYEih4qxgnzrndgPR0/l23Col3+fSy21dPjOt8+rdeSee+4KJ37huPC2jdcO1//xprDSSivXXpvegxVWWDGcefp3wtSpU8ODDz0Q7rjjtnDxJb8K79pqk/CHa28Iq66yWr75yJHTzj/5wbk/CYsttnhDlWPGjOmz7u1v2zh87rNfyNc99tij4eZb/hEuuugX4d1bbxpu+MttYckll+pT3hMCBDojYHKsM65qJdB2galTpuR1vm3DjfLJrGIHR37qmLD2equGr3ztpNrk2JT/ll1hhZXCpptsXhRt+jeWHTVqVJ9ycTLsiGxibbXVlw1fO/Vkk2NN5aq9Ur5VO76p9U6+pRaR6rZHrlU3tnpGoNcFBjq+HXXksbWxQjE5NpixQnSdZZZZmo4V3vyW5cIpp37Z5FgPJp9868GgD2OX5dsw4pd01/F9bo7Z5+jz3hW/G1t44UXyH4z88lcXhGM/c/wMezdl6pQw55g5a/VstukW+TYHffijYa11VwlnnvmN8K0zv5uvK95b11/vrWG55Zafbt2x7PzzL1CrNxaO79G77rJH2OwdG4bvnfvtcOIJX5puHV4kQKA9Ai6r2B5HtRDovMB/zxwrfjVV7DCeRfbWDd7W59Twokzxtyjb7G8s06zcXHPNFVZffY1w3333NNvMuqoLyLeqRzit/sm3tOJR5dbItSpHV98I9LbADI5v9913b82n+Oxf/K29MIgHxgqDwKpiUflWxaim2yf5lm5sStaytddaN2/x5DfeGFLL41lniy66WLi3zd+Xrb/+W/N2tbveIXXWxgQqLmByrOIB1r3eEBg37tm2d/TVV18N//zn7WGZZZZre90qLLeAfCt3/MrWevlWtoiVt71yrbyx03ICBKYv0KnjW7y0lLHC9O178VX51otRH74+y7fhsy/jnn998YV5s9/73p2G3Px4OdnZZ599yPXUV3B79r4al2WWWbZ+tccECHRQwGUVO4iragLdEPjt1VeG3197Tdhpx/c37C7eN+zRRx/us3777XcOb8nOCJve8vzzz4ejjj4sPJtNuh3/uZOmV9RrPSYg33os4MPcXfk2zAHood3LtR4Ktq4S6DGBThzfXnjhhfDpzxyejxU+e9zne0xUd6cnIN+mp+O1dgvIt3aLVqe+eGb0c8+NC188+cRap+JVkS67/JJwxmnfDmuvtU5t/cw8OPHzx+WbbbP1drXNi7Oxzz7njDDvvPPV1scHh3708D63R+nz4n+fPPTQg+FjHz8wf7bP3vs3K2IdAQIdEDA51gFUVRLohEDxRnvK108Oo0ePDs89/1z4x01/DzfeeEN482qrh6+cfGptt0XZ+OY/YcL42vr4YMPsnmX1y7QPDc+FMXOPqF+dPz4qu5/Zh/Y/qGG9FdUXKHJIvlU/1in0UL6lEIXeaINc64046yWBXhTo1PEtWo4fP37AscKHD/hIL3L3fJ/lW8+nQFcB5FtXuSuxs5gzE1+ZGP70p+vy/sTvxW697Zb88U9+9qOwxeZbzvC+YLHwyBEjw1NPP1WbZHvkkYfC9X/5U3jggX+H7bOzzw75yMfzOuN/ijy98R83hNln63tGWXyvnCf7X7GMHDkyn6jr/z3cwgstHH55wSVh1VVWK4r6S4BAhwVMjnUYWPUEBiPwicMPCXff/a/aJiuuuHI48/Rzas/jg/hGPGrUqBDvNbbmGmuHj3/siPC+nT/Qp0zx5JNHHB323mu/4umAf2NdRxx2VP56PAvtr3+7Plx91R/CxhttOuA2Xii/gHwrfwzL1AP5VqZolbutcq3c8dN6AgQGFhiu41ts0bGfOT5vWDFW+O2V14VNNt5s4MZ6pfQC8q30ISxVB+RbqcKVfGOnTJkSlnjTkuGqK67t09b44/Ld9tw5vG+X7cItN90V4u1Edtx5mz5ldt5pl3Dghw+prXv55Zdqk2zxjLDttt0hfOD9u4d11lmvViY+iPuMy/e/e35LE28rr7RKeP/7ds23+cEPvxdefHFCuOO2+8Pcc8+dr/MfAgS6I2ByrDvO9kKgJYE111w7xF+KFEu8wWexTP3vG+1FF14+w9Oxizfl4m9RR7O/sUy8TvKxx5yQv7znHvuG1d6yXDjpi8c3fJBotr115RWQb+WNXRlbLt/KGLVytlmulTNuWk2AwIwFhuP4Fls1duzYhrHCF790grHCjENW6hLyrdThK13j5VvpQlbKBq+//lvDkZ/8TDjiU4fmV2GKz/v/0GPZZZev9W3K1Clhuex5/0m2WoGZfBC/h4s/hi++h1tuuRXChz68dzjjW98Ixxz9uZms1WYECMyMgMmxmVGzDYE2CEydOrWhlv33+3DDuv4rmm3Xv0zxfGpo3EfxWv3f+jqXyW78Gc8iO/WbXw2X/ubX+ani9WU9LqdAfYyLHsi3QsLfdgvIt3aLqm8gAbk2kIz1BAhURaD+ODccn93q9x9N68cKl1x6Udghu5+xpToC9fGWb9WJa6o9kW+pRqb87YqXOIyXLmy2jJ5ttnx1vFVJXIoJqvxJv/9Mr55+RWuXVYzbzGiJbasvt/tue4Wzvn16/iP1/fb5UFh88TfNqAqvEyDQJoHmR4o2Va4aAgTKKXBMdtmUhRZcKBz56cPC66+/Xs5OaHVpBORbaUJViYbKt0qEsRSdkGulCJNGEiAwEwLF8e2oow8Pr7322kzUYBMCrQvIt9atlBy6gHwbumEKNcSJ12ZXUoqXUfzx+T/Im/jm1VafYVMHqqfZhsVkb/G3WZliXWxb/3Jnnv6d/OVjjjuyKOYvAQJdEHDmWBeQ7YJAM4H6X4k0e32gdYPZ7vLLLw2PP/ZoQ1WbbfaOPvcT61/nmDFjwoknnhwO+egB4Zunn5Kfdt5QiRWlEugf41YbP5jt5FurqtUvN5i8qdcYzHbyrV6udx8PJmfqlQaznVyrl/OYAIFuCwzmeBXbNpjyrRzfmtVXP1Y4/cxTjRW6nRQd3F+zeE9vd4MpL9+mJ9mbrw0mf6LQYMrLt97MqaLX8cysV159JfzxT9flqyZMGB9uu/3WcP5PzgsPP/xQ+PrXTg9LLLFkUbwtf4v8PPucM0K8N1n/ZZ+9PhiWXHKp/qtrz9dcY60QzyD72QXnh49+5BMhXvLRQoBA5wVMjnXe2B4INBXo/yuRpoWarBzMdpdfcWmI//ovI0eN6jM51qzOfffeP5xzzpnhK189Key37wH5mWT96/G8PALNYtxK6weznXxrRbQ3ygwmb+pFBrOdfKuX693Hg8mZeqXBbCfX6uU8JkCg2wKDOV7Ftg2mfCvHt4Hqqx8r7LXnfmGxunsld9vI/tonMFC8B9rDYMrLt4EUe3f9YPInKg2mvHzr3bwqev7IIw+Hrd+zRfE0n2za6t3vCXvstnfYYIMNa+vb9aDIz2+ddVrTKjfPfqQ+dMe9lAAAQABJREFUvcmxuNFJX/hqiJcs/vhhB4e//PnmQU0IN92plQQIzFBgRPZ/3tZuSjTDqhQgkJ7A3Q+EsPTC6bVLi4Yu8PDTIayy3NDraWcN8q2dmmnVJd/SikfVW5Navjm2VTfjUsu16krrWaoCjm+pRmbo7Urx+Cbfhh7XVGuQb6lGpprtkm/VjGuqvUox31K10q5yCrjnWDnjptUECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIzIWBybCbQbEKAAAECBAgQIECAAAECBAgQIECAAAECBAgQIFBOAZNj5YybVhMgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECMyEgMmxmUCzCQECBAgQIECAAAECBAgQIECAAAECBAgQIECAQDkFTI6VM25aTYAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgMBMCJsdmAs0mBAgQIECAAAECBAgQIECAAAECBAgQIECAAAEC5RQwOVbOuGk1AQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIDATAiYHJsJNJsQIECAAAECBAgQIECAAAECBAgQIECAAAECBAiUU8DkWDnjptUECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIzIWBybCbQbEKAAAECBAgQIECAAAECBAgQIECAAAECBAgQIFBOAZNj5YybVhMgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECMyEgMmxmUCzCQECBAgQIECAAAECBAgQIECAAAECBAgQIECAQDkFTI6VM25aTYAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgMBMCJsdmAs0m5REYlWX45Mnlaa+WtibwRhbTGNvUFvmWWkTa0x751h5HtbQmkGK+Oba1FruylUox18pmqL3lF3B8K38Mm/Ug1eObfGsWrfKvk2/lj2GZeiDfyhSt8rc11Xwrv6wepCSQ4NfLKfFoS9kFZpsthElvlL0X2t9fIMZ09iy2qS3yLbWItKc98q09jmppTSDFfHNsay12ZSuVYq6VzVB7yy/g+Fb+GDbrQarHN/nWLFrlXyffyh/DMvVAvpUpWuVva6r5Vn5ZPUhJwORYStHQlrYLzJFNoLzuzLG2uw53ha8nOjkm34Y7Mzqzf/nWGVe1NhdIMd8c25rHquxrU8y1sptqf/kEHN/KF7NWWpzq8U2+tRK98pWRb+WLWZlbLN/KHL3ytT3VfCufpBanLGByLOXoaNuQBRaYL4TnXxpyNSpITOCFl0NYMIttaot8Sy0i7WmPfGuPo1paE0gx3xzbWotd2UqlmGtlM9Te8gs4vpU/hs16kOrxTb41i1b518m38sewTD2Qb2WKVvnbmmq+lV9WD1ISMDmWUjS0pe0CI0eEsNhCITw9vu1Vq3CYBGIsY0xHZLFNbZFvqUVk6O2Rb0M3VEPrAqnmm2Nb6zEsS8lUc60sftpZHQHHt+rEsuhJysc3+VZEqTp/5Vt1YlmGnsi3MkSpOm1MOd+qo6wnKQiYHEshCtrQUYGxc4cwdq5sguyFju5G5V0QiDHM45nFNNVFvqUamcG3S74N3swWMy+Qer45ts18bFPbMvVcS81Le6ov4PhWnRiX4fgm3+RbNwXkWze1O7svx7fO+qq9r0AZ8q1viz0jMPMCI6Zmy8xvbksC5RGYkF1e8T9PhzDvnCGMnmXav1GjytP+XmzpG9n94uINQON9417I4rf4wiHMk010lmGRb2WIUt82yre+Hp51VqCs+ebY1tm86ETtZc21Tliok8D0BBzfpqeT5mtlPr7JtzRzanqtkm/T0/FauwXkW7tF1Tc9gTLn2/T65TUCrQiYHGtFSZnKCMSp4GefD+GVV0N4bVIIk6dUpmuV7Mio7NzW2WcLYY7ZQ1hg3jQvpTg9ePk2PZ30XpNv6cWkyi0qc745tpUrM8uca+WS1toqCDi+lSuKZT++yTf51k0B+dZN7aHvy/Ft6IZqaF2g7PnWek+VJNAoYHKs0cQaAgQIECBAgAABAgQIECBAgAABAgQIECBAgACBigq451hFA6tbBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECjQImxxpNrCFAgAABAgQIECBAgAABAgQIECBAgAABAgQIEKiogMmxigZWtwgQIECAAAECBAgQIECAAAECBAgQIECAAAECBBoFTI41mlhDgAABAgQIECBAgAABAgQIECBAgAABAgQIECBQUQGTYxUNrG4RIECAAAECBAgQIECAAAECBAgQIECAAAECBAg0CpgcazSxhgABAgQIECBAgAABAgQIECBAgAABAgQIECBAoKICJscqGljdIkCAAAECBAgQIECAAAECBAgQIECAAAECBAgQaBQwOdZoYg0BAgQIECBAgAABAgQIECBAgAABAgQIECBAgEBFBUyOVTSwukWAAAECBAgQIECAAAECBAgQIECAAAECBAgQINAoYHKs0cQaAgQIECBAgAABAgQIECBAgAABAgQIECBAgACBigqYHKtoYHWLAAECBAgQIECAAAECBAgQIECAAAECBAgQIECgUcDkWKOJNQQIECBAgAABAgQIECBAgAABAgQIECBAgAABAhUVMDlW0cDqFgECBAgQIECAAAECBAgQIECAAAECBAgQIECAQKOAybFGE2sIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQqKmByrKKB1S0CBAgQIECAAAECBAgQIECAAAECBAgQIECAAIFGAZNjjSbWECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIVFTA5FhFA6tbBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECjQImxxpNrCFAgAABAgQIECBAgAABAgQIECBAgAABAgQIEKiogMmxigZWtwgQIECAAAECBAgQIECAAAECBAgQIECAAAECBBoFTI41mlhDgAABAgQIECBAgAABAgQIECBAgAABAgQIECBQUQGTYxUNrG4RIECAAAECBAgQIECAAAECBAgQIECAAAECBAg0CpgcazSxhgABAgQIECBAgAABAgQIECBAgAABAgQIECBAoKICJscqGljdIkCAAAECBAgQIECAAAECBAgQIECAAAECBAgQaBQwOdZoYg0BAgQIECBAgAABAgQIECBAgAABAgQIECBAgEBFBUyOVTSwukWAAAECBAgQIECAAAECBAgQIECAAAECBAgQINAoMEvjKmsIVFhgyuQQJtwfwmvPh/D6iyFMmVThzlagayNHhzDrPCHMNm8IY1cIYcSocnUq5tv4J7J8eymESa9k+fZGudrfa60dmb0ljp4jy7e5Qph38SzfSvb7EflWrowtc77JNblWLgGtJdC6gLFC61YplKzCWMHYNIVMaq0N8q01J6XaIyDf2uOoltYEyp5vrfVSKQJNBUZMzZamr1hJoGoCLz8ewrjbQxizZAijsi/AZxkTQnwDsKQrECcv35gYwuRsYmniIyEssGYIc74p3fbWt+ylZ7N8eyjLt/mzXJs1+5flWvwy3JKuQJy8fCPm3OshvPxcCAsuG8JcC6Tb3vqWybd6jXI8Lmu+ybVy5Fd9K8uaa/V98JhANwSMFbqh3N59lHmsIN/amwvdqE2+dUPZPgoB+VZI+NsNgTLnWzd87KPSAibHKh1enasJvPhw9mV3dgbP3CvWVnlQQoEX78kmx5bI4rhU2o2f8OS0yZV5Fkm7nVo3fYEJT2WTYwtm+bbw9MsN96vybbgj0J79lyHf5Fp7Yj3ctZQh14bbyP57T8BYoRoxL8tYQb7Jt24KyLduanduX45vnbNVc6NAWfKtseXWEBi0QMmuGTXo/tmAQAgvPZZNVPzHxFgVcmHulbNYZmcAxn+pLi9mZ4y9lJ11ZGIs1Qi13q4Ywzye41rfptsl5Vu3xTu3v9TzTa51Lvbdrjn1XOu2h/0RMFaoTg6UYawg3+RbNwXkWze1O7svx7fO+qq9r0AZ8q1viz0jMNMCJsdmms6GpRCI9w147o5sYmylUjRXI1sQiLEcd1sIU6e0ULjLRfJ8eyi7P5ozxros37ndxVg++6B865ywmusFUs03x7b6KFXjcaq5Vg1dvSiTgLFCmaLVWluTHysYm7YWyJKUkm8lCVRFminfKhLIknQj5XwrCaFmlkPA5Fg54qSVMysw/r7snk+JX4JvZvvWy9vFmI6/Pz2BF7IzFOM9xizVEphzvhBeyC7Lmtoi31KLSHvak2K+ybX2xDa1WlLMtdSMtKf6AsYK1YxxqmMF+Sbfuikg37qp3b19Ob51z9qepn2fmuJ3b2JDoI0CJsfaiKmqBAUmjQ9h1OwJNkyThiQQYzrp+SFV0ZGNJ00MYZZZO1K1SodRYNToEF57aRgbMMCu5dsAMCVfnWK+ybWSJ9UAzU8x1wZoqtUEOiZgrNAx2mGtONmxgrHpsOZFp3Yu3zolq95mAvKtmYp1nRJINd861V/19qSAybGeDHsPdfr1CdlkxZge6nCPdHWWObPJsSy2qS35F8jZRIqlWgKzZjGNsU1tkW+pRaQ97Ukx3+Rae2KbWi0p5lpqRtpTfQFjhWrGONWxgnyTb90UkG/d1O7evhzfumdtT9n3qYl+9yY2BNooYHKsjZiqSlBgyqQQRpqsSDAyQ2tSjGmMbWrLlDeyfJsltVZpz1AFYkxjbFNb5FtqEWlPe1LMN7nWntimVkuKuZaakfZUX8BYoZoxTnasYGxayYSTb5UMa7Kdkm/JhqaSDUs13yqJrVPDJWBybLjk7ZcAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQKDrAibHuk5uhwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAsMlYHJsuOTtlwABAgQIECBAgAABAgQIECBAgAABAgQIECBAoOsCJse6Tm6HBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECwyVgcmy45O2XAAECBAgQIECAAAECBAgQIECAAAECBAgQIECg6wImx7pObocECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQLDJWBybLjk7ZcAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQKDrAibHuk5uhwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAsMlYHJsuOTtlwABAgQIECBAgAABAgQIECBAgAABAgQIECBAoOsCJse6Tm6HBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECwyVgcmy45O2XAAECBAgQIECAAAECBAgQIECAAAECBAgQIECg6wImx7pObocECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQLDJWBybLjk7ZcAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQKDrAibHuk5uhwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAsMlYHJsuOTttycF1n77FmHEXAv2+Tf3okuHnffYN9x3/79bNll13bf1qSPWGet57y57hFtvv6NPPcee+MWGsvVtmDhxYq38HAsu0VB2zEJLhq13/EC4485/1cp5UD6BF14Yn8f24E98sqXGH/TxIxpyIebN29+5Tbjoksv61PF/v7+uadkiz668+ppa+a122KVp2fU2eWe45LIra+U8KLeAfCt3/MrUerlWpmhpKwECMxJo11hhlXU2bPi8FccKO+y6V8NY4ZgTTmooW3yGi3+NFWYUtWq8nsr7aRx31udf8Xj9Tbc0VqhGquW9kG8VCmaiXVnrbZs3HEtm5rs376eJBlizCLRRYJY21qUqAgRaEFhqySXCD7/zrVrJe+69Pxxz4klh7Y3eEf7xx2vCKiuvWHtteg9WWH658N0zvxGmTp0aHnjwoXD7P/8VLrz40rDJu7cLN1x7dVht1ZXzzUeMGJH//cn3zwmLL7ZoQ5Vjxozps27jt28YvvDZz+TrHn3s8fCPm28Nv7jokrDpVu8Nt/31DyG231J9gSJvrrjogjDHHHOEJ596Ktx51z3hN1f8Nrxvz/3yHN5nj11ziKLsp4/4eNj6Xe9swFnjzavV1sWy88wzd7jk5+fn6yZMeDHcePMt4eLfXBF23G3vfP32225dK+9BbwgUOSTfeiPew9lLuTac+vZNgEArAksvtWQ475wza0XvuvvecNwXvpSPFW760+/CyiutUHtteg9WXGH58J0zTq2NFW67487wq0t+0zBWGDly2u9ljRWmp+m1/gL930+fePLJfKxw2ZVX52OFH333rLD37h/INyvKtjJWiBvMOeec4bILf5pv23+scPEFPw47bLdN/pr/9I5AkUPFWEG+9U7sh9JT76dD0bMtgd4RMDnWO7HW0wQEpkyZkk00zB4232SjWmvi44UXWjA/e+znv/p1OP6Yo2qvDfQg1jNnNqlV1LPFphvnRQ/58P4h/rLltLPPCeecfmq+Lk6exWWDddcOcUJtekusd4H556vVG8vGQc0eH3hf2HCLrcK3zz0vfOmE46ZXhdcqIjBlyrS82WjDt+aTWUW3jvnUYWHVdd8eTvrqqaGYHIt5E5eVsi9hipwsyvf/G8uOGjWqT7k4Gfbpww8Ny66+bjj5698MJsf6q1X/uXyrfoxT6aFcSyUS2kGAQDOB+Dmp2VhhkYUXyiccLrjwohbHClObjhU+euCH8rHCN7717fxHdrENxee4t663Tlh+uWWbNau2LpY1Vqhx9PSDgd5Pjz3y8P+OFb5emxwrcqyVsUJEnWWW5mOF5VZfL3z51NNMjvVg5sm3Hgz6ELvs/XSIgDYn0EMCLqvYQ8HW1XQF1l17zbxxr7/xxpAaGX9JGs8Ou+ue+4ZUT/+N37r+uvmqe+67v/9LnldU4L8nHIbiV3pFN+NZZG/bYP0+lwEtyhR/i7LN/sYyzcrNNddcIZ5hJseaqVV/nXyrfoxT6aFcSyUS2kGAwGAEirHCG5MnD2azhrJxrLDYoou0/fOWsUIDdeVXzOj99N77/nfLgOKzf/F3ZnDyscLqxgozY1eFbeRbFaKYRh+8n6YRB60gkJKAybGUoqEtPSsQL4cYl53e+54hG/zniSfD7LPNNuR66iu4+dbb8qfLLr1U/WqPe1Tg2XHj2t7zV199Ndye3dduuWWWbnvdKiy3gHwrd/zK1Hq5VqZoaSuB3hJo51jhiSefavtY4bY7/pkHxFiht/JyoN526v30tn/eaawwEHoPr5dvPRz8mei699OZQLMJgYoLuKxixQOse2kJxGv6j3vu+XDil75aa1g8U+biy67MLoP49bDu2mvV1s/Mg8+d9OV8s/rL0hX3ETjj298L8883b59qD/vowWHs2Hn6rOv/5P5/PxAO/sSn8tUf2mev/i973mMCV159Tbjm2j+E9++0fUPPL77sivDwo4/1Wb/z9tuGNVZ/c591/Z88//wL4bBPHxuefXZcOOmzx/R/2fMeFpBvPRz8LnddrnUZ3O4IEGgqkI8VxjWOFS65/Krw7dO+HtZZa9rVJppu3MLK4z7/pbzUdtu8u1a6OJsnjhXmm3dsbX18cPjHPtLn8tp9XvzvkwcfejgceOgR+bP9996zWRHrekigE++nL7wwPhx+9HH5WOHzxx7dQ5q6OiMB+TYjod59Pb63jfN+2rsJoOcEBiFgcmwQWIoSaIfAxImvhOv+dH1e1fgJL4Zbbrs9f3zeTy4I79x80xle6z8WjgPnp55+pjbJ9tAjj4Y//eVv4d8PPBjet+N7w8cOOiCvM/6nuOfYDf+4Kcwx++y19fHBwQfsF8aG/02OxXovySbqRsy1YJ9yCy+0ULjk5+eHVVdZqc96T6orUHxREu8BNnr06PBcNqn795tuDjfceFNYfbVVw6knf6HW+aJsnOiNOV2/bLThBvVP80sqxrr651gsdEx2j4KDPrRvn/Ke9IZAkUPyrTfiPZy9lGvDqW/fBAi0IjDxleZjhR/97Odhyy1aHSuMyMYKTzcdK+yU/XDp4x85sNaU4rgYxwr9rz7xkQ9/MBspzF0rO6Oxwmqrrlwr60G1BYq8afdnt6g2fvyEAccKMSctvScg33ov5kPtccwZ76dDVbQ9gd4QMDnWG3HWy0QE4k1Bl1xi8XDtlZf0aVGccNh5j33DNjvvFu699Yb8tS222aFPmXimTryJdrG89PJLtUm2+bIzwnbYdpuw+y47h/XW6Xv2WTE5dv73zg4rLL9csfmAf1dZecWw6/t2yl//3nk/DhNefDHcf/uNYe655xpwGy+UU+CQw48M/7r73lrjV15x+ewMxlNrz+ODOOk6atSofGJ17TXfEo449CPhAzvv2KdM8eToIz4R9ttr9+LpgH/jfcuOOvzQ/PV4Ftr1f70h/OGqS8OmG799wG28UH4B+Vb+GJalB3KtLJHSTgIE+gvMaKyw3S57hLtu+muIl6PeZqdd+2y+y047hEMO3L+27qWXX25prBD3GZc4Vlh+uWVr2w/0wFhhIJnqrR+u99MoefwxR+WgxVjhumz8vNkmG1UPWY9qAvKtRuFBGwS8n7YBURUEekTA5FiPBFo30xaIN7GOZ8187IhPh7/9/R9hww3Wa/jwv/yyy9Q6Ed/ol1922YZJtlqBmXwQ6115xRXCCf8djKyQDZD3PuAj4Zvf+nb47NHTLq04k1XbLEGBtdd4S4hnBRbLYossUjwMU6ZMzR9ffuHPZng5neJLleJvrZImD2KZ2WefrZZj++6xa1hu9XXD8V/8StvzucnurRpGAfk2jPg9tmu51mMB110CPSAQxwqf+dRh4dBPHp2fxR+f958oWH65ZWoS8XNcN8cK3zjz7PC5zxxZ278H1RAYjvfTKBcv+1+MR4uxwgnZbQn6/8C0Gsp6UQjIt0LC304KeD/tpK66CZRTwORYOeOm1SUViJciKS4J0L8LxWVMnnv++fylYkDQv1x8Pr16+pePZeMy0H7ry/evd6/ddgmnn/2d8OVTTw8f2nevsPhii9YX97hEAsUZhPVN/vAH96l/2vRxs+2aFsxWtlq2vtyyyyydn0X21W+cEX596eUhXurHUn6B+hgXvZFvhYS/7RSQa+3UVBcBAsMtED+Ljxwx7bN7/7bMll3mOi6tjBWyq0nl44X+dTR7XowRir/NyhTrBhorxB85xbHCmxZfrCjqb0kF6t9Xh+OzW/3+I2H9WOGiSy4LO++wXUllNbuZQH285VszIetmViC+p3k/nVk92xHoLYHmn7x7y0BvCXRNIJ41U/8BsNhxvDTKuT/6Sf403s9pRstA9TTbrjibp9l++5dvVu93zjg1TJw4MRx57PH9i3tOoC0Cx2e/NF5owQXDYZ8+Nrz++uttqVMlBAYSkG8DyVjfbgG51m5R9RGovkD8LD5l6rTLHNb3No4VfnD+z/JVrYwVpmYXACjGAPX1NHtcjBGKv83KFOsGGivE140VCiV/2y1QvJ8efvRx4bXXXmt39eoj0EdAvvXhKO2T+J7m/bS04dNwAl0VcOZYV7ntrNcF4q8tX3nl1dr1/+PNhm+9/Y5w3k8uCA89/Eg47WtfCkstuURbmeI+43LGt78X5s/uTdZ/+eDee0x3n2tll96LZ5Cdf8Ev85t3x9PQLeUTaOXXwM16NZjtLr3iqvDo4/9pqOYdm27c535i/escM2ZMOPnE48IBHz0snHLat/LLBjVUYkWpBPrHuNXGD2Y7+daqarXLDSZn6iUGs51cq5fzmACBTgrMaKxw+iknZ/cvflNbm1AcD+NYYb55xzbUPZixwicOOSgYKzQQlmpFkQ+tNnow5Vt5P21WX/1Y4dQzzjZWaDU4JSjXLN7Ta/Zgysu36UlW/zXvp9WPsR4SaJeAybF2SaqHQIsCjzz6WNhimx1qpeMA8j3v3jLsvfsH8nuN1V5o04PiV6Px8ojNlndstsl0J8fiNl896fhwUXbJu4M/8alwy1+ubVaNdYkLtPJr4GZdGMx2l15+VYj/+i+jsgnaTTd+e211szr332fPcOY554aTvnpqOCC7LM9CCy1YK+9B+QSaxbiVXgxmO/nWimj1ywwmZ+o1BrOdXKuX85gAgU4LPPzIo10dKxTHw9POOqdp1wY7Vrj5+t+3dDn3pjuzctgFinxotSGDKd/K++lA9dWPFfbba7ew2KIu999qjFIuN1C8B2rzYMrLt4EUe2e999PeibWeEhiKwIjszSW76IKFQEUFHrk8hAU2rGjnerxb4/4WwlKJ3Z/qoRtDWGi5Hg9MRbv/zAMhLLN+Wp2Tb2nFo52tSS3f5Fo7o5tWXanlWlo6WtMLAsYK1Y1yimMF+Sbfuikg37qp3d19Ob5117vX95ZivvV6TPS/rQLuOdZWTpURIECAAAECBAgQIECAAAECBAgQIECAAAECBAikLGByLOXoaBsBAgQIECBAgAABAgQIECBAgAABAgQIECBAgEBbBUyOtZVTZQQIECBAgAABAgQIECBAgAABAgQIECBAgAABAikLmBxLOTraRoAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAg0FYBk2Nt5VQZAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIBAygImx1KOjrYRIECAAAECBAgQIECAAAECBAgQIECAAAECBAi0VcDkWFs5VUaAAAECBAgQIECAAAECBAgQIECAAAECBAgQIJCygMmxlKOjbQQIECBAgAABAgQIECBAgAABAgQIECBAgAABAm0VMDnWVk6VESBAgAABAgQIECBAgAABAgQIECBAgAABAgQIpCxgcizl6GgbAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIBAWwVMjrWVU2UECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIpC5gcSzk62kaAAAECBAgQIECAAAECBAgQIECAAAECBAgQINBWAZNjbeVUGQECBAgQIECAAAECBAgQIECAAAECBAgQIECAQMoCJsdSjo62DV1g5OgQpkwaej1qSEsgxjTGNrVl5CxZvr2RWqu0Z6gCk7OYxtimtsi31CLSnvakmG9yrT2xTa2WFHMtNSPtqb6AsUI1Y5zsWMHYtJIJJ98qGdZkOyXfkg1NJRuWar5VElunhkvA5NhwydtvdwRmnSeENyZ2Z1/20j2BN14OYXQW29SW0XNk+WYyNrWwDLk9Maajxwy5mrZXIN/aTppEhSnmm1xLIjXa3ogUc63tnVQhgRkIGCvMAKikL6c6VpBvJU2oGTRbvs0AyMttFZBvbeVU2QwEUs23GTTbywQGI2BybDBaypZPYLZ5Q5j8SvnarcXTF3gji+no+aZfZjhenW0uk2PD4d7pfU7OJsdibFNb5FtqEWlPe1LMN7nWntimVkuKuZaakfZUX8BYoZoxTnasYGxayYSTb5UMa7Kdkm/JhqaSDUs13yqJrVPDJWBybLjk7bc7AmNXCGHiI93Zl710T+CVLKZjV+ze/lrd07yLh/Dy862WVq4sAi8/F0KMbWqLfEstIu1pT4r5JtfaE9vUakkx11Iz0p7qCxgrVDPGqY4V5Jt866aAfOumdvf25fjWPWt7CiHVfBMbAm0UMDnWRkxVJSgwYlQI868RwoR7E2ycJs2UwItZLBdYO4QRI2Zq845uNCI7pC64TAjjn+roblTeRYHxT2YxXU6+dZG8p3eVar45tlUvLVPNtepJ61HqAsYKqUdo8O1LeqxgbDr4gCa+xYR7Eh6byrfEs2fwzZNvgzezxcwLpPx+OvO9siWBBgGTYw0kVlROYK4lQpgrO+sjfpCwlFtgwt0hzJnFc84Ez+IpZOdaMMu3BbIJsieKNf6WVSB+eTz3QtPimWof5FuqkRl8u/J8WzjdfJNrg49pqluU4diWqp12VVPAWKE6cS3FWMHYtDIJF/NtriUTH5vKN/nWRQHvp13E7vCuyvB+2mEC1feOwIip2dI73dXTnhZ4+T8hjLs1hDmyD7CzzJH9mzOEkaN7miT5zk+ZlN3D6+XsvnGvZpfHfHjar/JSnhirB315XAjPPBjCmOzeaLNkeTZr9m/kLPUlPE5NYPIb0+4ZF+/DEy83ttDy2WB3/tRa2bw98q25S8pry5pvci3lrGretrLmWvPeWEugcwLGCp2z7VTNpR4rGJt2Ki06Vq986xitipsIyLcmKFZ1TKDM+dYxFBX3ioDJsV6JtH5OE5g6JTuj5/4QJmX3hZo0IYT4BmBJVyBOXo6eJ4TZsgmmebJ7jKV4KcXp6cV8eyEb+L6WTfBNmpjlWzb5YklXIE5ejh4TwuxzZfe0y85OlG/pxqoKLStzvjm2lSsDy5xr5ZLW2ioIGCuUK4pVGCsYm5Yn5+RbeWJVhZbKtypEsTx9KHu+lUdaSxMUMDmWYFA0iQABAgQIECBAgAABAgQIECBAgAABAgQIECBAoDMC7jnWGVe1EiBAgAABAgQIECBAgAABAgQIECBAgAABAgQIJChgcizBoGgSAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIBAZwRMjnXGVa0ECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIJCpgcSzAomkSAAAECBAgQIECAAAECBAgQIECAAAECBAgQINAZAZNjnXFVKwECBAgQIECAAAECBAgQIECAAAECBAgQIECAQIICJscSDIomESBAgAABAgQIECBAgAABAgQIECBAgAABAgQIdEbA5FhnXNVKgAABAgQIECBAgAABAgQIECBAgAABAgQIECCQoIDJsQSDokkECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQKdETA51hlXtRIgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECCQoYHIswaBoEgECBAgQIECAAAECBAgQIECAAAECBAgQIECAQGcETI51xlWtBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECCQqYHEswKJpEgAABAgQIECBAgAABAgQIECBAgAABAgQIECDQGQGTY51xVSsBAgQIECBAgAABAgQIECBAgAABAgQIECBAgECCAibHEgyKJhEgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECHRGwORYZ1zVSoAAAQIE/r+9O4G3oXwDOP7gWiJbsm/ZKhJZs2RXlshWspUSlRSyZE0kW6FSQpJQka3F2r+kRSWVLKmkKKEk2ZL9+s/zao5z7j3cO/eec+7MPb/387nOOTPvvPPOd475vHOeed8XAQQQQAABBBBAAAEEEEAAAQQQQAABBBBwoQDBMReeFKqEAAIIIIAAAggggAACCCCAAAIIIIAAAggggAACCCAQHgGCY+FxpVQEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEXChAcc+FJoUoIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAAALhESA4Fh5XSkUAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEHChAMExF54UqoQAAggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIBAeAYJj4XGlVAQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAARcKEBxz4UmhSggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAuERIDgWHldKRQABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQcKEAwTEXnhSqhAACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAgggEB4BgmPhcaVUBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABFwrEuLBOVAkBBBBIHQKxZ0QObxM5cUDk1BGR2FOp47g4CgQQSL5A2vQi6bOJZMwhkr2USJp0yS+TEhBAAAEEkidA2y15fmyNQGoW8Hrbjetbav52cmwIJE/A69e35B09W0e5QJqzVopyAw4fAQQQCL3A0d0i+zeJZMktEpPR+sskog0OEgIIIKACGiw/fdz6OylydK9IrvLW9aIgNggggAACKSVA2y2l5NkvAt4Q8HLbjeubN75j1BKBlBLw8vUtpczYb6oRIDiWak4lB4IAAq4ROLLD+rHbCo5lL+SaKlERBBBwucChXVZwrLBI1qIuryjVQwABBFKhAG23VHhSOSQEwizglbYb17cwfxEoHoFUKOCV61sqpOeQIi/AnGORN2ePCCCQmgX+sX7gJjCWms8wx4ZAeAQ0mH5057nrR3j2QKkIIIAAAsEEaLsFU2EZAggkJOCFthvXt4TOIusRQCCYgBeub8HqzTIEkiBAcCwJaGyCAAIIBBXQcdz/3kyPsaA4LEQAgQQFsls9x/ZvFDkbm2BWMiCAAAIIhECAtlsIECkCgSgWcHPbjetbFH8xOXQEQiDg5utbCA6PIhCwBQiO2RK8IoAAAskVOLTNGhYtb3JLYXsEEIhmAb2GHPopmgU4dgQQQCByArTdImfNnhBIrQJubbtxfUut3ziOC4HICbj1+hY5AfYUBQIEx6LgJHOICCAQIYFTB0Vi0kdoZ+wGAQRSpUC6DCInD6TKQ+OgEEAAAdcJ0HZz3SmhQgh4TsCtbTeub577KlFhBFwn4Nbrm+ugqJCXBQiOefnsUXcEEHCXwMnDVnAsk7vqRG0QQMBbAumta8jJQ96qM7VFAAEEvCpA282rZ456I+AeAbe23bi+uec7Qk0Q8KqAW69vXvWk3q4UIDjmytNCpRBAwJMCsadE0tJzzJPnjkoj4BYBvYbotYSEAAIIIBB+Adpu4TdmDwikdgG3tt24vqX2bx7Hh0D4Bdx6fQv/kbOHKBIgOBZFJ5tDRQABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQSiXYDgWLR/Azh+BBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQCCKBAiORdHJ5lARQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAgWgXIDgW7d8Ajh8BBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQiCIBgmNRdLI5VAQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAg2gUIjkX7N4DjRwABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQSiSIDgWBSdbA4VAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEIh2AYJj0f4N4PgRQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAgSgSIDgWRSebQ0UAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEol2A4Fi0fwM4fgQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAgigQIjkXRyeZQEUAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAIFoFyA4Fu3fAI4fAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEIgigZgoOlYOFQEEEEAgygU+/Hit5M+XR666srgnJL5ev1mO/HPU1DV7tqxS4bprXFHvDRu/k4OHDpu6XHppZqlcsZwr6kUlEEAAAQQQQCD1Ceze84ds++kXqWi1g7JZ7aGUSD9v/1V+2/W7b9d1a1fzvU/JN7/u3CU7ftnlq4Jb6uWrEG8QQCAsAn//fVA2ffuDlL6qhOTNm9vxPj5e84XExp412xXIn0euLOWO++NPP/9KTp06beqVzzquq63jIyGAAALhFCA4Fk5dykYAAQQQCInAZqvhv9+6AdCU1Eby8eMnpF7j9nLPXbfLSy+MDUm9/AvR8ivVbC5XFC0kyxa/7L8qye/ve2iIHD7yjxQskFfKlrlSnrtuRJLLCuWGs15bJBs2fSe79+yVLFkukW8+XxbK4ikLAQQQQAABBBDwCbz5zrvyUJ/h8vmHi6Va1Qpm+Yp3P5Smre6W5W/OlCaN6vryhuvNlOmvibZ/tD2myS1BqI8+WScz5yyQo0ePyZdfb5QDezZKjhzZwsVAuQgg4BKBdV9tlCYt75I5MyZKp/atHNeqzk3t5LryZSRH9mzSvGkD6eOS4NhTT78ohw4fkR+37ZCG9WvKrOkTHB8bGyCAAAJOBBhW0YkWeRFAAAEEIiqw45ffpGzlRlKuahMT2NLgVukKDaVanVayfcfOiNYloZ39tf9v+e77bbLms68Sypro9bFnY6XHfXfI6pVz5bmJ5wNj11ZpLGkyFwv4uzT3NdKszT3yzYYtAeU/9sTTAfnibnfovx5gulHWPGXj5b3ksqulcYvOor3F7PT0k4+aOj14/51y9uy5Jw7tdbwigAACCCCAAAJOBLo+MNC0P7r1GJjozT757EuT9+NP1yV6m+Rk1PZOzWqVTPtH22V26t3/8XhtJ21rVa/bWt5YuNTOZl61p0bcdpj/Zw0C2ql5m65B81a5oYUsfHO5nU3u7Nja1OnlqePMMtplPhreIOAKAb0/8/9/br+Pe38V6crGxMTIhDFDzPWjT8+uvt3b9fN/zVWognS8u7doT1X/dGuHB4Iem25buFQNX9Zfft0VNF+O/OWk3Z0Pya7d53vlvjX/RVOnm5vU8/Vs8xXEGwQQQCAMAvQcCwMqRSKAAAIIhEagdfv7TWNZe3rpU8EF8ueVseOnyKBhT8rs1xfL8CG9Q7OjEJRSqGB+2fzlSsmc+ZIQlJZwEcWuKCwvT33SBKc0iLhx8/ey+O13pdaNbWWt9WR12WuuMoWkSZPGvM5+aYIULlQgXsHZracF/VP16yvK6BH9zaLfdu2R9Vawbf6iZVK3cTvTQ0z3S0IAAQQQQAABBEIlsPjtlVKlUnlZ9NZKmT45cb37ta1yU4NarunBtXjeVMmZI7vs/fMv+fa7rbJs5Wrzo+8RawSArne3M1R2m6z3g12kRbMb4/HZvdLsFZdcksn0jNPPOpLAV+s3yZLlq+S2jj1kwWuT5dZWTe2svCKAgIsF9P7Qf2SRnb/tkSHDx0uF6jfLJ+/PlxtqVHFV7evXrSGPDnxIzpw5I1u3bZdNm3+QeQuXiE5RoPe7l12Ww9TXvqb5PzBgH0imTBntt76HKTu2ayldrVFcNIj/08+/ypfrN8q8BUvl62++lU3rVohe80gIIIBApAUIjkVanP0hgAACCCRK4EerIa69lfr26maGQrQ3Gtivu9zRoZU11GA+e5FrXu2AVLgrFBsba4Jw9pA+9epUN7vs+cBdUrJsXZn43AwTONOF9hPE+qNTQmO2a7l6s2OXq9vf0aG1dLJuZCrfcItMmf6qPDlqkC4mIYAAAggggAACyRZYtuIDOXDgkIwa3lduan6n6HCJiR0m0b+9kuyKJLEAbTtpqmE9XGTP+3O7NJORw/rKleXqyxPjnvcFx+w2WckSRQPaWsF2fVbOiv7w7H+Mt9zcUAb1e0BKXFPHelhsKsGxYHAsQ8BlAnqNSJs2bcD/Za2izoGto6HocK1JCY7ZgSktO9Qp9+WX+erboF5NU7xel1u2vVdeeXWh2D3N9JoW7Nji1se+9hUulN9Xrt6/duvSzuqRW1nuurefLFi83PSEjbstnxFAAIFwC4T+KhruGlM+AggggEBUCNgTBB87djze8foHxnRc8vpNOsg//xyNl2/chKlmLPZ4K6wF237aYYZqnGP1QIubvv/hJ7NOf7DRdPTovzJ81DOiQ0roMBEagHpuyqy4m0mb9t2l/+DRAcsb3txJllpP+er+at94u9m+WOlaovUOdSpRvKgUKVxQtP6hTJUqXmuK2/rj9lAWS1kIIIAAAgggEOUCbyxaKlUrl5cbrV5gxYsVkfmLlyVK5KNPvjBttc/Wfh0v/2vz3vK1uQqWqCavzFkYkGffvv1yvzWva94rqpg/HcJw7959AXlC8aFm9UrWMGS7JVhbNqnla88KnSdIe3OQEEDAuwLXV7nOVD7YCPV6fdP5xLLnKyeVa94S9L7TPvL06WOs0UNWSv7iVc19Zu4ilUSvgaFO9WpXM0V+vzW095k1qlU05XJNC/UZozwEEEisAMGxxEqRDwEEEEAgogLay0mDYC+8OOeiNwQVrB8IVn/0uXnazL+C+oTas5NnSvZsWf0X+96XLHGFGc5h8rQ5vmX2m9fnvy16U1KlUjmzqLj1hO7rb7wjXe68TR4b0kuKFikoPfsOF/+5ITTjms+/kg2bvreLMa+rVn8qM2ZZw2U0bCsVr7tGtHfXqVOn5ZEhY2Tl/z4KyBuKDzt/2x3yISk2WUM2amJIxVCcIcpAAAEEEEAAAVvg7aXv+3pAtWnZOF7bys4X9/XPfX+ZIb72/fV3wCqdv6ZTl4dN+0/bbNWqVpDuvYaK/YCPzllboXoz+fCTtfKU1Rt+jDU8445ff5OaDW4LKCcUH/bvP2CKCfVQYd9s3EKbLBQniDIQSEEBe07C1rc0CqiF3r/WbdRO9vy+19x7FiyQ19x36txlwdKoJydLv0Gj5Z7Ot0uXzm3NUIh6DdRhWEOZ/rZ6+GrKlPH8cImhKF+HVNRUnKH7Q8FJGQggkAQBhlVMAhqbIIAAAghERuDdd2ZJo1s6mxuCF1+eK72swFK725rLpZdm8VVAh3rQYNWr1hNyd1vBKzutXfeN/P7Hn9Lh9hb2ooBXHYpCh2cc89QL8scf+yRfvty+9W8sXCZabp48l5tlb70xTXQuLjsdP35CipepLU9OnCat4tzQ2Hn8X/UHmNUr5ponfXX50AEPSp6ilc3T0Y1vquOfNVnvR4x61mzvP49F2jTnnoOZPG22XJ7rsoDyNVCXM2f2gGVxP+h8ZvdZT1dr0jHiSQgggAACCCCAQCgEtLfD4cNHpPGNtU1xTRvVMz3r3176XtA5uRLap/bq1x+chw3uKSOGPuzLrj3FcufOZT537tbPDDm95v0Fcrk1dJgmbcsVKlVdXpwxV+69p71Zltx/9OEonR+sedMGvqLsYdBWWA9H/fXXucCZvVLzVaxQ1v4Y9FWt+lkjFGi7dXD/HkHzsBABBNwloP/vdYQT+z5Na7f79z9kzutvWsOv9pGmjev5KqxTCvTu/7g0a9JAlix6ybd86kuvSfeeQ0VHRRnQ937fcn1TuGABef29ZyRr1kvN8t497pZyVZvI0BETZOXbswLyJueDzpGmyf8+U49Nh430PzbNExOTToZY97sJJQ3gDRg6ztzbt2nZJKHsrEcAAQTCIkBwLCysFIoAAgggEAqBa8pcKes/WyKTrB87XrZ6X3XrMUh69hshOpG5TsSuSRvl93ftKIMfe0r+tCZBtwNa2qtLg2hNLhJ80rm0NDimPcXssdO1l5QOgTjImtvMTv6BMV3294GDUvrqkvLFlxvsLBd81XHYG99YxxcY04z6A03hQgVEA09JSVrmn9YPPfaNyK9Wb7FPPv3S6gn3i7RsfpP0sm6K7KRzVmha99VGM0+ZvVxfdZz3nHI+OKbl6lCSOnSkf9L66sTvkZpTzX/fvEcAAQQQQACB1Ckwd/4SyZ8vj1xb9mpzgLVqVpFsVo//eQuWBPwAm9ij1+CYDi/tHxjTbe3A2Ldbtsqaz76Uac+N9gXGdL0+KKRtvdUff+44OKZtJ00TJr0kWTJnlgMHD5n2oT6kpaMgPPPUMLPe/x9tZ+qQ3f6pkhUY8w+OpZE08u+/x+K1yXSbfr27yUPdO/tvznsEEHCpgB0U14clNR09eky2fP+j6MOWi6wHBG5uXF8qWKOLaNKHQTWNe2KAebX/0Xvd8c9Mt0ZUedUXHLPn8br91pt9gTHNr9fThvVvkHff+9je3PHrlu+3mfvM2LOx1n3xL+baqEF5nQtcy46b7GOzl2fIkF7OPVp5boltMHb8FGu+xCl2NvOqw+muWv6q5MiRLWA5HxBAAIFICRAci5Q0+0EAAQQQSJKABrueeKyv+Vv45nJraJxHTUDrzJkz1o3DQFOm9mgaNvJpmW3NH9av971m2fxFy6xeZs0kffr0F9xvmdKlzM2ITgBsB8fmW+91m9taNw3YbsYrb8hiK+CmATF7mJyADA4/XHJJRuspwsAfRpwUoT+q2DciObJnM08mt21zsxk+yL8c+8Zp1vQJ5kca/3XB3l9Zqpi0b3uLWTVz9kITCNy6YVWCPcyClcUyBBBAAAEEEEAgmIC2Y5at/EDq161hhke085SzftjVnmM6T5eT4Qg1kKRBp07tW9lFxXvd9O0PZtn0mfNk7oJ3AtbrPDolihUNWObkw2dr11vtxxhT5wrlzw2jbben7HLsNpn23O9x35324ou+6tCQmnQI8Y/XrJP/LZlt5me76EasRAAB1whozyp9YHP1ynOBL7tiG62h+Dt26S2NWnSWnzavNg8GbLQe0tTrnt6jxk06N+Pc+e/IwYOHEwwk6XX0/Q/WmGtiqZKBDz3GLTfYZ30I077PzGM9JHlXp1utYRvbik5L4J/0mqYPCMQ9Nv88+t4OjtWqWdW65lc3vXcfHz1J9L5z68YP4mbnMwIIIBBRAYJjEeVmZwgggAACyRG4tVVTqVWjijRsdocZ0vDRgQ+Zmw0dFqdl8xutHmDvmODYlu9+NBOgd2jbIsHdae+xvgNHya7dv0uhgvmtucuWmaeV7aEb9am+Vu3uMz9IdO/WSQZaQ1no3Fs6VMWsVxeZp/4yZQrt2OsJVVpvsq4oWijBG5GEyom7XsvVG6jhQ3qbVaWvKik6d8fTz8+Qxx/tEzc7nxFAAAEEEEAAgSQJ2AEw7bGuf3GTDkmoD/0kNumwZZoyZsxwwU2O/Jen3LVXWz348wfkq1Preili9ep3mrTtpGnR6y9I3rznh+h2Wk7c/NrzP3PmS3xtsvu6dJBiZWrJo49PJDgWF4vPCLhYQANDdg9T/2qWL1daRg3vJy3b3iurPvzMDO967PhxuSxnDv9svvf28iP//GOCY3bAyX71ZbTepEuX1nw8ffqM/+KA96dPn/YFrQJWWB/q16kuc2dNirs43mfdt30NjLfSb4H9YID2DrbvM3W7J8Y+L/rwq97jx03aezZt2jRxF/MZAQQQCLnAuStmyIulQAQQQAABBMIjoD883HJzQ1P4L7/u8u3k3i7t5ZsNW+THbdtl+bsfmjnE6lkN+4RSx//mJHtryf/Mtj9u22HNU3au55RuO2PWG7LSmhvitZnPyPgxg0WfeNMgWjSk229tJtdXuc4EIndaQzeSEEAAAQQQQACBUAjo0Im5cuWU2KPb5ey/O3x/Jw5uNUEhXe8k2cNq6xDTF0oF8ucxq2pbbTn9gTbuXxerZ4RbU36r7v0fvteMYKDzqpEQQMAbAhoYulAAKcN/I5zYcxAWzJ9Pdu/5wzx8Gffoftr+i1mkQ/NrsgNO9qtZ+N8/2gNNU5HCFw74x8TE+Mr4bzPfS7AyfSv93mi+YIE/vyzmrV2ev8Ogfg+YIW/7DhwtJ06ciLuJ9XiAup2bHiDeShYggAACIRQgOBZCTIpCAAEEEAidwGZr6BsdyjBYsuf68m/w6/jn2qNr5pyFsuitFZKYXmNatgbbbmpYS5ZaTy3rn/YY04nZ7bR9x7l5werVrmYvMjcsP2/faT5HuteYrxIRejN10ig5efKU9Bs0OkJ7ZDcIIIAAAgggkJoFjhz5R1Za8+G0btEoXs+FDBkymLlatU2m+ZykZk0ayEeffBEwTKP/9vXr1BBtt02eNueCP1b753fbe/0xWedoe/iRkUF/THZbfakPAghcXMCeY6zif3OONW1c12wwbsLUgA2/Xr/ZzCFmPyCqK+0eY8eOBQaWdLjG/73/iZmHOkuWzAHluOmD9ox9atQg0Qcwn5z4opuqRl0QQCDKBBhWMcpOOIeLAAIIeEVAfzR5ZMgYmTTlFalXu7rUvqGqGWZCx1pftfpT6dalnRmb3f94tPeYTlT82649Mvnpx/1XmR9DdIGu06F37GETdVnH21tK5259rbnEDsYbwqdkiXPzT/S1gkMjhvYWveEYPPwpqyG/Rzd1fUqb5txzMJOnzZbLc10Wr76dO7UxQzTGW/HfguvKl5G77rhVZs5eYA0t+YV1Hq6/UFaWI4AAAggggAACCQosfHOFnDp1Slo1P5bv2tAAAA9HSURBVP8wkv9GLZrdKIvfXmnmHtM5xLJny2pWa+/+alUr+GcNeD9yWB/rQadVUq9xezMvbeeOreU9a96dCZNeMu3CGtUqmWHMdDjtRrd0Nj/Majvnu++3ybQZr1vtvIcTnMsnYIcOP9g/Zq+wRiSwe4r4F6Ft3YuNeqA/Jo97YoDc2bWvjB0/Vez5yPzL4D0CCLhLQHtWaY+pDz9eayqm8y1u3rJV5sx901x7BvbrLpUqXmvW3X3HbeZedvioZ+Sw9XBAn573yHur1kiv/ufua3Ue7rjp4QEjzfCDxYsVEZ1XccToZyVr1kvlyVHn5uaOmz+Un+1hFUeMejZosf16d5OLBej0PvSZyS/L2AlTROcQ1x6yJAQQQCDSAgTHIi3O/hBAAAEEEiWgQ8eUv7a0dO81VJ6dPNP86YYF8ue15hXrJiOHxb850Eb1kOHjpUTxor6bDP+dNW1cT5avXC3DRj4tE8cN9a3SJ5fve2iwfLV+k4x5vL9vub7RecY+/2K96cWmPdl0KIvBjzwgOgzGPd0HpMicYwEVTOBD7Nlzc2E8P3V20Jw69rvOX3axNG7kANEhfLr3elS+/epd35OKF9uGdQgggAACCCCAQDCBeQuXmAecGtSrEWy1mUc2Xbp0Ms9qe2hwrGb1yiafPshU2foRuUzpUkG300DXe0vnmODRgKFjRf801a9bQ4oWKWje9+nZVc6ciZXHnnhaKlQ/P6dZ6xaNxZ7Lx2QMwz/20GIXmmdt8CM9Lhoc0yrd0aG1THxuhowZ/4LoQ2H8mByGE0WRCIRY4N9/j5mgvV1sxQplTaB/wpgh0vimOvZi8zDnqmWvSts7HpSJVlBf/zRpj9F3FkyXa8te7ctrv5n90gTpM+AJM9+2LqtcsZzMmDLWzCNt5wnXq31N02BesHR/1w4XDY7pNjpKSbU6raTf4NFmGoNg5bAMAQQQCKdAGutixiCu4RSmbAQQiB6BnctEcl8TPccbwSNdu+4ba/iYk6K9uAoWyHfBPeuNR5bLy8iwwT3N079xMx4+fETWW/OSlb6qhONJ0/ft2y9/7N0X9KYk7n5C9blijWbSuWMb6dXj7lAVGdJyJr3wirw8e75sWLs8pOVGfWH7tliTBJz/wS7qPQBAAAEEwiVA2y1csiEv94etP8veP/+SOrUS14Ndh1fUnzpy5sgu5cuVjlef/fsPmN4buiJvnsul9NUl4+XxX9Df+uH2p59/lTffmOa/2DXvt3z3o5St3EgO7NkY1t5vrjlgt1XEjW03rm9u+5Y4qs/6b741vce0d1ZirntrPvtS8uTOJVeWKp6o/aTJXEw+WPF6ggH5RBUWhkz3PThYjltzkc2aPiEMpVOkIwE3Xt8cHQCZEbi4AD3HLu7DWgQQQAABFwhcbAgd/+ppsEZTp3YtzWvcf7JZw/LU9Zs7LO76i33Obd1s6B8JAQQQQAABBBBAILICV1sPNulfYlNCPybnypXTUZswNvasCbYldv+Rzmc/82y/Rnr/7A8BBEIroL3LnKQbalRxkl1iYmLcfU2Ts9ZwlPTlcHRSyYwAAkkSSJukrdgIAQQQQAABFwnoGO6vWuO2jxz7nBkGsVTJYi6qXfKq0tsaY16f7KtRr03yCgrh1nUbtTN16tVvRAhLpSgEEEAAAQQQQMC9Am8vfc+0f7RddsLq0eCG9PjoSaZO11Zp7IbqUAcEEPCQQIOmHc31Q3tpuSVdXriiqdP0l+e5pUrUAwEEUrkAwyqm8hPM4SGAQAQFGLoigtjnd6VDLlav29osuLVVU2vohfGiE5aTEPCsAENXePbUUXEEEPCYAG03j50wqouASwXc2Hbj+ubSLwvVQsBjAm68vnmMkOq6W4BhFd19fqgdAggggEACAjrk4h871pkJjLNnz5ZAblYjgAACCCCAAAIIIIAAAggggAACCCCAQLQLEByL9m8Ax48AAgikAoG8eXOngqPgEBBAAAEEEEAAAQQQQAABBBBAAAEEEEAgEgLMORYJZfaBAAIIIIAAAggggAACCCCAAAIIIIAAAggggAACCCDgCgGCY644DVQCAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAgEgIExyKhzD4QQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQRcIUBwzBWngUoggAACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAghEQoDgWCSU2QcCCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggggIArBAiOueI0UAkEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAIFICBAci4Qy+0AAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEHCFAMExV5wGKoEAAggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIBAJAYJjkVBmHwggEB0CadOLxJ6KjmPlKBFAIDwCZ6xrSNoM4SmbUhFAAAEEAgVouwV68AkBBJwLuLXtxvXN+blkCwQQCBRw6/UtsJZ8QiBZAgTHksXHxggggICfQPpsIqeP+y3gLQIIIOBQQK8hGbI63IjsCCCAAAJJEqDtliQ2NkIAAT8Bt7bduL75nSTeIoBAkgTcen1L0sGwEQLBBQiOBXdhKQIIIOBcIGMOKzh20vl2bIEAAgjYAmdOWMGxnPYnXhFAAAEEwilA2y2cupSNQHQIuLXtxvUtOr5/HCUC4RRw6/UtnMdM2VEnQHAs6k45B4wAAmETyF5K5OjesBVPwQggEAUCeg3JfmUUHCiHiAACCLhAgLabC04CVUDA4wJubbtxffP4F4vqI+ACAbde31xAQxVSjwDBsdRzLjkSBBBIaYE06UQuKydyaFdK14T9I4CAFwUO/SaSq4JImjRerD11RgABBLwnQNvNe+eMGiPgJgE3t924vrnpm0JdEPCegJuvb97TpMYuFiA45uKTQ9UQQMCDApcWEsli/R3a6cHKU2UEEEgxAb1mZLnC+iuQYlVgxwgggEBUCtB2i8rTzkEjkGwB03Yr4u62G9e3ZJ9mCkAgKgW4N43K0x6tB53mrJWi9eA5bgQQQCBsAkf3iOzfIJI5j0hMRpH0mUTSpg/b7igYAQQ8JnDmlDVH4XERHcddh6vQHmMExjx2EqkuAgikKgHabqnqdHIwCIRcwMttN65vIf86UCACqUrAy9e3VHUiOJiUECA4lhLq7BMBBKJD4Gys1YNsm8jJA9bfYZFY68dwEgIIIKACaTOIZMgqkjGnSDZrjjGGUuR7gQACCKS8AG23lD8H1AABtwp4ve3G9c2t3yzqhUDKC3j9+pbygtTAwwIExzx88qg6AggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIICAMwHmHHPmRW4EEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEPCxAc8/DJo+oIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAAALOBAiOOfMiNwIIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAgIcFCI55+ORRdQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAWcCBMeceZEbAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEDAwwIExzx88qg6AggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIICAMwGCY868yI0AAggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIOBhAYJjHj55VB0BBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQMCZAMExZ17kRgABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQ8LAAwTEPnzyqjgACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggg4EyA4JgzL3IjgAACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAgh4WIDgmIdPHlVHAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBwJkBwzJkXuRFAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBDwsQHDMwyePqiOAAAIIIIAAAggggAACCCCAAAIIIIAAAggggAACCDgTIDjmzIvcCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggggAACHhYgOObhk0fVEUAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEnAkQHHPmRW4EEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEPCxAc8/DJo+oIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAAALOBAiOOfMiNwIIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAgIcFCI55+ORRdQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAWcCBMeceZEbAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEDAwwIExzx88qg6AggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIICAMwGCY868yI0AAggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIOBhAYJjHj55VB0BBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQMCZAMExZ17kRgABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQ8LAAwTEPnzyqjgACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggg4EyA4JgzL3IjgAACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAgh4WIDgmIdPHlVHAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBwJkBwzJkXuRFAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBDwsQHDMwyePqiOAAAIIIIAAAggggAACCCCAAAIIIIAAAggggAACCDgTIDjmzIvcCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggggAACHhYgOObhk0fVEUAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEnAkQHHPmRW4EEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEPCxAc8/DJo+oIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAAALOBAiOOfMiNwIIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAgIcFCI55+ORRdQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAWcC/wdLy/AEQDY5bgAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': 0.9993829727172852, 'word': 'S'}, {'entity': 'I-PER', 'score': 0.998155415058136, 'word': '##yl'}, {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va'}, {'entity': 'I-PER', 'score': 0.9992332458496094, 'word': '##in'}, {'entity': 'I-ORG', 'score': 0.9739148616790771, 'word': 'Hu'}, {'entity': 'I-ORG', 'score': 0.976115882396698, 'word': '##gging'}, {'entity': 'I-ORG', 'score': 0.9888299107551575, 'word': 'Face'}, {'entity': 'I-LOC', 'score': 0.9932070374488831, 'word': 'Brooklyn'}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        results.append(\n",
    "            {\"entity\": label, \"score\": probabilities[idx][pred], \"word\": tokens[idx]}\n",
    "        )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 2),\n",
       " (3, 7),\n",
       " (8, 10),\n",
       " (11, 12),\n",
       " (12, 14),\n",
       " (14, 16),\n",
       " (16, 18),\n",
       " (19, 22),\n",
       " (23, 24),\n",
       " (25, 29),\n",
       " (30, 32),\n",
       " (33, 35),\n",
       " (35, 40),\n",
       " (41, 45),\n",
       " (46, 48),\n",
       " (49, 57),\n",
       " (57, 58),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
    "inputs_with_offsets[\"offset_mapping\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sá»­ dá»¥ng pipeline question-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9802603125572205,\n",
       " 'start': 78,\n",
       " 'end': 106,\n",
       " 'answer': 'Jax, PyTorch, and TensorFlow'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "context = \"\"\"\n",
    "ðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow â€” with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question = \"Which deep learning libraries back ðŸ¤— Transformers?\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9714871048927307,\n",
       " 'start': 1892,\n",
       " 'end': 1919,\n",
       " 'answer': 'Jax, PyTorch and TensorFlow'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_context = \"\"\"\n",
    "ðŸ¤— Transformers: State of the Art NLP\n",
    "\n",
    "ðŸ¤— Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
    "question answering, summarization, translation, text generation and more in over 100 languages.\n",
    "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
    "\n",
    "ðŸ¤— Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
    "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
    "can be modified to enable quick research experiments.\n",
    "\n",
    "Why should I use transformers?\n",
    "\n",
    "1. Easy-to-use state-of-the-art models:\n",
    "  - High performance on NLU and NLG tasks.\n",
    "  - Low barrier to entry for educators and practitioners.\n",
    "  - Few user-facing abstractions with just three classes to learn.\n",
    "  - A unified API for using all our pretrained models.\n",
    "  - Lower compute costs, smaller carbon footprint:\n",
    "\n",
    "2. Researchers can share trained models instead of always retraining.\n",
    "  - Practitioners can reduce compute time and production costs.\n",
    "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
    "\n",
    "3. Choose the right framework for every part of a model's lifetime:\n",
    "  - Train state-of-the-art models in 3 lines of code.\n",
    "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
    "  - Seamlessly pick the right framework for training, evaluation and production.\n",
    "\n",
    "4. Easily customize a model or an example to your needs:\n",
    "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
    "  - Model internals are exposed as consistently as possible.\n",
    "  - Model files can be used independently of the library for quick experiments.\n",
    "\n",
    "ðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question_answerer(question=question, context=long_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jax, PyTorch and TensorFlow'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_context[1892:1919]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta sáº½ Ä‘i sÃ¢u thÃªm vÃ o mÃ´ hÃ¬nh, Sá»­ dá»¥ng mÃ´ hÃ¬nh cho tÃ¡c vá»¥ há»i Ä‘Ã¡p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
    "\n",
    "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"tf\") \n",
    "outputs = model(**inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which deep learning libraries back ðŸ¤— Transformers?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow â€” with a seamless integration\\nbetween them. It's straightforward to train your models with one before loading them for inference with the other.\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 67) (1, 67)\n"
     ]
    }
   ],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "print(start_logits.shape, end_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sequence_ids = inputs.sequence_ids()\n",
    "# Che táº¥t cáº£ má»i thá»© trá»« token cá»§a ngá»¯ cáº£nh\n",
    "mask = [i != 1 for i in sequence_ids]\n",
    "# Hiá»ƒn thá»‹ token [CLS]\n",
    "mask[0] = False\n",
    "mask = tf.constant(mask)[None]\n",
    "\n",
    "start_logits = tf.where(mask, -10000, start_logits)\n",
    "end_logits = tf.where(mask, -10000, end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cÃ¡c bÆ°á»›c Ä‘á»ƒ xá»­ lÃ½ má»™t tokenizer  \n",
    "<img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/tokenization_pipeline.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chÃºng ta sáº½ tiáº¿n hÃ nh qua 4 bÆ°á»›c sau:\n",
    "- normalization   \n",
    "- pre-tokenization  \n",
    "- model  \n",
    "- post-processing  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tokenizers.Tokenizer'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(type(tokenizer.backend_tokenizer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thuá»™c tÃ­nh normalizer cá»§a Ä‘á»‘i tÆ°á»£ng tokenizer cÃ³ phÆ°Æ¡ng thá»©c normalize_str() mÃ  ta cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ tháº¥y cÃ¡ch bÆ°á»›c chuáº©n hoÃ¡ Ä‘Æ°á»£c thá»±c hiá»‡n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are u?\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.backend_tokenizer.normalizer.normalize_str(\"HÃ©llÃ² hÃ´w are Ã¼?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', (0, 5)),\n",
       " (',', (5, 6)),\n",
       " ('how', (7, 10)),\n",
       " ('are', (11, 14)),\n",
       " ('you', (16, 19)),\n",
       " ('?', (19, 20))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\"Hello, how are  you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', (0, 5)),\n",
       " (',', (5, 6)),\n",
       " ('Ä how', (6, 10)),\n",
       " ('Ä are', (10, 14)),\n",
       " ('Ä ', (14, 15)),\n",
       " ('Ä you', (15, 19)),\n",
       " ('?', (19, 20))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\"Hello, how are  you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('â–Hello,', (0, 6)),\n",
       " ('â–how', (7, 10)),\n",
       " ('â–are', (11, 14)),\n",
       " ('â–you?', (16, 20))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\"Hello, how are  you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triá»ƒn khai BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"This is the Hugging Face Course.\",\n",
    "    \"This chapter is about tokenization.\",\n",
    "    \"This section shows several tokenizer algorithms.\",\n",
    "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiáº¿p theo, ta cáº§n tiá»n tokenize kho ngá»¯ liá»‡u nÃ y thÃ nh cÃ¡c tá»«. VÃ¬ ta Ä‘ang sao chÃ©p má»™t báº£n BPE tokenizer (nhÆ° GPT-2), ta váº«n cÃ³ thá»ƒ sá»­ dá»¥ng gpt2 tokenize cho bÆ°á»›c pre-tokenization:\n",
    "\n",
    "Copied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau Ä‘Ã³ ta tÃ­nh táº§n suáº¥t cá»§a tá»«ng tá»« trong kho ngá»¯ liá»‡u nhÆ° khi lÃ m vá»›i pre-tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'This': 3, 'Ä is': 2, 'Ä the': 1, 'Ä Hugging': 1, 'Ä Face': 1, 'Ä Course': 1, '.': 4, 'Ä chapter': 1, 'Ä about': 1, 'Ä tokenization': 1, 'Ä section': 1, 'Ä shows': 1, 'Ä several': 1, 'Ä tokenizer': 1, 'Ä algorithms': 1, 'Hopefully': 1, ',': 1, 'Ä you': 1, 'Ä will': 1, 'Ä be': 1, 'Ä able': 1, 'Ä to': 1, 'Ä understand': 1, 'Ä how': 1, 'Ä they': 1, 'Ä are': 1, 'Ä trained': 1, 'Ä and': 1, 'Ä generate': 1, 'Ä tokens': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "word_freqs = defaultdict(int)\n",
    "\n",
    "for text in corpus:\n",
    "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "    new_words = [word for word, offset in words_with_offsets]\n",
    "    for word in new_words:\n",
    "        word_freqs[word] += 1\n",
    "\n",
    "print(word_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiáº¿p theo chÃºng ta sáº½ tÃ­nh bá»™ tá»« vá»±ng cÆ¡ sá»Ÿ tá»« cÃ¡c kÃ­ tá»± sá»­ dá»¥ng trong kho ngá»¯ liá»‡u:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'C', 'F', 'H', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z', 'Ä ']\n"
     ]
    }
   ],
   "source": [
    "alphabet = []\n",
    "\n",
    "for word in word_freqs.keys():\n",
    "    for letter in word:\n",
    "        if letter not in alphabet:\n",
    "            alphabet.append(letter)\n",
    "alphabet.sort()\n",
    "\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"<|endoftext|>\"] + alphabet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', ',', '.', 'C', 'F', 'H', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z', 'Ä ']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    pre_tokenize_result = tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "    pre_tokenized_text = [word for word, offset in pre_tokenize_result]\n",
    "    splits = [[l for l in word] for word in pre_tokenized_text]\n",
    "    for pair, merge in merges.items():\n",
    "        for idx, split in enumerate(splits):\n",
    "            i = 0\n",
    "            while i < len(split) - 1:\n",
    "                if split[i] == pair[0] and split[i + 1] == pair[1]:\n",
    "                    split = split[:i] + [merge] + split[i + 2 :]\n",
    "                else:\n",
    "                    i += 1\n",
    "            splits[idx] = split\n",
    "\n",
    "    return sum(splits, [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÄIá»‚M Máº NH:\n",
    "1. táº¡o Ä‘Æ°á»£c nhá»¯ng thÃ nh pháº§n tá»« bá»‹ thiáº¿u (sub-word)\n",
    "\n",
    "ÄIá»‚M Yáº¾U:\n",
    "1. khÃ´ng thá»ƒ táº¡o Ä‘Æ°á»£c tá»« má»›i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordPiece tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÄIá»‚M Máº NH:\n",
    "1. so vá»›i BPE, tokenizer nÃ y há»c cÃ¡c pháº§n cá»§a tá»« nhÆ° lÃ  token nhanh hÆ¡n má»™t chÃºt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Táº¡i má»—i bÆ°á»›c cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n, thuáº­t toÃ¡n Unigram tÃ­nh toÃ¡n sá»± máº¥t mÃ¡t trÃªn kho ngá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p tá»« vá»±ng hiá»‡n táº¡i. Sau Ä‘Ã³, Ä‘á»‘i vá»›i má»—i kÃ½ hiá»‡u trong tá»« vá»±ng, thuáº­t toÃ¡n sáº½ tÃ­nh toÃ¡n má»©c Ä‘á»™ tá»•n tháº¥t tá»•ng thá»ƒ sáº½ tÄƒng lÃªn bao nhiÃªu náº¿u kÃ½ hiá»‡u bá»‹ xÃ³a vÃ  tÃ¬m kiáº¿m cÃ¡c kÃ½ hiá»‡u lÃ m tÄƒng nÃ³ Ã­t nháº¥t.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "náº¿u chÃºng ta sá»­ dá»¥ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ Unigram Ä‘á»ƒ táº¡o vÄƒn báº£n, chÃºng ta sáº½ luÃ´n dá»± Ä‘oÃ¡n token phá»• biáº¿n nháº¥t.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "GPT3 dÃ¹ng word piece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XÃ¢y dá»±ng má»™t WordPiece tokenizer tá»« Ä‘áº§u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thu tháº­p má»™t kho ngá»¯ liá»‡u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ta sáº½ chia nhá» thÃ nh cÃ¡c batch Ä‘á»ƒ khÃ´ng bá»‹ over ram memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", name=\"wikitext-2-raw-v1\", split=\"train\")\n",
    "\n",
    "\n",
    "def get_training_corpus():\n",
    "    '''\n",
    "    HÃ m tráº£ vá» cÃ¡c batch vá»›i má»—i batch chá»©a 1000 Ä‘oáº¡n vÄƒn\n",
    "    ''' \n",
    "    \n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"wikitext-2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(len(dataset)):\n",
    "        f.write(dataset[i][\"text\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wikitext-2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(len(dataset)):\n",
    "        f.write(dataset[i][\"text\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n",
      "0\n",
      "706\n",
      "524\n",
      "574\n",
      "0\n",
      "19\n",
      "0\n",
      "1221\n"
     ]
    }
   ],
   "source": [
    "for  i in range(10):\n",
    "    print(len(dataset[i]['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XÃ¢y dá»±ng má»™t WordPiece tokenizer tá»« Ä‘áº§u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta cáº§n chá»‰ rÃµ unknow_token Ä‘á»ƒ biáº¿t mÃ´ hÃ¬nh tráº£ vá» gÃ¬ khi gáº·p token chÆ°a biáº¿t. ta cáº§n cÃ i Ä‘áº·t max_input_chars_per_word tÆ°Æ¡ng á»©ng Ä‘á» dÃ i tá»‘i da cho má»™t tá»«, tá»« dÃ i hÆ¡n giá»›i háº¡n nÃ y sáº½ bá»‹ chia nhá» "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bÆ°á»›c Ä‘áº§u chÃºng ta sáº½ Ä‘i chuáº©n hoÃ¡, let's go "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VÃ¬ BERT Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng tÃ£i, ta cÃ³ thá»ƒ sá»­ dá»¥ng BertNormalizer vá»›i tuá»³ chá»n kinh Ä‘iá»ƒn Ä‘á»ƒ thiáº¿t láº­p cho BERT: lowercase vÃ  strip_accents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import strip_accents_ascii\n",
    "\n",
    "text = \"HÃ©llo, hÃ³w Ã¡re yÃ³u?\"\n",
    "text_without_accents = strip_accents_ascii(text)\n",
    "\n",
    "print(text_without_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.normalizer = normalizers.Sequence(\n",
    "#     [normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()]\n",
    "# )\n",
    "\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [normalizers.NFD(), normalizers.Lowercase()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng chuáº©n hoÃ¡ Unicode NFD Unicode normalizer, vÃ¬ náº¿u khÃ´ng chuáº©n hoÃ¡ StripAccents sáº½ khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c nhá»¯ng kÃ­ tá»± cÃ³ dáº¥u vÃ  khÃ´ng thá»ƒ tÃ¡ch nÃ³ Ä‘Ãºng nhÆ° ta muá»‘n.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heÌlloÌ€ hoÌ‚w are uÌˆ?\n",
      "ok chuÌng ta neÌ‚n Ä‘eÌ‚Ì‰ nhuÌ› theÌ‚Ì naÌ€y seÌƒ hay hoÌ›n Ä‘aÌ‚Ìy caÌc baÌ£n aÌ£\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.normalizer.normalize_str(\"HÃ©llÃ² hÃ´w are Ã¼?\"))\n",
    "print(tokenizer.normalizer.normalize_str(\"ok chÃºng ta nÃªn Ä‘á»ƒ nhÆ° tháº¿ nÃ y sáº½ hay hÆ¡n Ä‘áº¥y cÃ¡c báº¡n áº¡\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ä‘Ã o sÃ¢u hÆ¡n ***  \n",
    "Náº¿u báº¡n muá»‘n kiá»ƒm tra xem hai phiÃªn báº£n chuáº©n hoÃ¡ trÆ°á»›c Ä‘Ã³ trÃªn cÃ¹ng má»t chuá»—i  kÃ½ tá»± unicode u\"\\u0085\", báº¡n cháº¯c cháº¯n sáº½ nháº­n tháº¥y ráº±ng hai cÃ¡ch chuáº©n hoÃ¡ nÃ y khÃ´ng giá»‘ng nhau. Äá»ƒ trÃ¡nh phá»©c táº¡p hoÃ¡ phiÃªn báº£n vá»›i normalizers.Sequence quÃ¡ nhiá»u, chÃºng tÃ´i sáº½ khÃ´ng abao gá»“m sá»± thay tháº¿ theo Regex mÃ  BertNormalizer yÃªu cáº§u khi tham sá»— clean_text Ä‘Æ°á»£c thiáº¿t láº­p lÃ  True -Ä‘Ã¢y cÅ©ng lÃ  giÃ¡ trá»‹ máº·c Ä‘á»‹nh. NhÆ°ng Ä‘á»«ng lo: cÃ³ kháº£ nÄƒng ta sáº½ nháº­n Ä‘Æ°á»£c káº¿t quáº£ chuáº©n hoÃ¡ giá»‘ng nhau mÃ  khÃ´ng cáº§n sá»­ dá»¥ng BertNormalizer thá»§ cÃ´ng báº±ng cÃ¡ch thÃªm hai normalizers.Replace vÃ o chuá»—i chuáº©n hoÃ¡.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiáº¿p theo lÃ  bÆ°á»›c pre-tokenization. Má»™t láº§n ná»¯a, ta cÃ³ BertPreTokenizer Ä‘Æ°á»£c xÃ¢y dá»±ng sáºµn Ä‘á»ƒ dÃ¹ng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoáº·c ta cÃ³ thá»ƒ xÃ¢y tá»« Ä‘áº§u:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LÆ°u Ã½ ráº±ng Whitespace sáº½ tÃ¡ch theo dáº¥u cÃ¡ch vÃ  cÃ¡c kÃ­ tá»± khÃ´ng pháº£i chá»¯ cÃ¡i, sá»‘, hoáº·c dáº¥u gáº¡ch dÆ°á»›i, nÃªn vá» máº·t ká»¹ thuáº­t nÃ³ sáº½ tÃ¡ch theo dáº¥u cÃ¡ch vÃ  dáº¥u cÃ¢u:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Let', (0, 3)),\n",
       " (\"'\", (3, 4)),\n",
       " ('s', (4, 5)),\n",
       " ('test', (6, 10)),\n",
       " ('my', (11, 13)),\n",
       " ('pre', (14, 17)),\n",
       " ('-', (17, 18)),\n",
       " ('tokenizer', (18, 27)),\n",
       " ('.', (27, 28))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tÃ¡ch theo dáº¥u cÃ¡ch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Let's\", (0, 5)),\n",
       " ('test', (6, 10)),\n",
       " ('my', (11, 13)),\n",
       " ('pre-tokenizer.', (14, 28))]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "báº¡n cÃ³ thá»ƒ káº¿t há»£p cÃ¡c pre-tokenizer vá»›i nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Let', (0, 3)), (\"'\", (3, 4)), ('s', (4, 5)), ('test', (6, 10)), ('my', (11, 13)), ('pre', (14, 17)), ('-', (17, 18)), ('tokenizer', (18, 27)), ('.', (27, 28))]\n",
      "[('Let', (0, 3)), (\"'\", (3, 4)), ('s test my pre', (4, 17)), ('-', (17, 18)), ('tokenizer', (18, 27)), ('.', (27, 28))]\n"
     ]
    }
   ],
   "source": [
    "pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]\n",
    ")\n",
    "print(pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\"))\n",
    "\n",
    "pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [pre_tokenizers.Punctuation()]\n",
    ")\n",
    "print(pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BÆ°á»›c tiáº¿p theo trong pipeline tokenize lÃ  Ä‘Æ°a Ä‘áº§u vÃ o qua mÃ´ hÃ¬nh. Ta Ä‘Ã£ chá»‰ Ä‘á»‹nh mÃ´ hÃ¬nh cá»§a mÃ¬nh khi khá»Ÿi táº¡o, nhÆ°ng ta váº«n cáº§n huáº¥n luyá»‡n nÃ³, Ä‘iá»u nÃ y cáº§n tá»›i WordPieceTrainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "váº¥n Ä‘á» á»Ÿ Ä‘Ã¢y lÃ  khi khá»Ÿi Ä‘á»™ng má»™t trÃ¬nh huáº¥n luyá»‡n trong hugging face thÃ¬ báº¡n cáº§n truyá»n táº¥t cáº£ cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t báº¡n cáº§n khi sá»­ dá»¥ng,  náº¿u khÃ´ng nÃ³ sáº½ khÃ´ng thÃªm vÃ o bá»™ tá»« vá»±ng, vÃ¬ chÃºng khÃ´ng cÃ³ trong kho ngá»¯ liá»‡u huáº¥n luyá»‡n "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VÃ­ dá»¥, trong BERT, cÃ¡c token Ä‘áº·c biá»‡t bao gá»“m [CLS], [SEP], vÃ  [MASK]. Nhá»¯ng token nÃ y cÃ³ Ã½ nghÄ©a Ä‘áº·c biá»‡t trong mÃ´ hÃ¬nh vÃ  khÃ´ng nÃªn bá»‹ chia nhá». Äá»ƒ trÃ¡nh viá»‡c chÃºng bá»‹ chia nhá», ta cáº§n thÃªm chÃºng vÃ o bá»™ tá»« vá»±ng trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÅ©ng nhÆ° viá»‡c chá»‰ Ä‘á»‹nh vocab_size vÃ  special_tokens, ta cáº§n thiáº¿t láº­p min_frequency (sá»‘ láº§n má»™t token pháº£i xuáº¥t hiá»‡n Ä‘á»ƒ Ä‘Æ°á»£c thÃªm vÃ o bá»™ tá»« vá»±ng) hoáº·c thay Ä‘á»•i continuing_subword_prefix (náº¿u ta muá»‘n sá»­ dá»¥ng thá»© gÃ¬ khÃ¡c ngoÃ i ##). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Äá»ƒ huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh sá»­ dá»¥ng trÃ¬nh láº·p ta Ä‘á»‹nh nghÄ©a trÆ°á»›c Ä‘Ã³, ta chá»‰ cáº§n thá»±c hiá»‡n lá»‡nh nÃ y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chÃºng ta cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c tá»‡p vÄƒn báº£n Ä‘á»ƒ huáº¥n luyá»‡n tokenizer cá»§a mÃ¬nh nhÆ° sau (ta tÃ¡i khá»Ÿi táº¡o mÃ´ hÃ¬nh vá»›i má»™t WordPiece rá»—ng):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.model = models.WordPiece(unk_token=\"[UNK]\")\n",
    "tokenizer.train([\"wikitext-2.txt\"], trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '.']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding thu dc lÃ  má»™t encoding gá»“m táº¥t cáº£ cÃ¡c Ä‘áº§u ra cáº§n thiáº¿t  cá»§a má»™t tokenizer trong táº¥t cáº£ cÃ¡c thÃ´ng sá»‘ Ä‘a dáº¡ng cá»§a nÃ³: ids, type_ids, tokens, offsets, attention_mask, special_toekns_mask vÃ  overflowing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "háº­u xá»­ lÃ½: post-tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta cáº§n thÃªm token [CLS] token táº¡i Ä‘áº§u vÃ  [SEP] á»Ÿ cuá»‘i (hoáº·c sau má»—i cÃ¢u náº¿u ta cÃ³ cáº·p cÃ¢u). ChÃºng ta sáº½ sá»­ dá»¥ng `TemplateProcessor` Ä‘á»ƒ thá»±c hiá»‡n Ä‘iá»u nÃ y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.token_to_id(\"[CLS]\")\n",
    "sep_token_id = tokenizer.token_to_id(\"[SEP]\")\n",
    "print(cls_token_id, sep_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Äá»ƒ viáº¿t báº£n máº«u cho TemplateProcessor, chÃºng ta pháº£i chá»‰ Ä‘á»‹nh cÃ¡ch xá»­ lÃ½ má»™t cÃ¢u Ä‘Æ¡n vÃ  má»™t cáº·p cÃ¢u. Äá»‘i vá»›i cáº£ hai, chÃºng tÃ´i viáº¿t cÃ¡c token Ä‘áº·c biá»‡t muá»‘n sá»­ dá»¥ng; cÃ¢u Ä‘áº§u tiÃªn (hoáº·c cÃ¢u Ä‘Æ¡n) Ä‘Æ°á»£c biá»ƒu thá»‹ báº±ng $A, trong khi cÃ¢u thá»© hai (náº¿u token má»™t cáº·p) Ä‘Æ°á»£c biá»ƒu thá»‹ báº±ng $B. Äá»‘i vá»›i má»—i  loáº¡i trong sá»‘ nÃ y (token vÃ  cÃ¢u Ä‘áº·c biá»‡t), chÃºng ta cÅ©ng chá»‰ Ä‘á»‹nh loáº¡i token ID tÆ°Æ¡ng á»©ng sau hai dáº¥u cháº¥m. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do Ä‘Ã³, báº£n máº«u BERT cá»• Ä‘iá»ƒn Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=f\"[CLS]:0 $A:0 [SEP]:0\",\n",
    "    pair=f\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n",
    "    special_tokens=[(\"[CLS]\", cls_token_id), (\"[SEP]\", sep_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lÆ°u Ã½ ráº±ng chÃºng ta cáº§n truyá»n vÃ o táº¥t cáº£ cÃ¡c IDs cá»§a cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t, nÃªn cÃ¡c tokenizer cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i chÃºng thÃ nh cÃ¡c cáº·p ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Má»™t khi Ä‘Ã£ thÃªm vÃ o chÃºng ta cÃ³ thá»ƒ quay láº¡i vÃ­ dá»¥ trÆ°á»›c Ä‘Ã³ vÃ  sáº½ nháº­n Ä‘Æ°á»£c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VÃ  trÃªn má»™t cáº·p cÃ¢u, chÃºng ta cÃ³ thá»ƒ cÃ³ Ä‘Æ°á»£c káº¿t quáº£ sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '..', '[SEP]', 'on', 'a', 'pair', 'of', 'sentences', '.', '[SEP]']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer..\" , \"on a pair of sentences.\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChÃºng ta Ä‘Ã£ gáº§n nhÆ° hoÃ n thÃ nh viá»‡c xÃ¢y dá»±ng tokenizer nÃ y tá»« Ä‘áº§u â€” bÆ°á»›c cuá»‘i cÃ¹ng lÃ  thÃªm vÃ o má»™t trÃ¬nh giáº£i mÃ£:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.WordPiece(prefix=\"##\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HÃ£y cÅ©ng kiá»ƒm thá»­ vá»›i encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"let ' s test this tokenizer.. on a pair of sentences.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyá»‡t vá»i! Ta cÃ³ thá»ƒ lÆ°u tokenizer cá»§a mÃ¬nh vÃ o trong má»™t tá»‡p JSON nhÆ° dÆ°á»›i Ä‘Ã¢y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sau Ä‘Ã³ cÃ³ thá»ƒ load láº¡i tá»‡p nÃ y trong Ä‘á»‘i tÆ°á»£ng Tokenizer vá»›i phÆ°Æ¡ng thá»©c from_file():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = Tokenizer.from_file(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Äá»ƒ sá»­ dá»¥ng tokenizer nÃ y trong ðŸ¤— Transformers, chÃºng ta pháº£i bá»c nÃ³ trong PreTrainedTokenizerFast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng lá»›p chung hoáº·c, náº¿u tokenizer cá»§a chÃºng ta tÆ°Æ¡ng á»©ng vá»›i má»™t mÃ´ hÃ¬nh hiá»‡n cÃ³, hÃ£y sá»­ dá»¥ng lá»›p Ä‘Ã³ (á»Ÿ Ä‘Ã¢y lÃ  BertTokenizerFast). Náº¿u báº¡n Ã¡p dá»¥ng bÃ i há»c nÃ y Ä‘á»ƒ xÃ¢y dá»±ng má»™t tokenizer hoÃ n toÃ n má»›i, báº¡n sáº½ pháº£i sá»­ dá»¥ng tÃ¹y chá»n Ä‘áº§u tiÃªn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Äá»ƒ bá»c tokenizer trong má»™t PreTrainedTokenizerFast, chÃºng ta cÃ³ thá»ƒ chuyá»ƒn tokenizer mÃ  chÃºng ta Ä‘Ã£ xÃ¢y dá»±ng dÆ°á»›i dáº¡ng tokenizer_object hoáº·c truyá»n tá»‡p tokenizer chÃºng ta Ä‘Ã£ lÆ°u dÆ°á»›i dáº¡ng tokenizer_file. Äiá»u quan trá»ng cáº§n nhá»› lÃ  chÃºng ta pháº£i Ä‘áº·t thá»§ cÃ´ng táº¥t cáº£ cÃ¡c tokenizer Ä‘áº·c biá»‡t , vÃ¬ lá»›p Ä‘Ã³ khÃ´ng thá»ƒ suy ra tá»« Ä‘á»‘i tÆ°á»£ng tokenizer nÃ o lÃ  tokenizer bá»‹ MASK, [CLS], [SEP], vÃ  [PAD] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    # tokenizer_file=\"tokenizer.json\", # Báº¡n cÃ³ thá»ƒ táº£i tá»« tá»‡p tokenizer\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Náº¿u báº¡n Ä‘ang sá»± dá»¥ng má»™t lá»›p tokenizer Ä‘áº·c biá»‡t (nhÆ° BertTokenizerFast), báº¡n chá»‰ cáº§n chá»‰ Ä‘á»‹nh má»™t token Ä‘áº·c biáº¿t khÃ¡c so vá»›i máº·c Ä‘á»‹nh (á»Ÿ Ä‘Ã¢y lÃ  khÃ´ng xÃ¡c Ä‘á»‹nh, do cÃ¡c thÃ nh pháº§n nÃ y Ä‘Ã£ cÃ³ tá»« trÆ°á»›c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = BertTokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng tokenizer nhÆ° báº¥t ká»³ tokenizer nÃ o khÃ¡c cá»§a hugging face transformers. Báº¡n cÃ³ thá»ƒ lÆ°u nÃ³ vá»›i phÆ°Æ¡ng thá»©c save_pretrained(), hoáº·c push nÃ³ lÃªn Hub vá»›i phÆ°Æ¡ng thá»©c push_to_hub()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá» chÃºng ta Ä‘Ã£ tháº¥y cÃ¡ch xÃ¢y dá»±ng bá»™ WordPiece tokenizer, hÃ£y lÃ m tÆ°Æ¡ng tá»± Ä‘á»‘i vá»›i BPE tokenizer. ChÃºng ta sáº½ tiáº¿n hÃ nh nhanh hÆ¡n má»™t chÃºt vÃ¬ báº¡n Ä‘Ã£ biáº¿t táº¥t cáº£ cÃ¡c bÆ°á»›c vÃ  chá»‰ lÃ m ná»•i báº­t nhá»¯ng Ä‘iá»ƒm khÃ¡c biá»‡t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XÃ¢y dá»±ng má»™t BPE tokenizer tá»« Ä‘áº§u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá» hÃ£y cÅ©ng nhau xÃ¢y dá»±ng GPT-2 tokenizer. Giá»‘ng nhÆ° BERT tokenizer, chÃºng ta báº¯t Ä‘áº§u báº±ng viá»‡c khá»Ÿi táº¡o Tokenizer vá»›i mÃ´ hÃ¬nh BPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cÅ©ng giá»‘ng nhÆ° Bert, chÃºng ta cÃ³ thá»ƒ khá»Ÿi táº¡o mÃ´ hÃ¬nh nÃ y vá»›i má»™t bá»™ tá»« vá»±ng náº¿u ta Ä‘Ã£ cÃ³ (ta sáº½ cáº§n truyá»n vÃ o vocab vÃ  merges trong trÆ°á»ng há»£p nÃ y), nhÆ°ng vÃ¬ ta sáº½ huáº¥n luyá»‡n tá»« Ä‘áº§u, chÃºng ta khÃ´ng cáº§n lÃ m váº­y. Ta cÅ©ng khÃ´ng cáº§n chá»‰ Ä‘á»‹nh unk_token vÃ¬ GPT-2 sá»­ dá»¥ng BPE cáº¥p byte, phÆ°Æ¡ng phÃ¡p khÃ´ng cáº§n Ä‘áº¿n nÃ³ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 khÃ´ng sá»­ dá»¥ng má»™t trÃ¬nh chuáº©n hoÃ¡, nÃªn ta cÃ³ thá»ƒ bá» qua bÆ°á»›c nÃ y vÃ  Ä‘i trá»±c tiáº¿p vÃ o bÆ°á»›c pre-tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuá»³ chá»n ByteLevel chÃºng ta thÃªm vÃ o á»Ÿ Ä‘Ã¢y khÃ´ng thÃªm dáº¥u cÃ¡ch vÃ o Ä‘áº§u cá»§a má»™t cÃ¢u (thÆ°á»ng nÃ³ lÃ  máº·c Ä‘á»‹nh). Ta cÃ³ thá»ƒ nhÃ¬n cÃ¡c pre-tokenization tá»« vÃ­ dá»¥ tÆ°Æ¡ng tá»± á»Ÿ trÃªn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Let', (0, 3)),\n",
       " (\"'s\", (3, 5)),\n",
       " ('Ä test', (5, 10)),\n",
       " ('Ä pre', (10, 14)),\n",
       " ('-', (14, 15)),\n",
       " ('tokenization', (15, 27)),\n",
       " ('!', (27, 28))]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test pre-tokenization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(nháº¯c láº¡i: Ä  lÃ  kÃ½ hiá»‡u dáº¥u cÃ¡ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiáº¿p theo lÃ  mÃ´ hÃ¬nh mÃ  ta cáº§n huáº¥n luyá»‡n. Vá»›i GPT-2, token Ä‘áº·c biá»‡t duy nháº¥t cáº§n lÃ  token káº¿t thÃºc vÄƒn báº£n: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=[\"<|endoftext|>\"])\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NhÆ° vá»›i WordPieceTrainer, cÅ©ng nhÆ° vocab_size vÃ  special_tokens, ta cÃ³ thá»ƒ chá»‰ Ä‘á»‹nh min_frequency náº¿u muá»‘n, hoáº·c náº¿u ta cÃ³ háº­u tá»‘ káº¿t thÃºc tá»« (nhÆ° </w>), ta cÃ³ thá»ƒ thiáº¿t láº­p nÃ³ vá»›i end_of_word_suffix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***tokenizer nÃ y cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c tá»‡p vÄƒn báº£n:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.model = models.BPE()\n",
    "tokenizer.train([\"wikitext-2.txt\"], trainer=trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HÃ£y cÅ©ng xem káº¿t quáº£ tokenize trÃªn má»™t vÄƒn báº£n máº«u:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'et', \"'\", 's', 'Ä test', 'Ä this', 'Ä to', 'ken', 'izer', '.']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta Ã¡p dá»¥ng háº­u xá»­ lÃ½ cáº¥p byte cho GPT-2 tokenizer nhÆ° sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuá»³ chá»n trim_offsets = False chá»‰ cho háº­u xá»­ lÃ½ biáº¿t ráº±ng ta cáº§n bá» má»™t sá»‘ offset token báº¯t Ä‘áº§u vá»›i \"Ä \": theo cÃ¡ch nÃ y, Ä‘iá»ƒm báº¯t Ä‘áº§u cá»§a ofset sáº½ trá» vÃ o vÃ¹ng khÃ´ng gian phÃ­a trÆ°á»›c cá»§a tá»«  (vÃ¬ vÃ¹ng khÃ´ng gian nÃ y vá» máº·t ká»¹ thuáº­t lÃ  má»™t pháº§n cá»§a tá»«). HÃ£y cÃ¹ng nhÃ¬n xem káº¿t quáº£ vá»›i chuá»—i vÄƒn báº£n  ta vuewaf mÃ£ hoÃ¡ vá»›i 'Ä test' lÃ  token á»Ÿ chá»‰ má»¥c 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Let's test this tokenizer.\"\n",
    "encoding = tokenizer.encode(sentence)\n",
    "start, end = encoding.offsets[4]\n",
    "sentence[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'et', \"'\", 's', 'Ä test', 'Ä this', 'Ä to', 'ken', 'izer', '.']\n",
      "[(0, 1), (1, 3), (3, 4), (4, 5), (5, 10), (10, 15), (15, 18), (18, 21), (21, 25), (25, 26)]\n",
      "L\n",
      "et\n",
      "'\n",
      "s\n",
      " test\n",
      " this\n",
      " to\n",
      "ken\n",
      "izer\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print(encoding.tokens)\n",
    "len(encoding.tokens)\n",
    "print(encoding.offsets)\n",
    "count = 0\n",
    "for (start, end) in encoding.offsets:\n",
    "    print(sentence[start:end])\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuá»‘i cÃ¹ng,  ta thÃªm má»™t trÃ¬nh giáº£i mÃ£ cáº¥p byte:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.ByteLevel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vÃ  kiá»ƒm tra xem nÃ³ hoáº¡t Ä‘á»™ng Ä‘Ãºng chÆ°a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's test this tokenizer.\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> nÃ³ Ä‘Ã£ reproduce láº¡i cÃ¢u ban Ä‘áº§u nÃªn nÃ³ Ä‘Ã£ hoáº¡t Ä‘á»™ng Ä‘Ãºng "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá» ta Ä‘Ã£ xong rá»“i, ta cÃ³ thá»ƒ lÆ°u tokenizer nhÆ° trÃªn, vÃ  bao nÃ³ láº¡i trong PreTrainedTokenizerFast hoáº·c GPT2TokenizerFast náº¿u ta muá»‘n nÃ³ trong ðŸ¤— Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cÃ¡ch 1 \n",
    "from transformers import PreTrainedTokenizerFast \n",
    "wrapped_tokenizer  = PreTrainedTokenizerFast(\n",
    "    tokenizer_object = tokenizer,\n",
    "    bos_token = \"<|endoftext|>\",\n",
    "    eos_token = \"<|endoftext|>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cÃ¡ch 2 dÃ¹ng luÃ´n GPT2TokenizerFast Ä‘Æ°á»£c xÃ¢y dá»±ng sáºµn thÃ¬ mÃ¬nh kjhoong cáº§n Ä‘á»‹nh nghÄ©a thÃªm cÃ¡c tham sá»‘ nhÆ° cÃ¡ch 1\n",
    "from transformers import GPT2TokenizerFast\n",
    "wrapped_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xÃ¢y dá»±ng má»™t Unigram tokenizer tá»« Ä‘áº§u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng má»™t XLNet tokenizer. CÅ©ng giá»‘ng nhÆ° cÃ¡c tokenizer trÆ°á»›c Ä‘Ã³, ta cÃ³ thá»ƒ báº¯t Ä‘áº§u khá»Ÿi táº¡o Tokenizer vá»›i má»™t mÃ´ hÃ¬nh Unigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.Unigram())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Má»™t láº§n ná»¯a, chÃºng ta cÃ³ thá»ƒ khá»Ÿi táº¡o mÃ´ hÃ¬nh nÃ y vá»›i má»™t tá»« vá»±ng náº¿u cÃ³.\n",
    "\n",
    "Vá»›i sá»± chuáº©n hoÃ¡ nÃ y, XLNet sá»­ dá»¥ng má»™t vÃ i phÆ°Æ¡ng phÃ¡p thay tháº¿ (Ä‘áº¿n tá»« SentencePiece):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Regex\n",
    "\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace(\"``\", '\"'),\n",
    "        normalizers.Replace(\"''\", '\"'),\n",
    "        normalizers.NFKD(),\n",
    "        normalizers.StripAccents(),\n",
    "        normalizers.Replace(Regex(\" {2,}\"), \" \"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ä‘iá»u nÃ y thay tháº¿ \"  vÃ  \" báº±ng \"  (á»Ÿ Ä‘Ã¢y chuáº©n hoÃ¡ dáº¥u má»Ÿ ngoáº·c vÃ  Ä‘Ã³ng ngoáº·c báº±ng 1 dáº¥u kÃ©p cá»¥ thá»ƒ)  vÃ  thay tháº¿ báº¥t ká»³ chuá»—i nÃ o chá»©a hai hoáº·c nhiá»u hÆ¡n dáº¥u cÃ¡ch liá»n nhau thnahf má»™t dáº¥u duy nháº¥t, cÅ©ng nhÆ° loáº¡i bá» cÃ¡c dáº¥u cÃ³ trong vÄƒn báº£n Ä‘á»ƒ tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-tokenizer Ä‘Æ°á»£c sá»­ dá»¥ng cho SentencePiece tokenizer lÃ  Metaspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta cÃ³ thá»ƒ nhÃ¬n vÃ o Ä‘áº§u ra quy trÃ¬nh tiá»n tokenizer qua vÃ­  dá»¥ vÄƒn báº£n dÆ°á»›i Ä‘Ã¢y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"â–Let's\", (0, 5)),\n",
       " ('â–test', (5, 10)),\n",
       " ('â–the', (10, 14)),\n",
       " ('â–pre-tokenizer!', (14, 29))]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test the pre-tokenizer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiáº¿p theo lÃ  mÃ´ hÃ¬nh ta cáº§n huáº¥n luyá»‡n. XLNet cÃ³ má»™t sá»‘ token Ä‘áº·c biá»‡t:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "special_tokens = [\"<cls>\", \"<sep>\", \"<unk>\", \"<pad>\", \"<mask>\", \"<s>\", \"</s>\"]\n",
    "trainer = trainers.UnigramTrainer(\n",
    "    vocab_size=25000, special_tokens=special_tokens, unk_token=\"<unk>\"\n",
    ")\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Má»™t tham sá»‘ vÃ´ cÃ¹ng quan trong mÃ  ta khÃ´ng thá»ƒ quÃªn cá»§a UnigramTrainer lÃ  unk_token. Ta cÃ³ thá»ƒ truyá»n vÃ o cÃ¡c tham sá»‘ cá»¥ thá»ƒ khÃ¡c tá»›i thuáº­t toÃ¡n Unigram, vÃ­ dá»¥ shrinking_factor cho cÃ¡c bÆ°á»›c mÃ  ta xoÃ¡ token (máº·c Ä‘á»‹nh lÃ  0.75) hoáº·c max_piece_length Ä‘á»ƒ chá»‰ Ä‘á»‹nh Ä‘á»™ dÃ i tá»‘i Ä‘a cá»§a má»™t token (máº·c Ä‘á»‹nh lÃ  16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c tá»‡p vÄƒn báº£n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.model = models.Unigram()\n",
    "# tokenizer.train([\"wikitext-2.txt\"], trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tokenizer.train_from_iterator() got an unexpected keyword argument 'unk_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m text_iterator \u001b[38;5;241m=\u001b[39m line_by_line_text_generator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikitext-2.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the tokenizer\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_from_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[UNK]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tokenizer.train_from_iterator() got an unexpected keyword argument 'unk_token'"
     ]
    }
   ],
   "source": [
    "def line_by_line_text_generator(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            yield line\n",
    "\n",
    "# Create the iterator\n",
    "text_iterator = line_by_line_text_generator(\"wikitext-2.txt\")\n",
    "\n",
    "# Train the tokenizer\n",
    "tokenizer.train_from_iterator(text_iterator, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â–Let', \"'\", 's', 'â–test', 'â–this', 'â–to', 'ken', 'izer', '.']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)\n",
    "# print(encoding.type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Má»™t  Ä‘áº·c Ä‘iá»ƒm Ä‘áº·c biá»‡t cá»§a XLNet Ä‘Ã³ lÃ  nÃ³ thÃªm <cls> á»Ÿ cuá»‘i má»—i cÃ¢u, vá»›i kiá»ƒu ID laf 2 (Ä‘á»ƒ phÃ¢n biá»‡t vá»›i cÃ¡c token khÃ¡c). NÃ³ Ä‘Ãªm thÃªm vÃ o phÃ­a bÃªn trÃ¡i giá»‘ng nhÆ° káº¿t quáº£ á»Ÿ trÃªn, a cÃ³ thá»ƒ xá»­ lÃ½ táº¥t cáº£ cÃ¡c token Ä‘áº·c biá»‡t vÃ  cÃ¡c token kiá»ƒu ID vá»›i cÃ¹ng má»™t báº£n máº«u, nhÆ° BERT, nhÆ°ng Ä‘áº§u tiÃªn ta pháº£i láº¥y cÃ¡c ID cá»§a token [cls] vÃ  [sep]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.token_to_id(\"<cls>\")\n",
    "sep_token_id = tokenizer.token_to_id(\"<sep>\")\n",
    "print(cls_token_id, sep_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Báº£n máº«u sáº½ trÃ´ng nhÆ° sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"$A:0 <sep>:0 <cls>:2\",\n",
    "    pair=\"$A:0 <sep>:0 $B:1 <sep>:1 <cls>:2\",\n",
    "    special_tokens=[(\"<sep>\", sep_token_id), (\"<cls>\", cls_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VÃ  ta cÃ³ thá»ƒ kiá»ƒm tra xem nÃ³ hoáº¡t Ä‘á»™ng khÃ´ng báº±ng cÃ¡ch mÃ£ hoÃ¡ cáº·p cÃ¢u:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â–Let', \"'\", 's', 'â–test', 'â–this', 'â–to', 'ken', 'izer', '.', '.', '.', '<sep>', 'â–', 'on', 'â–', 'a', 'â–pair', 'â–of', 'â–sentence', 's', '!', '<sep>', '<cls>']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer...\", \"on a pair of sentences!\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuá»‘i cÃ¹ng, ta sáº½ thÃªm trÃ¬nh giáº£i mÃ£ Metaspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.Metaspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ta cÃ³ thá»ƒ lÆ°u tokenizer nhÆ° trÃªn, vÃ  bao nÃ³ láº¡i trong PreTrainedTokenizerFast hoáº·c XLNetTokenizerFast náº¿u ta muá»‘n nÃ³ trong ðŸ¤— Transformers. Má»™t Ä‘iá»ƒm cáº§n lÆ°u Ã½ lÃ  khi sá»­ dá»¥ng PreTrainedTokenizerFast thÃ¬ trÃªn Ä‘áº§u cá»§a cÃ¡c token Ä‘áº·c biá»‡t ta cáº§n nÃ³i cho thÆ° viá»‡n ðŸ¤— Transformers viáº¿t ta cáº§n Ä‘á»‡m vÃ o phÃ­a bÃªn trÃ¡i:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    cls_token=\"<cls>\",\n",
    "    sep_token=\"<sep>\",\n",
    "    mask_token=\"<mask>\",\n",
    "    padding_side=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoáº·c má»™t cÃ¡ch khÃ¡c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = XLNetTokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
