{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuananh/anaconda3/envs/code/lib/python3.8/site-packages/datasets/load.py:1461: FutureWarning: The repository for code_search_net contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/code_search_net\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# This can take a few minutes to load, so grab a coffee or tea while you wait!\n",
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 412178\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412178"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_new_token(self, netloc):\n",
      "        \"\"\"Get a new token from BIG-IP and store it internally.\n",
      "\n",
      "        Throws relevant exception if it fails to get a new token.\n",
      "\n",
      "        This method will be called automatically if a request is attempted\n",
      "        but there is no authentication token, or the authentication token\n",
      "        is expired.  It is usually not necessary for users to call it, but\n",
      "        it can be called if it is known that the authentication token has\n",
      "        been invalidated by other means.\n",
      "        \"\"\"\n",
      "        login_body = {\n",
      "            'username': self.username,\n",
      "            'password': self.password,\n",
      "        }\n",
      "\n",
      "        if self.auth_provider:\n",
      "            if self.auth_provider == 'local':\n",
      "                login_body['loginProviderName'] = 'local'\n",
      "            elif self.auth_provider == 'tmos':\n",
      "                login_body['loginProviderName'] = 'tmos'\n",
      "            elif self.auth_provider not in ['none', 'default']:\n",
      "                providers = self.get_auth_providers(netloc)\n",
      "                for provider in providers:\n",
      "                    if self.auth_provider in provider['link']:\n",
      "                        login_body['loginProviderName'] = provider['name']\n",
      "                        break\n",
      "                    elif self.auth_provider == provider['name']:\n",
      "                        login_body['loginProviderName'] = provider['name']\n",
      "                        break\n",
      "        else:\n",
      "            if self.login_provider_name == 'tmos':\n",
      "                login_body['loginProviderName'] = self.login_provider_name\n",
      "\n",
      "        login_url = \"https://%s/mgmt/shared/authn/login\" % (netloc)\n",
      "\n",
      "        response = requests.post(\n",
      "            login_url,\n",
      "            json=login_body,\n",
      "            verify=self.verify,\n",
      "            auth=HTTPBasicAuth(self.username, self.password)\n",
      "        )\n",
      "        self.attempts += 1\n",
      "        if not response.ok or not hasattr(response, \"json\"):\n",
      "            error_message = '%s Unexpected Error: %s for uri: %s\\nText: %r' %\\\n",
      "                            (response.status_code,\n",
      "                             response.reason,\n",
      "                             response.url,\n",
      "                             response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "        respJson = response.json()\n",
      "\n",
      "        token = self._get_token_from_response(respJson)\n",
      "        created_bigip = self._get_last_update_micros(token)\n",
      "\n",
      "        try:\n",
      "            expiration_bigip = self._get_expiration_micros(\n",
      "                token, created_bigip\n",
      "            )\n",
      "        except (KeyError, ValueError):\n",
      "            error_message = \\\n",
      "                '%s Unparseable Response: %s for uri: %s\\nText: %r' %\\\n",
      "                (response.status_code,\n",
      "                 response.reason,\n",
      "                 response.url,\n",
      "                 response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "\n",
      "        try:\n",
      "            self.expiration = self._get_token_expiration_time(\n",
      "                created_bigip, expiration_bigip\n",
      "            )\n",
      "        except iControlUnexpectedHTTPError:\n",
      "            error_message = \\\n",
      "                '%s Token already expired: %s for uri: %s\\nText: %r' % \\\n",
      "                (response.status_code,\n",
      "                 time.ctime(expiration_bigip),\n",
      "                 response.url,\n",
      "                 response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "def get_new_token(self, netloc):\n",
      "        \"\"\"Get a new token from BIG-IP and store it internally.\n",
      "\n",
      "        Throws relevant exception if it fails to get a new token.\n",
      "\n",
      "        This method will be called automatically if a request is attempted\n",
      "        but there is no authentication token, or the authentication token\n",
      "        is expired.  It is usually not necessary for users to call it, but\n",
      "        it can be called if it is known that the authentication token has\n",
      "        been invalidated by other means.\n",
      "        \"\"\"\n",
      "        login_body = {\n",
      "            'username': self.username,\n",
      "            'password': self.password,\n",
      "        }\n",
      "\n",
      "        if self.auth_provider:\n",
      "            if self.auth_provider == 'local':\n",
      "                login_body['loginProviderName'] = 'local'\n",
      "            elif self.auth_provider == 'tmos':\n",
      "                login_body['loginProviderName'] = 'tmos'\n",
      "            elif self.auth_provider not in ['none', 'default']:\n",
      "                providers = self.get_auth_providers(netloc)\n",
      "                for provider in providers:\n",
      "                    if self.auth_provider in provider['link']:\n",
      "                        login_body['loginProviderName'] = provider['name']\n",
      "                        break\n",
      "                    elif self.auth_provider == provider['name']:\n",
      "                        login_body['loginProviderName'] = provider['name']\n",
      "                        break\n",
      "        else:\n",
      "            if self.login_provider_name == 'tmos':\n",
      "                login_body['loginProviderName'] = self.login_provider_name\n",
      "\n",
      "        login_url = \"https://%s/mgmt/shared/authn/login\" % (netloc)\n",
      "\n",
      "        response = requests.post(\n",
      "            login_url,\n",
      "            json=login_body,\n",
      "            verify=self.verify,\n",
      "            auth=HTTPBasicAuth(self.username, self.password)\n",
      "        )\n",
      "        self.attempts += 1\n",
      "        if not response.ok or not hasattr(response, \"json\"):\n",
      "            error_message = '%s Unexpected Error: %s for uri: %s\\nText: %r' %\\\n",
      "                            (response.status_code,\n",
      "                             response.reason,\n",
      "                             response.url,\n",
      "                             response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "        respJson = response.json()\n",
      "\n",
      "        token = self._get_token_from_response(respJson)\n",
      "        created_bigip = self._get_last_update_micros(token)\n",
      "\n",
      "        try:\n",
      "            expiration_bigip = self._get_expiration_micros(\n",
      "                token, created_bigip\n",
      "            )\n",
      "        except (KeyError, ValueError):\n",
      "            error_message = \\\n",
      "                '%s Unparseable Response: %s for uri: %s\\nText: %r' %\\\n",
      "                (response.status_code,\n",
      "                 response.reason,\n",
      "                 response.url,\n",
      "                 response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n",
      "\n",
      "        try:\n",
      "            self.expiration = self._get_token_expiration_time(\n",
      "                created_bigip, expiration_bigip\n",
      "            )\n",
      "        except iControlUnexpectedHTTPError:\n",
      "            error_message = \\\n",
      "                '%s Token already expired: %s for uri: %s\\nText: %r' % \\\n",
      "                (response.status_code,\n",
      "                 time.ctime(expiration_bigip),\n",
      "                 response.url,\n",
      "                 response.text)\n",
      "            raise iControlUnexpectedHTTPError(error_message,\n",
      "                                              response=response)\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])\n",
    "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MESSAGE_CALLBACK = lambda x: None\n",
    "def handle_simple_responses(\n",
    "      self, timeout_ms=None, info_cb=DEFAULT_MESSAGE_CALLBACK):\n",
    "    \"\"\"Accepts normal responses from the device.\n",
    "\n",
    "    Args:\n",
    "      timeout_ms: Timeout in milliseconds to wait for each response.\n",
    "      info_cb: Optional callback for text sent from the bootloader.\n",
    "\n",
    "    Returns:\n",
    "      OKAY packet's message.\n",
    "    \"\"\"\n",
    "    return self._accept_responses('OKAY', info_cb, timeout_ms=timeout_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = (\n",
    "    raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "    for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "gen = (i for i in range(10))\n",
    "print(list(gen))\n",
    "print(list(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "        for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    dataset = raw_datasets[\"train\"]\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = dataset[start_idx : start_idx + 1000]\n",
    "        yield samples[\"whole_func_string\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your tokenizer from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how to build your tokenizer from scratch, we have to dive a little bit more in the 🤗 Tokenizers library and the tokenization pipeline. This pipeline takes several steps:  \n",
    "\n",
    "- **Normalization:** Executes all the initial transformations over the initial input string. For example when you need to lowercase some text, maybe strip it, or even apply one of the common unicode normalization process, you will add a Normalizer.  \n",
    "\n",
    "- **Pre-tokenization:** In charge of splitting the initial input string. That's the component that decides where and how to pre-segment the origin string. The simplest example would be to simply split on spaces.  \n",
    "\n",
    "- **Model:** Handles all the sub-token discovery and generation, this is the part that is trainable and really dependent of your input data.\n",
    "\n",
    "- **Post-Processing:** Provides advanced construction features to be compatible with some of the Transformers-based SoTA models. For instance, for BERT it would wrap the tokenized sentence around [CLS] and [SEP] tokens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other directions: \n",
    "- **Decoding**: in charge of mapping back a tokenized input to the original string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện một tokenizer mới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ġadd',\n",
       " '_',\n",
       " 'n',\n",
       " 'umbers',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'Ġb',\n",
       " '):',\n",
       " 'Ċ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ\"\"\"',\n",
       " 'Add',\n",
       " 'Ġthe',\n",
       " 'Ġtwo',\n",
       " 'Ġnumbers',\n",
       " 'Ġ`',\n",
       " 'a',\n",
       " '`',\n",
       " 'Ġand',\n",
       " 'Ġ`',\n",
       " 'b',\n",
       " '`',\n",
       " '.\"',\n",
       " '\"\"',\n",
       " 'Ċ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġreturn',\n",
       " 'Ġa',\n",
       " 'Ġ+',\n",
       " 'Ġb']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''\n",
    "\n",
    "tokens = old_tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'Ġadd', '_', 'numbers', '(', 'a', ',', 'Ġb', '):', 'ĊĠĠĠ', 'Ġ\"\"\"', 'Add', 'Ġthe', 'Ġtwo', 'Ġnumbers', 'Ġ`', 'a', '`', 'Ġand', 'Ġ`', 'b', '`.\"\"\"', 'ĊĠĠĠ', 'Ġreturn', 'Ġa', 'Ġ+', 'Ġb']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(example)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(old_tokenizer.tokenize(example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'ĠLinear', 'Layer', '():', 'ĊĠĠĠ', 'Ġdef', 'Ġ__', 'init', '__(', 'self', ',', 'Ġinput', '_', 'size', ',', 'Ġoutput', '_', 'size', '):', 'ĊĠĠĠĠĠĠĠ', 'Ġself', '.', 'weight', 'Ġ=', 'Ġtorch', '.', 'randn', '(', 'input', '_', 'size', ',', 'Ġoutput', '_', 'size', ')', 'ĊĠĠĠĠĠĠĠ', 'Ġself', '.', 'bias', 'Ġ=', 'Ġtorch', '.', 'zeros', '(', 'output', '_', 'size', ')', 'ĊĊĠĠĠ', 'Ġdef', 'Ġ__', 'call', '__(', 'self', ',', 'Ġx', '):', 'ĊĠĠĠĠĠĠĠ', 'Ġreturn', 'Ġx', 'Ġ@', 'Ġself', '.', 'weights', 'Ġ+', 'Ġself', '.', 'bias', 'ĊĠĠĠĠ']\n"
     ]
    }
   ],
   "source": [
    "example = \"\"\"class LinearLayer():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weight = torch.randn(input_size, output_size)\n",
    "        self.bias = torch.zeros(output_size)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.weights + self.bias\n",
    "    \"\"\"\n",
    "print(tokenizer.tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer nhanh và chậm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "encoding = tokenizer(example)\n",
    "print(type(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'My', 'name', 'is', 'S', '##yl', '##va', '##in', 'and', 'I', 'work', 'at', 'Hu', '##gging', 'Face', 'in', 'Brooklyn', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(encoding.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sylvain'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = encoding.word_to_chars(3)\n",
    "example[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bên trong pipeline token-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline là một nhóm các model đã được code sẵn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 17:07:12.617401: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 17:07:13.178742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.99938285,\n",
       "  'index': 4,\n",
       "  'word': 'S',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99815494,\n",
       "  'index': 5,\n",
       "  'word': '##yl',\n",
       "  'start': 12,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99590707,\n",
       "  'index': 6,\n",
       "  'word': '##va',\n",
       "  'start': 14,\n",
       "  'end': 16},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99923277,\n",
       "  'index': 7,\n",
       "  'word': '##in',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9738931,\n",
       "  'index': 12,\n",
       "  'word': 'Hu',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.976115,\n",
       "  'index': 13,\n",
       "  'word': '##gging',\n",
       "  'start': 35,\n",
       "  'end': 40},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9887976,\n",
       "  'index': 14,\n",
       "  'word': 'Face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9932106,\n",
       "  'index': 16,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\")\n",
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thực hiện nhóm chúng lại với nhau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"simple\")\n",
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 17:07:18.188945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.209848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.210021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.210879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.211056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.211207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.284694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.284883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.285040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 17:07:18.285179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22494 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "All the weights of TFBertForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n",
      "2024-05-17 17:07:19.731955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForTokenClassification\n",
    "\n",
    "model_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "inputs = tokenizer(example, return_tensors=\"tf\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19)\n",
      "(1, 19, 9)\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"].shape)\n",
    "print(outputs.logits.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có một lô với 1 chuỗi gồm 19 token và mô hình có 9 nhãn khác nhau, vì vậy đầu ra của mô hình có hình dạng 1 x 19 x 9. Giống như đối với pipeline phân loại văn bản, chúng ta sử dụng hàm softmax để chuyển đổi các logits đó theo xác suất, và chúng ta lấy argmax để nhận dự đoán (lưu ý rằng ta có thể lấy argmax trên logits vì softmax không thay đổi thứ tự):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "probabilities = tf.math.softmax(outputs.logits, axis=-1)[0]\n",
    "probabilities = probabilities.numpy().tolist()\n",
    "predictions = tf.math.argmax(outputs.logits, axis=-1)[0]\n",
    "predictions = predictions.numpy().tolist()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-MISC',\n",
       " 2: 'I-MISC',\n",
       " 3: 'B-PER',\n",
       " 4: 'I-PER',\n",
       " 5: 'B-ORG',\n",
       " 6: 'I-ORG',\n",
       " 7: 'B-LOC',\n",
       " 8: 'I-LOC'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ở đây định dạng B-PER chỉ được sử dụng để phân tách 2 từ khác nhau, dòng thứ 2 màu hồng được sử dụng trong hoàn cảnh này (còn để dễ hiểu và phân biệt rõ hơn ta sẽ nhìn vào dòng thứ 3)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': 0.9993829727172852, 'word': 'S'}, {'entity': 'I-PER', 'score': 0.998155415058136, 'word': '##yl'}, {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va'}, {'entity': 'I-PER', 'score': 0.9992332458496094, 'word': '##in'}, {'entity': 'I-ORG', 'score': 0.9739148616790771, 'word': 'Hu'}, {'entity': 'I-ORG', 'score': 0.976115882396698, 'word': '##gging'}, {'entity': 'I-ORG', 'score': 0.9888299107551575, 'word': 'Face'}, {'entity': 'I-LOC', 'score': 0.9932070374488831, 'word': 'Brooklyn'}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        results.append(\n",
    "            {\"entity\": label, \"score\": probabilities[idx][pred], \"word\": tokens[idx]}\n",
    "        )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 2),\n",
       " (3, 7),\n",
       " (8, 10),\n",
       " (11, 12),\n",
       " (12, 14),\n",
       " (14, 16),\n",
       " (16, 18),\n",
       " (19, 22),\n",
       " (23, 24),\n",
       " (25, 29),\n",
       " (30, 32),\n",
       " (33, 35),\n",
       " (35, 40),\n",
       " (41, 45),\n",
       " (46, 48),\n",
       " (49, 57),\n",
       " (57, 58),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
    "inputs_with_offsets[\"offset_mapping\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sử dụng pipeline question-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9802603125572205,\n",
       " 'start': 78,\n",
       " 'end': 106,\n",
       " 'answer': 'Jax, PyTorch, and TensorFlow'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "context = \"\"\"\n",
    "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch, and TensorFlow — with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question = \"Which deep learning libraries back 🤗 Transformers?\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9714871048927307,\n",
       " 'start': 1892,\n",
       " 'end': 1919,\n",
       " 'answer': 'Jax, PyTorch and TensorFlow'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_context = \"\"\"\n",
    "🤗 Transformers: State of the Art NLP\n",
    "\n",
    "🤗 Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
    "question answering, summarization, translation, text generation and more in over 100 languages.\n",
    "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
    "\n",
    "🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
    "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
    "can be modified to enable quick research experiments.\n",
    "\n",
    "Why should I use transformers?\n",
    "\n",
    "1. Easy-to-use state-of-the-art models:\n",
    "  - High performance on NLU and NLG tasks.\n",
    "  - Low barrier to entry for educators and practitioners.\n",
    "  - Few user-facing abstractions with just three classes to learn.\n",
    "  - A unified API for using all our pretrained models.\n",
    "  - Lower compute costs, smaller carbon footprint:\n",
    "\n",
    "2. Researchers can share trained models instead of always retraining.\n",
    "  - Practitioners can reduce compute time and production costs.\n",
    "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
    "\n",
    "3. Choose the right framework for every part of a model's lifetime:\n",
    "  - Train state-of-the-art models in 3 lines of code.\n",
    "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
    "  - Seamlessly pick the right framework for training, evaluation and production.\n",
    "\n",
    "4. Easily customize a model or an example to your needs:\n",
    "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
    "  - Model internals are exposed as consistently as possible.\n",
    "  - Model files can be used independently of the library for quick experiments.\n",
    "\n",
    "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question_answerer(question=question, context=long_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jax, PyTorch and TensorFlow'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_context[1892:1919]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta sẽ đi sâu thêm vào mô hình, Sử dụng mô hình cho tác vụ hỏi đáp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
    "\n",
    "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"tf\") \n",
    "outputs = model(**inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which deep learning libraries back 🤗 Transformers?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch, and TensorFlow — with a seamless integration\\nbetween them. It's straightforward to train your models with one before loading them for inference with the other.\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 67) (1, 67)\n"
     ]
    }
   ],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "print(start_logits.shape, end_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sequence_ids = inputs.sequence_ids()\n",
    "# Che tất cả mọi thứ trừ token của ngữ cảnh\n",
    "mask = [i != 1 for i in sequence_ids]\n",
    "# Hiển thị token [CLS]\n",
    "mask[0] = False\n",
    "mask = tf.constant(mask)[None]\n",
    "\n",
    "start_logits = tf.where(mask, -10000, start_logits)\n",
    "end_logits = tf.where(mask, -10000, end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "các bước để xử lý một tokenizer  \n",
    "<img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/tokenization_pipeline.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chúng ta sẽ tiến hành qua 4 bước sau:\n",
    "- normalization   \n",
    "- pre-tokenization  \n",
    "- model  \n",
    "- post-processing  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tokenizers.Tokenizer'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(type(tokenizer.backend_tokenizer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thuộc tính normalizer của đối tượng tokenizer có phương thức normalize_str() mà ta có thể dùng để thấy cách bước chuẩn hoá được thực hiện:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are u?\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.backend_tokenizer.normalizer.normalize_str(\"Héllò hôw are ü?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', (0, 5)),\n",
       " (',', (5, 6)),\n",
       " ('how', (7, 10)),\n",
       " ('are', (11, 14)),\n",
       " ('you', (16, 19)),\n",
       " ('?', (19, 20))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\"Hello, how are  you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', (0, 5)),\n",
       " (',', (5, 6)),\n",
       " ('Ġhow', (6, 10)),\n",
       " ('Ġare', (10, 14)),\n",
       " ('Ġ', (14, 15)),\n",
       " ('Ġyou', (15, 19)),\n",
       " ('?', (19, 20))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\"Hello, how are  you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁Hello,', (0, 6)),\n",
       " ('▁how', (7, 10)),\n",
       " ('▁are', (11, 14)),\n",
       " ('▁you?', (16, 20))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\"Hello, how are  you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triển khai BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"This is the Hugging Face Course.\",\n",
    "    \"This chapter is about tokenization.\",\n",
    "    \"This section shows several tokenizer algorithms.\",\n",
    "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, ta cần tiền tokenize kho ngữ liệu này thành các từ. Vì ta đang sao chép một bản BPE tokenizer (như GPT-2), ta vẫn có thể sử dụng gpt2 tokenize cho bước pre-tokenization:\n",
    "\n",
    "Copied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó ta tính tần suất của từng từ trong kho ngữ liệu như khi làm với pre-tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'This': 3, 'Ġis': 2, 'Ġthe': 1, 'ĠHugging': 1, 'ĠFace': 1, 'ĠCourse': 1, '.': 4, 'Ġchapter': 1, 'Ġabout': 1, 'Ġtokenization': 1, 'Ġsection': 1, 'Ġshows': 1, 'Ġseveral': 1, 'Ġtokenizer': 1, 'Ġalgorithms': 1, 'Hopefully': 1, ',': 1, 'Ġyou': 1, 'Ġwill': 1, 'Ġbe': 1, 'Ġable': 1, 'Ġto': 1, 'Ġunderstand': 1, 'Ġhow': 1, 'Ġthey': 1, 'Ġare': 1, 'Ġtrained': 1, 'Ġand': 1, 'Ġgenerate': 1, 'Ġtokens': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "word_freqs = defaultdict(int)\n",
    "\n",
    "for text in corpus:\n",
    "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "    new_words = [word for word, offset in words_with_offsets]\n",
    "    for word in new_words:\n",
    "        word_freqs[word] += 1\n",
    "\n",
    "print(word_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo chúng ta sẽ tính bộ từ vựng cơ sở từ các kí tự sử dụng trong kho ngữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'C', 'F', 'H', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z', 'Ġ']\n"
     ]
    }
   ],
   "source": [
    "alphabet = []\n",
    "\n",
    "for word in word_freqs.keys():\n",
    "    for letter in word:\n",
    "        if letter not in alphabet:\n",
    "            alphabet.append(letter)\n",
    "alphabet.sort()\n",
    "\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"<|endoftext|>\"] + alphabet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', ',', '.', 'C', 'F', 'H', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z', 'Ġ']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    pre_tokenize_result = tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "    pre_tokenized_text = [word for word, offset in pre_tokenize_result]\n",
    "    splits = [[l for l in word] for word in pre_tokenized_text]\n",
    "    for pair, merge in merges.items():\n",
    "        for idx, split in enumerate(splits):\n",
    "            i = 0\n",
    "            while i < len(split) - 1:\n",
    "                if split[i] == pair[0] and split[i + 1] == pair[1]:\n",
    "                    split = split[:i] + [merge] + split[i + 2 :]\n",
    "                else:\n",
    "                    i += 1\n",
    "            splits[idx] = split\n",
    "\n",
    "    return sum(splits, [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ĐIỂM MẠNH:\n",
    "1. tạo được những thành phần từ bị thiếu (sub-word)\n",
    "\n",
    "ĐIỂM YẾU:\n",
    "1. không thể tạo được từ mới"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordPiece tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ĐIỂM MẠNH:\n",
    "1. so với BPE, tokenizer này học các phần của từ như là token nhanh hơn một chút.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tại mỗi bước của quá trình huấn luyện, thuật toán Unigram tính toán sự mất mát trên kho ngữ liệu được cung cấp từ vựng hiện tại. Sau đó, đối với mỗi ký hiệu trong từ vựng, thuật toán sẽ tính toán mức độ tổn thất tổng thể sẽ tăng lên bao nhiêu nếu ký hiệu bị xóa và tìm kiếm các ký hiệu làm tăng nó ít nhất.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nếu chúng ta sử dụng mô hình ngôn ngữ Unigram để tạo văn bản, chúng ta sẽ luôn dự đoán token phổ biến nhất.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "GPT3 dùng word piece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng một WordPiece tokenizer từ đầu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thu thập một kho ngữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ta sẽ chia nhỏ thành các batch để không bị over ram memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", name=\"wikitext-2-raw-v1\", split=\"train\")\n",
    "\n",
    "\n",
    "def get_training_corpus():\n",
    "    '''\n",
    "    Hàm trả về các batch với mỗi batch chứa 1000 đoạn văn\n",
    "    ''' \n",
    "    \n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"wikitext-2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(len(dataset)):\n",
    "        f.write(dataset[i][\"text\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wikitext-2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(len(dataset)):\n",
    "        f.write(dataset[i][\"text\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n",
      "0\n",
      "706\n",
      "524\n",
      "574\n",
      "0\n",
      "19\n",
      "0\n",
      "1221\n"
     ]
    }
   ],
   "source": [
    "for  i in range(10):\n",
    "    print(len(dataset[i]['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Xây dựng một WordPiece tokenizer từ đầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta cần chỉ rõ unknow_token để biết mô hình trả về gì khi gặp token chưa biết. ta cần cài đặt max_input_chars_per_word tương ứng đọ dài tối da cho một từ, từ dài hơn giới hạn này sẽ bị chia nhỏ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bước đầu chúng ta sẽ đi chuẩn hoá, let's go "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì BERT được sử dụng rộng tãi, ta có thể sử dụng BertNormalizer với tuỳ chọn kinh điển để thiết lập cho BERT: lowercase và strip_accents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import strip_accents_ascii\n",
    "\n",
    "text = \"Héllo, hów áre yóu?\"\n",
    "text_without_accents = strip_accents_ascii(text)\n",
    "\n",
    "print(text_without_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.normalizer = normalizers.Sequence(\n",
    "#     [normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()]\n",
    "# )\n",
    "\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [normalizers.NFD(), normalizers.Lowercase()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta cũng có thể sử dụng chuẩn hoá Unicode NFD Unicode normalizer, vì nếu không chuẩn hoá StripAccents sẽ không nhận diện được những kí tự có dấu và không thể tách nó đúng như ta muốn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "héllò hôw are ü?\n",
      "ok chúng ta nên để như thế này sẽ hay hơn đấy các bạn ạ\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.normalizer.normalize_str(\"Héllò hôw are ü?\"))\n",
    "print(tokenizer.normalizer.normalize_str(\"ok chúng ta nên để như thế này sẽ hay hơn đấy các bạn ạ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***đào sâu hơn ***  \n",
    "Nếu bạn muốn kiểm tra xem hai phiên bản chuẩn hoá trước đó trên cùng mọt chuỗi  ký tự unicode u\"\\u0085\", bạn chắc chắn sẽ nhận thấy rằng hai cách chuẩn hoá này không giống nhau. Để tránh phức tạp hoá phiên bản với normalizers.Sequence quá nhiều, chúng tôi sẽ không abao gồm sự thay thế theo Regex mà BertNormalizer yêu cầu khi tham sỗ clean_text được thiết lập là True -đây cũng là giá trị mặc định. Nhưng đừng lo: có khả năng ta sẽ nhận được kết quả chuẩn hoá giống nhau mà không cần sử dụng BertNormalizer thủ công bằng cách thêm hai normalizers.Replace vào chuỗi chuẩn hoá.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo là bước pre-tokenization. Một lần nữa, ta có BertPreTokenizer được xây dựng sẵn để dùng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoặc ta có thể xây từ đầu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý rằng Whitespace sẽ tách theo dấu cách và các kí tự không phải chữ cái, số, hoặc dấu gạch dưới, nên về mặt kỹ thuật nó sẽ tách theo dấu cách và dấu câu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Let', (0, 3)),\n",
       " (\"'\", (3, 4)),\n",
       " ('s', (4, 5)),\n",
       " ('test', (6, 10)),\n",
       " ('my', (11, 13)),\n",
       " ('pre', (14, 17)),\n",
       " ('-', (17, 18)),\n",
       " ('tokenizer', (18, 27)),\n",
       " ('.', (27, 28))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tách theo dấu cách "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Let's\", (0, 5)),\n",
       " ('test', (6, 10)),\n",
       " ('my', (11, 13)),\n",
       " ('pre-tokenizer.', (14, 28))]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bạn có thể kết hợp các pre-tokenizer với nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Let', (0, 3)), (\"'\", (3, 4)), ('s', (4, 5)), ('test', (6, 10)), ('my', (11, 13)), ('pre', (14, 17)), ('-', (17, 18)), ('tokenizer', (18, 27)), ('.', (27, 28))]\n",
      "[('Let', (0, 3)), (\"'\", (3, 4)), ('s test my pre', (4, 17)), ('-', (17, 18)), ('tokenizer', (18, 27)), ('.', (27, 28))]\n"
     ]
    }
   ],
   "source": [
    "pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]\n",
    ")\n",
    "print(pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\"))\n",
    "\n",
    "pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [pre_tokenizers.Punctuation()]\n",
    ")\n",
    "print(pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước tiếp theo trong pipeline tokenize là đưa đầu vào qua mô hình. Ta đã chỉ định mô hình của mình khi khởi tạo, nhưng ta vẫn cần huấn luyện nó, điều này cần tới WordPieceTrainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vấn đề ở đây là khi khởi động một trình huấn luyện trong hugging face thì bạn cần truyền tất cả các ký tự đặc biệt bạn cần khi sử dụng,  nếu không nó sẽ không thêm vào bộ từ vựng, vì chúng không có trong kho ngữ liệu huấn luyện "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ, trong BERT, các token đặc biệt bao gồm [CLS], [SEP], và [MASK]. Những token này có ý nghĩa đặc biệt trong mô hình và không nên bị chia nhỏ. Để tránh việc chúng bị chia nhỏ, ta cần thêm chúng vào bộ từ vựng trước khi huấn luyện mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cũng như việc chỉ định vocab_size và special_tokens, ta cần thiết lập min_frequency (số lần một token phải xuất hiện để được thêm vào bộ từ vựng) hoặc thay đổi continuing_subword_prefix (nếu ta muốn sử dụng thứ gì khác ngoài ##). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để huấn luyện một mô hình sử dụng trình lặp ta định nghĩa trước đó, ta chỉ cần thực hiện lệnh này:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chúng ta cũng có thể sử dụng các tệp văn bản để huấn luyện tokenizer của mình như sau (ta tái khởi tạo mô hình với một WordPiece rỗng):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.model = models.WordPiece(unk_token=\"[UNK]\")\n",
    "tokenizer.train([\"wikitext-2.txt\"], trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '.']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding thu dc là một encoding gồm tất cả các đầu ra cần thiết  của một tokenizer trong tất cả các thông số đa dạng của nó: ids, type_ids, tokens, offsets, attention_mask, special_toekns_mask và overflowing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hậu xử lý: post-tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta cần thêm token [CLS] token tại đầu và [SEP] ở cuối (hoặc sau mỗi câu nếu ta có cặp câu). Chúng ta sẽ sử dụng `TemplateProcessor` để thực hiện điều này "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.token_to_id(\"[CLS]\")\n",
    "sep_token_id = tokenizer.token_to_id(\"[SEP]\")\n",
    "print(cls_token_id, sep_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để viết bản mẫu cho TemplateProcessor, chúng ta phải chỉ định cách xử lý một câu đơn và một cặp câu. Đối với cả hai, chúng tôi viết các token đặc biệt muốn sử dụng; câu đầu tiên (hoặc câu đơn) được biểu thị bằng $A, trong khi câu thứ hai (nếu token một cặp) được biểu thị bằng $B. Đối với mỗi  loại trong số này (token và câu đặc biệt), chúng ta cũng chỉ định loại token ID tương ứng sau hai dấu chấm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do đó, bản mẫu BERT cổ điển được định nghĩa như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=f\"[CLS]:0 $A:0 [SEP]:0\",\n",
    "    pair=f\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n",
    "    special_tokens=[(\"[CLS]\", cls_token_id), (\"[SEP]\", sep_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lưu ý rằng chúng ta cần truyền vào tất cả các IDs của các ký tự đặc biệt, nên các tokenizer có thể chuyển đổi chúng thành các cặp ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một khi đã thêm vào chúng ta có thể quay lại ví dụ trước đó và sẽ nhận được "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và trên một cặp câu, chúng ta có thể có được kết quả sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '..', '[SEP]', 'on', 'a', 'pair', 'of', 'sentences', '.', '[SEP]']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer..\" , \"on a pair of sentences.\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta đã gần như hoàn thành việc xây dựng tokenizer này từ đầu — bước cuối cùng là thêm vào một trình giải mã:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.WordPiece(prefix=\"##\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy cũng kiểm thử với encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"let ' s test this tokenizer.. on a pair of sentences.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt vời! Ta có thể lưu tokenizer của mình vào trong một tệp JSON như dưới đây:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sau đó có thể load lại tệp này trong đối tượng Tokenizer với phương thức from_file():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = Tokenizer.from_file(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để sử dụng tokenizer này trong 🤗 Transformers, chúng ta phải bọc nó trong PreTrainedTokenizerFast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể sử dụng lớp chung hoặc, nếu tokenizer của chúng ta tương ứng với một mô hình hiện có, hãy sử dụng lớp đó (ở đây là BertTokenizerFast). Nếu bạn áp dụng bài học này để xây dựng một tokenizer hoàn toàn mới, bạn sẽ phải sử dụng tùy chọn đầu tiên.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để bọc tokenizer trong một PreTrainedTokenizerFast, chúng ta có thể chuyển tokenizer mà chúng ta đã xây dựng dưới dạng tokenizer_object hoặc truyền tệp tokenizer chúng ta đã lưu dưới dạng tokenizer_file. Điều quan trọng cần nhớ là chúng ta phải đặt thủ công tất cả các tokenizer đặc biệt , vì lớp đó không thể suy ra từ đối tượng tokenizer nào là tokenizer bị MASK, [CLS], [SEP], và [PAD] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    # tokenizer_file=\"tokenizer.json\", # Bạn có thể tải từ tệp tokenizer\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu bạn đang sự dụng một lớp tokenizer đặc biệt (như BertTokenizerFast), bạn chỉ cần chỉ định một token đặc biết khác so với mặc định (ở đây là không xác định, do các thành phần này đã có từ trước)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = BertTokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn có thể sử dụng tokenizer như bất kỳ tokenizer nào khác của hugging face transformers. Bạn có thể lưu nó với phương thức save_pretrained(), hoặc push nó lên Hub với phương thức push_to_hub()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ chúng ta đã thấy cách xây dựng bộ WordPiece tokenizer, hãy làm tương tự đối với BPE tokenizer. Chúng ta sẽ tiến hành nhanh hơn một chút vì bạn đã biết tất cả các bước và chỉ làm nổi bật những điểm khác biệt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng một BPE tokenizer từ đầu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ hãy cũng nhau xây dựng GPT-2 tokenizer. Giống như BERT tokenizer, chúng ta bắt đầu bằng việc khởi tạo Tokenizer với mô hình BPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cũng giống như Bert, chúng ta có thể khởi tạo mô hình này với một bộ từ vựng nếu ta đã có (ta sẽ cần truyền vào vocab và merges trong trường hợp này), nhưng vì ta sẽ huấn luyện từ đầu, chúng ta không cần làm vậy. Ta cũng không cần chỉ định unk_token vì GPT-2 sử dụng BPE cấp byte, phương pháp không cần đến nó "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 không sử dụng một trình chuẩn hoá, nên ta có thể bỏ qua bước này và đi trực tiếp vào bước pre-tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuỳ chọn ByteLevel chúng ta thêm vào ở đây không thêm dấu cách vào đầu của một câu (thường nó là mặc định). Ta có thể nhìn các pre-tokenization từ ví dụ tương tự ở trên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Let', (0, 3)),\n",
       " (\"'s\", (3, 5)),\n",
       " ('Ġtest', (5, 10)),\n",
       " ('Ġpre', (10, 14)),\n",
       " ('-', (14, 15)),\n",
       " ('tokenization', (15, 27)),\n",
       " ('!', (27, 28))]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test pre-tokenization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(nhắc lại: Ġ là ký hiệu dấu cách)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo là mô hình mà ta cần huấn luyện. Với GPT-2, token đặc biệt duy nhất cần là token kết thúc văn bản: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=[\"<|endoftext|>\"])\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như với WordPieceTrainer, cũng như vocab_size và special_tokens, ta có thể chỉ định min_frequency nếu muốn, hoặc nếu ta có hậu tố kết thúc từ (như </w>), ta có thể thiết lập nó với end_of_word_suffix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***tokenizer này cũng có thể được huấn luyện trên các tệp văn bản:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.model = models.BPE()\n",
    "tokenizer.train([\"wikitext-2.txt\"], trainer=trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy cũng xem kết quả tokenize trên một văn bản mẫu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'et', \"'\", 's', 'Ġtest', 'Ġthis', 'Ġto', 'ken', 'izer', '.']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta áp dụng hậu xử lý cấp byte cho GPT-2 tokenizer như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuỳ chọn trim_offsets = False chỉ cho hậu xử lý biết rằng ta cần bỏ một số offset token bắt đầu với \"Ġ\": theo cách này, điểm bắt đầu của ofset sẽ trỏ vào vùng không gian phía trước của từ  (vì vùng không gian này về mặt kỹ thuật là một phần của từ). Hãy cùng nhìn xem kết quả với chuỗi văn bản  ta vuewaf mã hoá với 'Ġtest' là token ở chỉ mục 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Let's test this tokenizer.\"\n",
    "encoding = tokenizer.encode(sentence)\n",
    "start, end = encoding.offsets[4]\n",
    "sentence[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'et', \"'\", 's', 'Ġtest', 'Ġthis', 'Ġto', 'ken', 'izer', '.']\n",
      "[(0, 1), (1, 3), (3, 4), (4, 5), (5, 10), (10, 15), (15, 18), (18, 21), (21, 25), (25, 26)]\n",
      "L\n",
      "et\n",
      "'\n",
      "s\n",
      " test\n",
      " this\n",
      " to\n",
      "ken\n",
      "izer\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print(encoding.tokens)\n",
    "len(encoding.tokens)\n",
    "print(encoding.offsets)\n",
    "count = 0\n",
    "for (start, end) in encoding.offsets:\n",
    "    print(sentence[start:end])\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuối cùng,  ta thêm một trình giải mã cấp byte:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.ByteLevel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "và kiểm tra xem nó hoạt động đúng chưa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's test this tokenizer.\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> nó đã reproduce lại câu ban đầu nên nó đã hoạt động đúng "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ ta đã xong rồi, ta có thể lưu tokenizer như trên, và bao nó lại trong PreTrainedTokenizerFast hoặc GPT2TokenizerFast nếu ta muốn nó trong 🤗 Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cách 1 \n",
    "from transformers import PreTrainedTokenizerFast \n",
    "wrapped_tokenizer  = PreTrainedTokenizerFast(\n",
    "    tokenizer_object = tokenizer,\n",
    "    bos_token = \"<|endoftext|>\",\n",
    "    eos_token = \"<|endoftext|>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cách 2 dùng luôn GPT2TokenizerFast được xây dựng sẵn thì mình kjhoong cần định nghĩa thêm các tham số như cách 1\n",
    "from transformers import GPT2TokenizerFast\n",
    "wrapped_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xây dựng một Unigram tokenizer từ đầu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy cùng nhau xây dựng một XLNet tokenizer. Cũng giống như các tokenizer trước đó, ta có thể bắt đầu khởi tạo Tokenizer với một mô hình Unigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.Unigram())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một lần nữa, chúng ta có thể khởi tạo mô hình này với một từ vựng nếu có.\n",
    "\n",
    "Với sự chuẩn hoá này, XLNet sử dụng một vài phương pháp thay thế (đến từ SentencePiece):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Regex\n",
    "\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace(\"``\", '\"'),\n",
    "        normalizers.Replace(\"''\", '\"'),\n",
    "        normalizers.NFKD(),\n",
    "        normalizers.StripAccents(),\n",
    "        normalizers.Replace(Regex(\" {2,}\"), \" \"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "điều này thay thế \"  và \" bằng \"  (ở đây chuẩn hoá dấu mở ngoặc và đóng ngoặc bằng 1 dấu kép cụ thể)  và thay thế bất kỳ chuỗi nào chứa hai hoặc nhiều hơn dấu cách liền nhau thnahf một dấu duy nhất, cũng như loại bỏ các dấu có trong văn bản để tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-tokenizer được sử dụng cho SentencePiece tokenizer là Metaspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta có thể nhìn vào đầu ra quy trình tiền tokenizer qua ví  dụ văn bản dưới đây "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"▁Let's\", (0, 5)),\n",
       " ('▁test', (5, 10)),\n",
       " ('▁the', (10, 14)),\n",
       " ('▁pre-tokenizer!', (14, 29))]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test the pre-tokenizer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo là mô hình ta cần huấn luyện. XLNet có một số token đặc biệt:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "special_tokens = [\"<cls>\", \"<sep>\", \"<unk>\", \"<pad>\", \"<mask>\", \"<s>\", \"</s>\"]\n",
    "trainer = trainers.UnigramTrainer(\n",
    "    vocab_size=25000, special_tokens=special_tokens, unk_token=\"<unk>\"\n",
    ")\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một tham số vô cùng quan trong mà ta không thể quên của UnigramTrainer là unk_token. Ta có thể truyền vào các tham số cụ thể khác tới thuật toán Unigram, ví dụ shrinking_factor cho các bước mà ta xoá token (mặc định là 0.75) hoặc max_piece_length để chỉ định độ dài tối đa của một token (mặc định là 16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer này có thể được huấn luyện trên các tệp văn bản:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.model = models.Unigram()\n",
    "# tokenizer.train([\"wikitext-2.txt\"], trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tokenizer.train_from_iterator() got an unexpected keyword argument 'unk_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m text_iterator \u001b[38;5;241m=\u001b[39m line_by_line_text_generator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikitext-2.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the tokenizer\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_from_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[UNK]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tokenizer.train_from_iterator() got an unexpected keyword argument 'unk_token'"
     ]
    }
   ],
   "source": [
    "def line_by_line_text_generator(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            yield line\n",
    "\n",
    "# Create the iterator\n",
    "text_iterator = line_by_line_text_generator(\"wikitext-2.txt\")\n",
    "\n",
    "# Train the tokenizer\n",
    "tokenizer.train_from_iterator(text_iterator, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Let', \"'\", 's', '▁test', '▁this', '▁to', 'ken', 'izer', '.']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)\n",
    "# print(encoding.type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một  đặc điểm đặc biệt của XLNet đó là nó thêm <cls> ở cuối mỗi câu, với kiểu ID laf 2 (để phân biệt với các token khác). Nó đêm thêm vào phía bên trái giống như kết quả ở trên, a có thể xử lý tất cả các token đặc biệt và các token kiểu ID với cùng một bản mẫu, như BERT, nhưng đầu tiên ta phải lấy các ID của token [cls] và [sep]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.token_to_id(\"<cls>\")\n",
    "sep_token_id = tokenizer.token_to_id(\"<sep>\")\n",
    "print(cls_token_id, sep_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bản mẫu sẽ trông như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"$A:0 <sep>:0 <cls>:2\",\n",
    "    pair=\"$A:0 <sep>:0 $B:1 <sep>:1 <cls>:2\",\n",
    "    special_tokens=[(\"<sep>\", sep_token_id), (\"<cls>\", cls_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và ta có thể kiểm tra xem nó hoạt động không bằng cách mã hoá cặp câu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Let', \"'\", 's', '▁test', '▁this', '▁to', 'ken', 'izer', '.', '.', '.', '<sep>', '▁', 'on', '▁', 'a', '▁pair', '▁of', '▁sentence', 's', '!', '<sep>', '<cls>']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer...\", \"on a pair of sentences!\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, ta sẽ thêm trình giải mã Metaspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.Metaspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ta có thể lưu tokenizer như trên, và bao nó lại trong PreTrainedTokenizerFast hoặc XLNetTokenizerFast nếu ta muốn nó trong 🤗 Transformers. Một điểm cần lưu ý là khi sử dụng PreTrainedTokenizerFast thì trên đầu của các token đặc biệt ta cần nói cho thư viện 🤗 Transformers viết ta cần đệm vào phía bên trái:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    cls_token=\"<cls>\",\n",
    "    sep_token=\"<sep>\",\n",
    "    mask_token=\"<mask>\",\n",
    "    padding_side=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoặc một cách khác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = XLNetTokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
